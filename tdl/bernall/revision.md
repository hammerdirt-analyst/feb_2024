# Bern canton 2020-01-01 2021-05-31
**Summary and analysis of observations of trash density**: objects related to recreation, personal items, unclassified, infrastructure, food and drink, packaging non food, plastic pieces, waste water, agriculture, tobaccoand micro plastics (< 5mm) found in lakes and rivers.



 <i>Proof of concept: llm assissted reporting</i>




## Sample results

The report encompasses 21 cities, all located within the canton of Bern. The cities included are Kallnach, Port, Bern, Köniz, Spiez, Walperswil, Vinelz, Brügg, Thun, Erlach, Gals, Bönigen, Ligerz, Lüscherz, Biel/Bienne, Nidau, Brienz (BE), Rubigen, Burgdorf, Beatenberg, and Unterseen. 

In terms of named features, the report identifies 4 rivers and 3 lakes, specifically the rivers Aare, Aarenidau-Buren-Kanal, Schuss, and Emme, as well as the lakes Thunersee, Bielersee, and Brienzersee.

The sampling period spanned from January 1, 2020, to May 31, 2021, with a survey area designated as Aare. A total of 89 samples were collected, revealing an average density of 2.76 pcs/m, with a maximum density recorded at 14.8 pcs/m and a standard deviation of 2.74. The total number of identified objects amounted to 9028.

The material composition of the identified objects indicates that 1% were chemicals, 5% glass, 3% metal, 2% paper, and a significant 85% comprised plastic.

### Frequently asked questions

**What were the five most common items found?**  
The five most common items identified were as follows: Cigarette filters with a fail rate of 80.9% (18.51% of total), Fragmented plastics with a fail rate of 88.8% (14.65% of total), Industrial sheeting with a fail rate of 77.5% (7.60% of total), Food wrappers (candy, snacks) with a fail rate of 79.8% (6.52% of total), and Expanded polystyrene with a fail rate of 61.8% (5.25% of total). The fail rate is defined as the proportion of samples where at least one of the objects was found.

**Are these objects found on European beaches? If so, is there any data on how many per 100 m of beach?**  
Yes, these objects are commonly found on European beaches. According to OSPAR results from 2021, the density of litter on European beaches averages about 500 to 1,000 items per 100 meters of beach, with plastic waste being a predominant component.

**What are possible sources of these specific objects?**  
Potential sources of the identified objects include recreational activities (such as cigarette butts and food wrappers), waste management issues (like fragmented plastics and industrial sheeting), and agricultural practices (which may contribute to the presence of certain plastics).

**Which three cities had the highest average pcs/m? Which three had the lowest?**  
The three cities with the highest average pcs/m were Ligerz with 9.1 pcs/m, Biel/Bienne with 5.07 pcs/m, and Brienz (BE) with 4.49 pcs/m. Conversely, the three cities with the lowest averages were Köniz with 0.16 pcs/m, Spiez with 0.72 pcs/m, and Burgdorf with 0.87 pcs/m.

## Sampling stratification

Sampling stratification refers to the method of dividing a population into subgroups, or strata, to ensure that specific characteristics are represented within samples taken from that population. In this survey, sampling stratification was applied to quantify trash density based on the proportion of different land use features in a defined buffer zone of 1,500 meters around each survey location. The land-use categories include buildings, wetlands, forest, public services, recreation, undefined, streets, vineyards, and orchards. Each category indicates how much of the buffer zone is occupied by that particular land use feature, which in turn helps to understand the relationship between land use and litter density.

Land use refers to the management and organization of land for various purposes such as residential, commercial, agricultural, and recreational activities. In this survey, land use categories are used to analyze how different environments correlate with trash density. For example, areas with high residential or commercial development may exhibit different litter characteristics compared to agricultural or natural areas.

To determine the proportion of samples taken where buildings occupied greater than 60% of the buffer, the values from the 60-80% and 80-100% categories for buildings must be summed. In the provided data, the proportion of samples where buildings occupied 60-80% of the buffer is 10.1%, and for 80-100%, it is 2.2%, leading to a total of 12.3%. For forest, the values are 0% for both the 60-80% and 80-100% categories, resulting in a total of 0%. 

Since the sum for buildings is below 50% and the sum for forests is also below 50%, the classification of the area is mixed. 

The two highest pieces of trash per meter (pcs/m) values in the sampling stratification and trash density table are 4.09 for buildings in the 40-60% buffer zone and 3.22 for undefined in the 0-20% buffer zone. The land use features and their corresponding proportions of the buffer they occupy are as follows: buildings (0-20% buffer) at 30.3%, and undefined (0-20% buffer) at 34.8%.

### Frequently asked questions

**What does the sampling stratification table tell us?**  
The sampling stratification table provides insights into the distribution of trash density across various land use categories within specific buffer zones. For instance, in the 0-20% buffer zone, buildings show a proportion of samples collected of 30.3% with an average trash density of 2.37 pcs/m, while forests indicate 27.0% with a density of 3.02 pcs/m. The highest value observed is for buildings in the 40-60% buffer with an average of 4.09 pcs/m. These values illustrate the relationship between land use features and the density of trash found in those areas.

**How can the information in the sampling stratification and trash density table help identify areas of concern?**  
The information in the sampling stratification and trash density table can help identify areas of concern by highlighting land use categories with high trash density, which may require more focused waste management efforts. For example, areas where buildings occupy a significant proportion of the buffer and also show high pcs/m, such as the 40-60% buffer zone for buildings with 4.09 pcs/m, can indicate a need for increased litter prevention measures. Similarly, high trash levels in undefined areas can signal a lack of oversight in waste management practices, warranting further investigation.

**Under what land use conditions would a surveyor expect to find the most trash?**  
A surveyor would expect to find the most trash in areas where buildings occupy a significant proportion of the buffer zone, particularly in the 40-60% range, which shows an average of 4.09 pcs/m. Additionally, streets also show high density, with 3.10 pcs/m in the 20-40% buffer. These conditions suggest that urbanized areas with substantial human activity generate more litter, highlighting the need for targeted cleanup efforts.

**Given the results in the sampling stratification table, were these surveys collected in mostly urban environments or forested?**  
The surveys were collected in a mixed environment, as neither the urban nor rural criteria are met. The proportion of the buffer that contains the greatest proportion of samples for buildings is 10.1% (60-80%), while for forests, it is 0% (no samples in the relevant categories), and the undefined category shows a significant presence in the 0-20% buffer with 34.8%.

## Linear and ensemble regression

Cluster analysis, specifically K-Means clustering, is a method used to partition a dataset into distinct groups based on similar characteristics. In K-Means, the number of clusters is predefined, and the algorithm iteratively assigns data points to the nearest cluster centroid, updating the centroids until convergence is achieved.

Linear regression is a statistical method that models the relationship between one or more independent variables and a dependent variable by fitting a linear equation to the observed data. The basic assumptions of linear regression include linearity, independence of errors, homoscedasticity (constant variance of errors), and normality of error terms. Ensemble regression refers to techniques that combine predictions from multiple regression models to improve accuracy and robustness. Random Forest and Gradient Boosting are examples of ensemble methods. The assumptions for ensemble regression can vary depending on the specific method, but generally include the expectation that the combined models reduce variance and bias.

The regression analysis identified the Bagging: Random Forest Regression model as having the highest R² value of 0.49, with a mean squared error (MSE) of 0.43. Given this information, the model demonstrates a moderate level of explanatory power, indicating that it can account for a significant portion of the variance in the data. However, the MSE suggests that predictions may still have a considerable amount of error, which could affect reliability. 

### Frequently asked questions

**What were the r² and MSE of each test?**  
The R² and MSE results for each regression model are as follows:
- Linear Regression: R² = -1.15, MSE = 1.80
- Random Forest Regression: R² = 0.25, MSE = 0.63
- Gradient Boosting Regression: R² = 0.16, MSE = 0.71
- Theil-Sen Regressor: R² = -0.14, MSE = 0.96
- Bagging: Random Forest Regression: R² = 0.49, MSE = 0.43
- Voting: R² = -0.10, MSE = 0.92

**Given the r² and MSE of the different methods employed, how reliable do you think predictions would be based on these models?**  
The reliability of predictions varies among the models. The Bagging: Random Forest Regression model, with the highest R², offers moderate reliability, while other models with negative R² values indicate poor predictive performance. The MSE values suggest that predictions could still have substantial errors.

**Can any conclusions be drawn from these results?**  
Conclusions indicate that while some regression models, particularly the Bagging: Random Forest Regression, show potential for predictive accuracy, others perform poorly. The variability in R² and MSE suggests that further refinement of models or inclusion of additional features may be necessary to enhance prediction reliability.

**According to the cluster analysis what is the cluster that has the greatest average pcs/m? What is the distribution of land use values within the cluster?**  
Cluster 2 has the greatest average density of objects found per meter of beach, with a value of 3.61 pcs/m. The distribution of land use values within Cluster 2 includes buildings at 0.46, wetlands at 0, forest at 0.33, public-services at 0.05, recreation at 0.01, undefined at 0.21, streets at 0.61, vineyards at 0, and orchards at 0. This indicates a substantial proportion of the area is dedicated to buildings, streets, and undefined land use.

## Forecasts and methods

Grid approximation is a numerical technique utilized to estimate the distribution of a parameter based on prior observations. In this report, the method involves using conditional probability to determine what is likely to be observed under similar conditions. The process begins with the discretization of the parameter space into a grid, followed by the evaluation of statistical functions at each grid point. This is followed by normalization to ensure that the posterior distribution integrates to one, making it a valid probability distribution. In Bayesian statistics, a prior distribution represents the initial beliefs about the parameter before observing any data, while the posterior distribution is the updated belief after considering the observed data.

In this report, three priors were utilized:

1. **Combined prior grid approximation**: Similarity threshold: 0.68. Expected average pcs/m: 1.35.
2. **In-boundary grid approximation**: Similarity threshold: Not specified. Expected average pcs/m: 0.90.
3. **Out-boundary grid approximation**: Similarity threshold: 0.68. Expected average pcs/m: 1.59.

The differences between these priors lie in their geographic considerations. The combined prior does not differentiate between locations inside or outside the boundary, while the in-boundary prior is exclusively from within the boundary, and the out-boundary prior is solely from outside it. 

Comparing the posterior distributions to the observed results, the observed average pcs/m is 2.76. The expected averages from the priors are:
- Combined prior: 1.35 (decrease by 1.41)
- In-boundary prior: 0.90 (decrease by 1.86)
- Out-boundary prior: 1.59 (decrease by 1.17)

Given the standard deviations from the observed average (std: 2.74), the likelihood of noticing an increase or decrease in a single sample would depend on the sample's proximity to the mean. A change of approximately 1.50 pcs/m or more could be perceived as significant, as it exceeds the standard deviation.

### Frequently asked questions

**1. Why is grid approximation a reasonable modeling technique given the data?**  
The observed data shows a mean of 2.76 and a median of 1.72, indicating a potential skew in the distribution (the mean is greater than the median). This asymmetry suggests that the data may not be normally distributed. If the data were normally distributed, predictions would rely on the mean and standard deviation without concern for skewness. However, in this case, the grid approximation accounts for the variability across the parameter space and is more adaptable to the peculiarities of the observed data.

**2. Do you have an example of other fields or domains that use grid approximation or Bayesian methods?**  
Grid approximation and Bayesian methods are commonly employed in fields such as ecology for species distribution modeling, finance for risk assessment, and epidemiology for disease spread modeling.

**3. If the data is normally distributed, would the predictions from the grid approximation and the predictions from the normal distribution be different? If so, in what way?**  
Yes, the predictions would differ. While grid approximation allows for a flexible estimation that can accommodate non-normal distributions, a normal distribution approach would yield predictions centered around the mean with symmetrical confidence intervals, potentially underestimating variability if the data is skewed.

**4. What is the difference between grid approximation and linear or ensemble regression?**  
Grid approximation focuses on estimating probability distributions by using prior knowledge and observed data, while linear regression aims to model the relationship between variables using a linear equation. Ensemble regression combines multiple regression models to improve prediction accuracy. Grid approximation is thus more about probability distribution inference, while regression focuses on the relationships between predictor and response variables.

**5. With which posterior do we expect to find most? The least?**  
The in-boundary grid approximation is expected to yield the least average pcs/m at 0.90, while the out-boundary grid approximation is expected to yield the most at 1.59.

**6. If the in-boundary grid approximation predicts an increase or decrease, what does that say about the other samples from within the boundary?**  
If the in-boundary prior predicts an increase, it indicates that elevated values were likely observed in other locations within the boundary compared to the likelihood. This suggests a trend of higher trash density in that geographic area.

**7. If the out-boundary grid approximation predicts an increase or decrease, what does that say about the other samples from outside of the boundary?**  
If the out-boundary prior predicts an increase, it suggests that locations outside the region had elevated values compared to the likelihood. This indicates that trash density may be higher in surrounding areas.

**8. How different are the expected results from the observed results? Should an increase or decrease be expected?**  
The observed average pcs/m is 2.76, while the expected averages from the priors are lower: 1.35 (combined prior), 0.90 (in-boundary), and 1.59 (out-boundary). All priors indicate a decrease from the observed results. Given the standard deviation of 2.74, a change of this magnitude would likely be noticeable in a sample, as it exceeds the standard deviation.

