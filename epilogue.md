## Trash in : GPT out 
### the big refactor

To understand hammerdirt it is necessary to recall the untidiness of the past. Karma is a bitch and you don't ever 
really know how big your debt is until it is paid in full. The last we heard from hammerdirt he was cleaning 
toilets thinking about his shiny new uniform. Things evolved from there, and things like that tend to have momentum. 
It takes a certain amount of effort to stop a large rock rolling down a hill \(name your reference there\). 

Life goes on and datascience _happened_, hammerdirt tried to hang on for the ride and produced a django API that 
served a ReactJS client that was used to record observations in the field. These two bits of software were essential to 
produce a collection of JupyterNote books that combined made a pretty nifty JupyterBook. We added .pdf downloads for 
each chapter and put some serious effort into projecting the survey results onto a topographic map.

### Next step in the value chain

Reporting the results at an appropriate scale is one way of extracting value out of the data. This provides local 
stakeholders with an accurate presentation of the situation at an actionable scale. The next step in the 
value chain is to return those results back to the client/community in a way that they can use for their own 
research. The _trash assistant_ is a GPT that holds the data for the region and a defined set of references. 

The _trash assistant_ is maintained by the people who collect the data and manage the repository. It is trained to 
perform certain standard tasks and has style preferences that can easily be modified. The maintainers ensure the 
integrity of the data and respond to issues concerning the _trash assistant_.

### Easy collaboration and reporting

The _trash assistant_ accompanies the static reports and can be used by client organisations to consider the results 
within the context their own projects. The _trash assistant_ removes the need for 


