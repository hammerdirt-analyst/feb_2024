{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c16819-72da-4b47-a3aa-988d3f5a8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca0862-a1e5-4fd3-ae17-65ac2fd7cd0a",
   "metadata": {},
   "source": [
    "# Testing data models\n",
    "\n",
    "The methods used in the version of the federal report were tested, but their was not a specific set of validation criteria beforehand. Test were done as the work progressed. This wasted alot of time\n",
    "\n",
    "here we test the land use and survey data models.\n",
    "\n",
    "1. is the land use data complete for each survey location?\n",
    "2. does the survey data aggregate correctly to sample level?\n",
    "   * what happens to objects with a quantity of zero?\n",
    "   * aggregating to cantonal, municipal or survey area\n",
    "     * are all locations included?\n",
    "     * are lakes and rivers distinguished?\n",
    "3. Does the aggregated data for iqaasl match the federal report?\n",
    "\n",
    "### Gfoams, Gfrags, Gcaps\n",
    "\n",
    "These are aggregate groups. It is difficult to infer how well a participant differentiates between size or use of the following codes.\n",
    "\n",
    "1. Gfrags: G79, G78, G75\n",
    "2. Gfoams: G81, G82, G76\n",
    "3. Gcaps: G21, G22, G23, G24\n",
    "\n",
    "These aggregate groups are used when comparing values between sampling campaigns.\n",
    "\n",
    "### Sampling campaigns\n",
    "\n",
    "The dates of the sampling campaigns are expanded to include the surveys that happened between large organized campaigns. The start and end dates are defined below.\n",
    "\n",
    "__Attention!!__ The codes used for each survey campaign are different. Different groups organized and conducted surveys using the MLW protocol. The data was then sent to us.\n",
    "\n",
    "__MCBP:__ November 2015 - November 2016. The initial sampling campaign. Fragmented plastics (Gfrags/G79/G78/G76) were not sorted by size. All unidentified hard plastic items were classified in this manner.\n",
    "\n",
    "* start_date = 2015-11-15\n",
    "* end_date = 2017-03-31\n",
    "\n",
    "__SLR:__ April 2017 - May 2018. Sampling campaign by the WWF. Objects less than 2.5 cm were not counted.\n",
    "\n",
    "* start_date = 2017-04-01\n",
    "* end_date = 2020-03-31\n",
    "\n",
    "__IQAASL:__ April 2020 - May 2021. Sampling campaign mandated by the Swiss confederation. Additional codes were added for regional objects.\n",
    "\n",
    "* start_date = 2020-04-01\n",
    "* end_date = 2021-05-31\n",
    "\n",
    "__Plastock (not added yet):__ January 2022 - December 2022. Sampling campaign from the Association pour la Sauvegarde du Léman. Not all objects were counted, They only identified a limited number of objects.\n",
    "\n",
    "### Feature type\n",
    "\n",
    "The feature type is a label that applies to general conditions of use for the location and other locations in the region\n",
    "\n",
    "* r: rivers: surveys on river banks\n",
    "* l: lake: surveys on the lake shore\n",
    "* p: parcs: surveys in recreational areas\n",
    "\n",
    "### Parent boundary\n",
    "\n",
    "Designates the larger geographic region of the survey location. For lakes and rivers it is the name of the catchment area or river basin. For parcs it is the the type of park ie.. les Alpes. Recall that each feature has a name, for example Alpes Lépontines is the the name of a feature in the geographic region of _Les Alpes_.\n",
    "\n",
    "### Language\n",
    "\n",
    "The code descriptions are available in three languages\n",
    "\n",
    "* en: english\n",
    "* fr: french\n",
    "* de: german"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54148c36-ff96-4891-b230-479c5598f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_vitals(data):\n",
    "    total = data.quantity.sum()\n",
    "    median = data.pcs_m.median()\n",
    "    samples = data.loc_date.nunique()\n",
    "    ncodes = data.code.nunique()\n",
    "    nlocations = data.slug.nunique()\n",
    "    nbodies = data.feature_name.nunique()\n",
    "    ncities = data.city.nunique()\n",
    "    min_date = data[\"date\"].min()\n",
    "    max_date = data[\"date\"].max()\n",
    "    \n",
    "    return total, median, samples, ncodes, nlocations, nbodies, ncities, min_date, max_date\n",
    "\n",
    "def find_missing(more_than, less_than):\n",
    "    return np.setdiff1d(more_than, less_than)\n",
    "def find_missing_loc_dates(done, dtwo):\n",
    "    locs_one = done.loc_date.unique()\n",
    "    locs_two = dtwo.loc_date.unique()\n",
    "    return find_missing(locs_one, locs_two)\n",
    "\n",
    "def use_gfrags_gfoams_gcaps(data, codes,columns=[\"Gfoams\", \"Gfrags\", \"Gcaps\"]):\n",
    "    for col in columns:\n",
    "        change = codes.loc[codes.parent_code == col].index\n",
    "        data.loc[data.code.isin(change), \"code\"] = col\n",
    "        \n",
    "    return data\n",
    "\n",
    "def make_a_summary(vitals, add_summary_name=False):\n",
    "\n",
    "    a_summary = f\"\"\"\n",
    "    Number of objects: {vitals[0]}\n",
    "    \n",
    "    Median pieces/meter: {vitals[1]}\n",
    "    \n",
    "    Number of samples: {vitals[2]}\n",
    "    \n",
    "    Number of unique codes: {vitals[3]}\n",
    "    \n",
    "    Number of sample locations: {vitals[4]}\n",
    "    \n",
    "    Number of features: {vitals[5]}\n",
    "    \n",
    "    Number of cities: {vitals[6]}\n",
    "    \n",
    "    Start date: {vitals[7]}\n",
    "    \n",
    "    End date: {vitals[8]}\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if add_summary_name:\n",
    "        a_summary = f\"\"\"\n",
    "        Summary name = {add_summary_name}\n",
    "\n",
    "        {a_summary}\n",
    "        \"\"\"\n",
    "        \n",
    "    return a_summary\n",
    "def combine_survey_files(list_of_files):\n",
    "\n",
    "    files = []\n",
    "    for afile in list_of_files:\n",
    "        files.append(pd.read_csv(afile))\n",
    "    return pd.concat(files)\n",
    "\n",
    "def indexed_feature_data(file, index: str = \"code\"):\n",
    "    df = pd.read_csv(file)\n",
    "    df.set_index(index, drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# period dates\n",
    "period_dates = {\n",
    "    \"mcbp\":[\"2015-11-15\", \"2017-03-31\"],\n",
    "    \"slr\": [\"2017-04-01\", \"2020-03-31\"],\n",
    "    \"iqaasl\": [\"2020-04-01\", \"2021-05-31\"],\n",
    "    \"2022\": [\"2021-06-01\", \"2022-12-01\"]\n",
    "}\n",
    "code_cols = ['material', 'description', 'source', 'parent_code', 'single_use', 'groupname']\n",
    "\n",
    "group_by_columns = [\n",
    "    'loc_date', \n",
    "    'date', \n",
    "    'feature_name', \n",
    "    'slug',     \n",
    "    'parent_boundary',\n",
    "    'length',\n",
    "    'groupname',\n",
    "    'city',\n",
    "    'code', \n",
    "]\n",
    "agg_this = {\n",
    "    \"quantity\":\"sum\",\n",
    "    \"pcs_m\": \"sum\"\n",
    "}\n",
    "\n",
    "survey_data = [\n",
    "    \"data/end_process/after_may_2021.csv\",\n",
    "    \"data/end_process/iqaasl.csv\",\n",
    "    \"data/end_process/mcbp.csv\",\n",
    "    \"data/end_process/slr.csv\",\n",
    "]\n",
    "\n",
    "code_data =  \"data/end_process/codes.csv\"\n",
    "beach_data = \"data/end_process/beaches.csv\"\n",
    "land_cover_data = \"data/end_process/land_cover.csv\"\n",
    "land_use_data = \"data/end_process/land_use.csv\"\n",
    "street_data = \"data/end_process/streets.csv\"\n",
    "intersection_attributes = \"data/end_process/river_intersect_lakes.csv\"\n",
    "surveys = combine_survey_files(survey_data)\n",
    "codes = indexed_feature_data(code_data, index=\"code\")\n",
    "beaches = indexed_feature_data(beach_data, index=\"slug\")\n",
    "land_cover = pd.read_csv(land_cover_data)\n",
    "land_use = pd.read_csv(land_use_data)\n",
    "streets = pd.read_csv(street_data)\n",
    "river_intersect_lakes = pd.read_csv(intersection_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8cad59-357b-4893-8a26-86b7150c24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the new code values to the results\n",
    "g_frag_foam = use_gfrags_gfoams_gcaps(surveys, codes)\n",
    "\n",
    "# separate the values greater than zero and the new code values\n",
    "gthan_zero = g_frag_foam[(g_frag_foam.quantity > 0) | (g_frag_foam.code.isin([\"Gfrags\", \"Gfoams\", \"Gcaps\"]))].copy()\n",
    "\n",
    "# separate the values = to zero and the codes that are not being changed\n",
    "t_t0 = g_frag_foam[(g_frag_foam.quantity == 0) & (~g_frag_foam.code.isin([\"Gfrags\", \"Gfoams\", \"Gcaps\"]))].copy()\n",
    "\n",
    "# group the codes that have a value greater\n",
    "t_ti = gthan_zero.groupby(group_by_columns, as_index=False).agg(agg_this)\n",
    "\n",
    "t_th = pd.concat([t_t0, t_ti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be22a0f3-17fe-4e3b-a77b-c4406777912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Number of objects: 196842\n",
      "    \n",
      "    Median pieces/meter: 0.0\n",
      "    \n",
      "    Number of samples: 1352\n",
      "    \n",
      "    Number of unique codes: 227\n",
      "    \n",
      "    Number of sample locations: 245\n",
      "    \n",
      "    Number of features: 59\n",
      "    \n",
      "    Number of cities: 142\n",
      "    \n",
      "    Start date: 2015-11-23\n",
      "    \n",
      "    End date: 2022-10-06\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "vitals_t = collect_vitals(t_th)\n",
    "print(make_a_summary(vitals_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b37056d-cf17-4d74-8e65-2e48c848e890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Number of objects: 196842\n",
      "    \n",
      "    Median pieces/meter: 0.0\n",
      "    \n",
      "    Number of samples: 1352\n",
      "    \n",
      "    Number of unique codes: 227\n",
      "    \n",
      "    Number of sample locations: 245\n",
      "    \n",
      "    Number of features: 59\n",
      "    \n",
      "    Number of cities: 142\n",
      "    \n",
      "    Start date: 2015-11-23\n",
      "    \n",
      "    End date: 2022-10-06\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "vitals_o = collect_vitals(surveys)\n",
    "print(make_a_summary(vitals_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fba949-faaf-45c5-a4b7-f0111a5c8872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: hammerdirt-analyst\n",
      "\n",
      "conda environment: cantonal_report\n",
      "\n",
      "pandas: 2.0.3\n",
      "numpy : 1.25.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a hammerdirt-analyst -co --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4090bf-97d6-42aa-8cfe-e2d6122df11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
