{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c16819-72da-4b47-a3aa-988d3f5a8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Type, Optional\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "from review_methods_tests import collect_vitals, find_missing, find_missing_loc_dates\n",
    "from review_methods_tests import use_gfrags_gfoams_gcaps, make_a_summary,combine_survey_files\n",
    "\n",
    "from setvariables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4558dc36-9186-4446-a24e-22cd22678f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_data_by_date(data: pd.DataFrame, start: str, end: str):\n",
    "    mask = (data.date >= start) & (data.date <= end)\n",
    "    return data[mask]\n",
    "\n",
    "def aggregate_dataframe(df: pd.DataFrame,\n",
    "                        groupby_columns: List[str],\n",
    "                        aggregation_functions: Dict[str, Union[str, callable]],\n",
    "                        index: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate specified columns in a Pandas DataFrame using given aggregation functions.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        groupby_columns (List[str]): List of column names to group by.\n",
    "        aggregation_functions (Dict[str, Union[str, callable]]): \n",
    "            A dictionary where keys are column names to aggregate, \n",
    "            and values are either aggregation functions (e.g., 'sum', 'mean', 'max', 'min')\n",
    "            or custom aggregation functions (callable functions).\n",
    "        index (bool, optional): Whether to use the groupby columns as an index.\n",
    "            Default is False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with aggregated values.\n",
    "    \"\"\"\n",
    "    grouped = df.groupby(groupby_columns, as_index=index).agg(aggregation_functions)\n",
    "    \n",
    "    return grouped\n",
    "    \n",
    "def merge_dataframes_on_column_and_index(left_df: pd.DataFrame,\n",
    "                                         right_df: pd.DataFrame,\n",
    "                                         left_column: str,\n",
    "                                         how: str = 'inner',\n",
    "                                         validate: str = 'many_to_one') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge two DataFrames where the left DataFrame is merged on a specified column and \n",
    "    the right DataFrame is merged on its index.\n",
    "\n",
    "    Args:\n",
    "        left_df (pd.DataFrame): The left DataFrame to be merged.\n",
    "        right_df (pd.DataFrame): The right DataFrame to be merged on its index.\n",
    "        left_column (str): The column in the left DataFrame to merge on.\n",
    "        how (str, optional): The type of merge to be performed ('left', 'right', 'outer', or 'inner'). \n",
    "            Default is 'inner'.\n",
    "        validate (str, optional): Whether to perform merge validation checks. \n",
    "            Default is 'many_to_one'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame resulting from the merge operation.\n",
    "    \"\"\"\n",
    "  \n",
    "    merged_df = left_df.merge(right_df, left_on=left_column, right_index=True, how=how)\n",
    "    return merged_df\n",
    "\n",
    "def get_top_x_records_with_max_quantity(df: pd.DataFrame, quantity_column: str, id_column: str, x: int):\n",
    "    \"\"\"\n",
    "    Get the top x records with the greatest quantity and their associated ID from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        quantity_column (str): The name of the quantity column.\n",
    "        id_column (str): The name of the ID column.\n",
    "        x (int): The number of records to return.\n",
    "\n",
    "    Returns:\n",
    "        A data frame\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by the quantity column in descending order, take the top x records, and select the ID column\n",
    "    top_x_records = df.nlargest(x, quantity_column)[[id_column, quantity_column]]\n",
    "    top_x_records[\"%\"] = top_x_records[quantity_column]/top_x_records[quantity_column].sum()\n",
    "    return top_x_records[[id_column, quantity_column, \"%\"]]\n",
    "\n",
    "def calculate_object_occurrence_rates(df: pd.DataFrame,\n",
    "                                      objects_to_check: List[str],\n",
    "                                      y: int,\n",
    "                                      j: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate the rate of occurrence for each object in a group of objects 'X' for a given quantity 'y' and number of samples 'j'\n",
    "    from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'sample,' 'object,' and 'quantity.'\n",
    "        objects_to_check (List[str]): The list of objects to calculate occurrence rates for.\n",
    "        y (int): The minimum quantity required for objects to be considered.\n",
    "        j (int): The total number of samples.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: A dictionary where keys are objects and values are the rates of occurrence for each object.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame to include rows where 'object' is in 'objects_to_check' and quantity is greater than or equal to 'y'\n",
    "    filtered_df = df[(df['code'].isin(objects_to_check)) & (df['quantity'] >= y)]\n",
    "\n",
    "    # Calculate the occurrence rates for each object\n",
    "    occurrence_rates = {}\n",
    "    for obj in objects_to_check:\n",
    "        object_filtered_df = filtered_df[filtered_df['code'] == obj]\n",
    "        rate = len(object_filtered_df) / j if j > 0 else 0\n",
    "        occurrence_rates[obj] = rate\n",
    "\n",
    "    return occurrence_rates\n",
    "\n",
    "def calculate_quantity_proportions(df: pd.DataFrame,\n",
    "                                   objects_to_check: List[str]\n",
    "                                   ) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate the proportion of the quantity of each object in a group of objects from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'sample,' 'object,' and 'quantity.'\n",
    "        objects_to_check (List[str]): The list of objects to calculate proportions for.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: A dictionary where keys are objects and values are their quantity proportions.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame to include rows where 'object' is in 'objects_to_check'\n",
    "    filtered_df = df[df['code'].isin(objects_to_check)]\n",
    "\n",
    "    # Calculate the total quantity for each object\n",
    "    object_quantities = filtered_df.groupby('code')['quantity'].sum().to_dict()\n",
    "\n",
    "    # Calculate the proportion for each object\n",
    "    total_quantity = df.quantity.sum()\n",
    "    proportions = {obj: quantity / total_quantity for obj, quantity in object_quantities.items()}\n",
    "\n",
    "    return proportions\n",
    "\n",
    "def calculate_rate_per_unit(df: pd.DataFrame,\n",
    "                            objects_to_check: List[str],\n",
    "                            column_of_interest: str = \"code\",\n",
    "                            groupby_columns: List[str] = ['code'],\n",
    "                            unit_measurement: str = \"pcs_m\",\n",
    "                            method: Dict[str, str] = {\"pcs_m\": \"median\"},\n",
    "                            ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the rate of occurence of object(s) for a given unit measurement.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'sample,' 'object,' and 'quantity.'\n",
    "        objects_to_check (List[str]): The list of objects to calculate proportions for.\n",
    "        column_of_interest (str): The column label of the objects being compared.\n",
    "        groupby_columns Dict[str]: The columns used for the aggregation.\n",
    "        unit_measurement (str): The column labe of the unit of measurement.\n",
    "        method (Dict[str]): Dictionary specifying the aggregation functions for the unit_measurement.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe where index is column_of_interest and the value column is the rate.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame to include rows where 'object' is in 'objects_to_check'\n",
    "    filtered_df = df[df[column_of_interest].isin(objects_to_check)]\n",
    "\n",
    "    # Calculate the total quantity for each object\n",
    "    object_rates = filtered_df.groupby(groupby_columns, as_index=False)[rate].agg(method)\n",
    "\n",
    "    # Calculate the proportion for each object\n",
    "    rates = object_rates[[column_of_interest, rate]].set_index(column_of_interest, drop=True)\n",
    "    \n",
    "\n",
    "    return rates\n",
    "\n",
    "\n",
    "\n",
    "def count_objects_with_positive_quantity(df: pd.DataFrame) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Count how many times each object had a quantity greater than zero in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'sample,' 'object,' and 'quantity.'\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series with the count of positive quantity occurrences for each object.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame to include rows where quantity is greater than zero\n",
    "    positive_quantity_df = df[df['quantity'] > 0]\n",
    "    no_count_df = df[(df['quantity'] == 0)]\n",
    "\n",
    "    # Count the occurrences of positive quantities for each object\n",
    "    object_counts = positive_quantity_df['code'].value_counts()\n",
    "    failed = object_counts/df.loc_date.nunique()\n",
    "    no_counts = no_count_df['code'].value_counts()\n",
    "    zeroes = no_counts[~no_counts.index.isin(object_counts.index)]\n",
    "    zeroes.loc[:] = 0\n",
    "\n",
    "    return pd.concat([failed, zeroes])\n",
    "\n",
    "def aggregate_boundaries(df: pd.DataFrame, unit_columns: list, unit_agg: dict, boundary_labels: list, boundary_columns: list, group_agg: dict)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate data from a dataframe by boundaries and groups.\n",
    "\n",
    "    Aggregates a dataframe in two steps. First, it performs\n",
    "    aggregation at the 'unit' level defined by 'unit_columns' and 'unit_agg' to obtain\n",
    "    test statistics. Then, it aggregates these 'unit' statistics further at the\n",
    "    'boundary' level defined by 'boundary_labels' and 'boundary_columns', and computes\n",
    "    the test statistics for each boundary.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing data to be aggregated.\n",
    "        unit_columns (list): List of columns for 'unit' level aggregation.\n",
    "        unit_agg (dict): Dictionary specifying the aggregation functions for 'unit' level.\n",
    "        boundary_labels (list): List of boundary labels to define 'boundaries' for further aggregation.\n",
    "        boundary_columns (list): List of columns for 'boundary' level aggregation.\n",
    "        group_agg (dict): Dictionary specifying the aggregation functions for 'boundary' level.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing aggregated data at the 'boundary' level with\n",
    "        additional 'label' column indicating the boundary label. \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    unit_aggregate = aggregate_dataframe(code_result_df.copy(), unit_columns, unit_agg)\n",
    "    boundary_summaries = []\n",
    "    for label in boundary_labels:\n",
    "        boundary_mask = unit_aggregate.parent_boundary == label\n",
    "        boundary_aggregate = unit_aggregate[boundary_mask].groupby(boundary_columns, as_index=False).agg(agg_groups)\n",
    "        boundary_aggregate['label'] = label\n",
    "        boundary_summaries.append(boundary_aggregate)\n",
    "\n",
    "    return pd.concat(boundary_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca0862-a1e5-4fd3-ae17-65ac2fd7cd0a",
   "metadata": {},
   "source": [
    "# Testing data models\n",
    "\n",
    "The methods used in the version of the federal report were tested, but their was not a specific set of validation criteria beforehand. Test were done as the work progressed. This wasted alot of time\n",
    "\n",
    "here we test the land use and survey data models.\n",
    "\n",
    "1. is the land use data complete for each survey location?\n",
    "2. does the survey data aggregate correctly to sample level?\n",
    "   * what happens to objects with a quantity of zero?\n",
    "   * aggregating to cantonal, municipal or survey area\n",
    "     * are all locations included?\n",
    "     * are lakes and rivers distinguished?\n",
    "3. Does the aggregated data for iqaasl match the federal report?\n",
    "\n",
    "### Gfoams, Gfrags, Gcaps\n",
    "\n",
    "These are aggregate groups. It is difficult to infer how well a participant differentiates between size or use of the following codes.\n",
    "\n",
    "1. Gfrags: G79, G78, G75\n",
    "2. Gfoams: G81, G82, G76\n",
    "3. Gcaps: G21, G22, G23, G24\n",
    "\n",
    "These aggregate groups are used when comparing values between sampling campaigns.\n",
    "\n",
    "### Sampling campaigns\n",
    "\n",
    "The dates of the sampling campaigns are expanded to include the surveys that happened between large organized campaigns. The start and end dates are defined below.\n",
    "\n",
    "__Attention!!__ The codes used for each survey campaign are different. Different groups organized and conducted surveys using the MLW protocol. The data was then sent to us.\n",
    "\n",
    "__MCBP:__ November 2015 - November 2016. The initial sampling campaign. Fragmented plastics (Gfrags/G79/G78/G76) were not sorted by size. All unidentified hard plastic items were classified in this manner.\n",
    "\n",
    "* start_date = 2015-11-15\n",
    "* end_date = 2017-03-31\n",
    "\n",
    "__SLR:__ April 2017 - May 2018. Sampling campaign by the WWF. Objects less than 2.5 cm were not counted.\n",
    "\n",
    "* start_date = 2017-04-01\n",
    "* end_date = 2020-03-31\n",
    "\n",
    "__IQAASL:__ April 2020 - May 2021. Sampling campaign mandated by the Swiss confederation. Additional codes were added for regional objects.\n",
    "\n",
    "* start_date = 2020-04-01\n",
    "* end_date = 2021-05-31\n",
    "\n",
    "__Plastock (not added yet):__ January 2022 - December 2022. Sampling campaign from the Association pour la Sauvegarde du Léman. Not all objects were counted, They only identified a limited number of objects.\n",
    "\n",
    "### Feature name\n",
    "\n",
    "The feature name is the name of a river lake or other regional label that you would find on a map. People in the region know the name.\n",
    "\n",
    "### Feature type\n",
    "\n",
    "The feature type is a label that applies to general conditions of use for the location and other locations in the region\n",
    "\n",
    "* r: rivers: surveys on river banks\n",
    "* l: lake: surveys on the lake shore\n",
    "* p: parcs: surveys in recreational areas\n",
    "\n",
    "### Parent boundary\n",
    "\n",
    "Designates the larger geographic region of the survey location. For lakes and rivers it is the name of the catchment area or river basin. For parcs it is the the type of park ie.. les Alpes. Recall that each feature has a name, for example Alpes Lépontines is the the name of a feature in the geographic region of _Les Alpes_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54148c36-ff96-4891-b230-479c5598f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys = combine_survey_files(survey_data)\n",
    "codes = pd.read_csv(code_data).set_index(\"code\")\n",
    "beaches = pd.read_csv(beach_data).set_index(\"slug\")\n",
    "land_cover = pd.read_csv(land_cover_data)\n",
    "land_use = pd.read_csv(land_use_data)\n",
    "streets = pd.read_csv(street_data)\n",
    "river_intersect_lakes = pd.read_csv(intersection_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e61c05f-baa2-4e9f-91ab-4d6840198579",
   "metadata": {},
   "source": [
    "## Aggregate a set of data by sample (location and date)\n",
    "\n",
    "Use the loc_date column in the survey data. Use the IQAASL period and four river baisns test against the federal report.\n",
    "\n",
    "### Before aggregating does the number of locations, cities, samples and quantity match the federal report?\n",
    "\n",
    "__The feature types include lakes and rivers, alpes were condsidered separately__\n",
    "\n",
    "From https://hammerdirt-analyst.github.io/IQAASL-End-0f-Sampling-2021/lakes_rivers.html#\n",
    "\n",
    "1. cities = yes\n",
    "2. samples = yes\n",
    "3. locations = yes\n",
    "4. quantity = No it is short 50 pieces\n",
    "5. start and end date = yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bed0606-48a3-4d23-8de3-330e10b6f140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Number of objects: 54694\n",
      "    \n",
      "    Median pieces/meter: 0.0\n",
      "    \n",
      "    Number of samples: 386\n",
      "    \n",
      "    Number of unique codes: 235\n",
      "    \n",
      "    Number of sample locations: 143\n",
      "    \n",
      "    Number of features: 28\n",
      "    \n",
      "    Number of cities: 77\n",
      "    \n",
      "    Start date: 2020-03-08\n",
      "    \n",
      "    End date: 2021-05-12\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# startint varaibles\n",
    "period = \"iqaasl\"\n",
    "survey_areas = [\"rhone\", \"ticino\", \"linth\", \"aare\"]\n",
    "start, end = [*period_dates[period]]\n",
    "\n",
    "# the surveys from the survey areas of intersest\n",
    "survey_data = surveys[surveys.parent_boundary.isin(survey_areas)].copy()\n",
    "\n",
    "# the survey data sliced by the start and end data\n",
    "feature_d= slice_data_by_date(survey_data.copy(), start, end)\n",
    "\n",
    "# convert codes to gfrags, gcaps and gfoams\n",
    "feature_data = use_gfrags_gfoams_gcaps(feature_d.copy(), codes)\n",
    "\n",
    "# check the numbers\n",
    "feature_vitals = collect_vitals(feature_d)\n",
    "print(make_a_summary(feature_vitals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57569da8-0cbe-4acc-bfbd-95d660052c5e",
   "metadata": {},
   "source": [
    "### Number of lakes, rivers, parcs, cities and cantons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8bc084a-579d-4da4-a147-11f4f7c21ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canton</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aargau</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bern</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fribourg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genève</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glarus</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luzern</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuchâtel</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schwyz</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solothurn</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St. Gallen</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticino</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valais</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vaud</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zug</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zürich</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature_name  feature_type  city\n",
       "canton                                      \n",
       "Aargau                 2             1     4\n",
       "Bern                   7             2    21\n",
       "Fribourg               1             1     2\n",
       "Genève                 2             2     2\n",
       "Glarus                 3             2     2\n",
       "Luzern                 1             1     1\n",
       "Neuchâtel              2             1     4\n",
       "Schwyz                 1             1     1\n",
       "Solothurn              1             1     2\n",
       "St. Gallen             5             2     5\n",
       "Ticino                 5             2     7\n",
       "Valais                 2             2     6\n",
       "Vaud                   4             2    14\n",
       "Zug                    2             2     2\n",
       "Zürich                 4             2     6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = feature_data.slug.unique()\n",
    "feature_columns = [\"feature_name\", \"feature_type\", \"city\"]\n",
    "beaches.loc[locations].groupby(\"canton\").agg({x:\"nunique\" for x in feature_columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec69cc1-b826-47a6-a2fc-abe599e4481c",
   "metadata": {},
   "source": [
    "### aggregate to sample\n",
    "\n",
    "The assessments are made on a per sample basis. That means that we can look at an individual object value at each sample. The sum of all the individual objects in a survey is the total for that survey. Dividing the totals by the length of the survey gives the assessment metric: _pieces of trash per meter_.\n",
    "\n",
    "1. Are the quantiles of the current data  = to the federal report? Yes\n",
    "2. Are the material totals = to the federal report? No,plastics if off by 50 pcs\n",
    "3. Are the fail rates of the most common objects = to the federal report? Yes\n",
    "4. Is the % of total of the most common objects = to the fedral report? yes\n",
    "5. Is the median pieces/meter of the most common objects = to the federal report? yes\n",
    "6. Is the quantity of the most common objects = to the federal report? yes\n",
    "\n",
    "#### The summary of survey totals\n",
    "\n",
    "fig 1.5 in IQAASL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfec738d-1a5b-4e14-98a5-765cd0a285b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcs_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>386.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.952073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.063422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.822500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>54694.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pcs_m\n",
       "count    386.000000\n",
       "mean       3.952073\n",
       "std        7.063422\n",
       "min        0.020000\n",
       "25%        0.822500\n",
       "50%        1.895000\n",
       "75%        3.865000\n",
       "max       66.170000\n",
       "total  54694.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when the codes are changed to gfrags, gfoams and gcaps that creates \n",
    "# multiple code results for the same code at the same sample\n",
    "# note that the code_result_columns do not have the groupname column\n",
    "# this is because the code is changed and not the groupname\n",
    "\n",
    "code_result_df = aggregate_dataframe(feature_data.copy(), code_result_columns, unit_agg)\n",
    "code_result_df = code_result_df.merge(codes.groupname, left_on=\"code\", right_index=True)\n",
    "\n",
    "# aggregate the code totals on the sample day and check against the federal report\n",
    "sample_totals = aggregate_dataframe(code_result_df.copy(), [\"loc_date\", \"slug\", \"parent_boundary\"], unit_agg)\n",
    "sample_summary = sample_totals.pcs_m.describe()\n",
    "sample_summary[\"total\"] = sample_totals.quantity.sum()\n",
    "pd.DataFrame(sample_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6dd92c-60b1-47e9-a99f-036f0ab37272",
   "metadata": {},
   "source": [
    "#### Material totals and proportions\n",
    "\n",
    "fig 1.5 iqaal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92698c51-4640-41d1-be48-466c177d65f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>quantity</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chemicals</td>\n",
       "      <td>140</td>\n",
       "      <td>0.002560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cloth</td>\n",
       "      <td>343</td>\n",
       "      <td>0.006271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glass</td>\n",
       "      <td>2919</td>\n",
       "      <td>0.053370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>metal</td>\n",
       "      <td>1874</td>\n",
       "      <td>0.034263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper</td>\n",
       "      <td>1527</td>\n",
       "      <td>0.027919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>plastic</td>\n",
       "      <td>47093</td>\n",
       "      <td>0.861027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rubber</td>\n",
       "      <td>390</td>\n",
       "      <td>0.007131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unidentified</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wood</td>\n",
       "      <td>406</td>\n",
       "      <td>0.007423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       material  quantity         %\n",
       "0     chemicals       140  0.002560\n",
       "1         cloth       343  0.006271\n",
       "2         glass      2919  0.053370\n",
       "3         metal      1874  0.034263\n",
       "4         paper      1527  0.027919\n",
       "5       plastic     47093  0.861027\n",
       "6        rubber       390  0.007131\n",
       "7  unidentified         2  0.000037\n",
       "8          wood       406  0.007423"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the material label to each code\n",
    "merged_result = merge_dataframes_on_column_and_index(code_result_df.copy(), codes[\"material\"], 'code', how='inner', validate=True)\n",
    "\n",
    "# sum the materials for the data frame\n",
    "materials = aggregate_dataframe(merged_result.copy(), [\"material\"], {\"quantity\":\"sum\"})\n",
    "materials[\"%\"] = materials.quantity/materials.quantity.sum()\n",
    "materials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c5091-d3cd-45b3-b18f-43bffca65c11",
   "metadata": {},
   "source": [
    "#### Quantity, median pcs/m, fail rate, and % of total\n",
    "\n",
    "fig 1.6 iqaasl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f996669d-61fb-480f-849b-a14acda37a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>quantity</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>G27</td>\n",
       "      <td>8485</td>\n",
       "      <td>0.155136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Gfrags</td>\n",
       "      <td>7400</td>\n",
       "      <td>0.135298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Gfoams</td>\n",
       "      <td>5559</td>\n",
       "      <td>0.101638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>G30</td>\n",
       "      <td>3325</td>\n",
       "      <td>0.060793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>G67</td>\n",
       "      <td>2534</td>\n",
       "      <td>0.046330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>G712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>G713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>G88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>G180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       code  quantity         %\n",
       "111     G27      8485  0.155136\n",
       "225  Gfrags      7400  0.135298\n",
       "224  Gfoams      5559  0.101638\n",
       "115     G30      3325  0.060793\n",
       "147     G67      2534  0.046330\n",
       "..      ...       ...       ...\n",
       "162    G712         0  0.000000\n",
       "163    G713         0  0.000000\n",
       "169     G88         0  0.000000\n",
       "78     G180         0  0.000000\n",
       "0        G1         0  0.000000\n",
       "\n",
       "[226 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum the cumulative quantity for each code and calculate the median pcs/meter\n",
    "code_totals = aggregate_dataframe(code_result_df.copy(), [\"code\"], {\"quantity\":\"sum\", \"pcs_m\":\"median\"})\n",
    "\n",
    "# find the top ten codes\n",
    "abundant = get_top_x_records_with_max_quantity(code_totals.copy(), \"quantity\", \"code\", len(code_totals))\n",
    "abundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdc90cf-53dd-4e73-9c36-d50c2e9ff157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>quantity</th>\n",
       "      <th>%</th>\n",
       "      <th>fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>G27</td>\n",
       "      <td>8485</td>\n",
       "      <td>0.155136</td>\n",
       "      <td>0.878238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Gfrags</td>\n",
       "      <td>7400</td>\n",
       "      <td>0.135298</td>\n",
       "      <td>0.862694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Gfoams</td>\n",
       "      <td>5559</td>\n",
       "      <td>0.101638</td>\n",
       "      <td>0.686528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>G30</td>\n",
       "      <td>3325</td>\n",
       "      <td>0.060793</td>\n",
       "      <td>0.852332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>G67</td>\n",
       "      <td>2534</td>\n",
       "      <td>0.046330</td>\n",
       "      <td>0.696891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>G712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>G713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>G88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>G180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       code  quantity         %      fail\n",
       "111     G27      8485  0.155136  0.878238\n",
       "225  Gfrags      7400  0.135298  0.862694\n",
       "224  Gfoams      5559  0.101638  0.686528\n",
       "115     G30      3325  0.060793  0.852332\n",
       "147     G67      2534  0.046330  0.696891\n",
       "..      ...       ...       ...       ...\n",
       "162    G712         0  0.000000  0.000000\n",
       "163    G713         0  0.000000  0.000000\n",
       "169     G88         0  0.000000  0.000000\n",
       "78     G180         0  0.000000  0.000000\n",
       "0        G1         0  0.000000  0.000000\n",
       "\n",
       "[226 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify the objects that were found in at least 50% of the samples\n",
    "# calculate the quantity per sample for each code and sample\n",
    "occurrences = aggregate_dataframe(code_result_df, [\"loc_date\", \"code\"], {\"quantity\":\"sum\"})\n",
    "\n",
    "# count the number of times that any object was found and\n",
    "# and divide it by the total number of samples \n",
    "event_counts  = count_objects_with_positive_quantity(occurrences)\n",
    "\n",
    "# select the objects that were found in at least 50% of the surveys\n",
    "abundant[\"fail\"] = abundant.code.apply(lambda x: event_counts.loc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e34f8d-f665-4c86-a9cf-44cbc39ef7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundant.sort_values(by=\"quantity\", inplace=True, ascending=False)\n",
    "abundant.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd31a37-c5a7-40ec-9a8e-413a661530be",
   "metadata": {},
   "source": [
    "### The most common objects\n",
    "\n",
    "fig 1.6 iqaasl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "136b5ef1-7a8b-4bf0-8a64-e68d46e9b30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>quantity</th>\n",
       "      <th>%</th>\n",
       "      <th>fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G27</td>\n",
       "      <td>8485</td>\n",
       "      <td>0.155136</td>\n",
       "      <td>0.878238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gfrags</td>\n",
       "      <td>7400</td>\n",
       "      <td>0.135298</td>\n",
       "      <td>0.862694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gfoams</td>\n",
       "      <td>5559</td>\n",
       "      <td>0.101638</td>\n",
       "      <td>0.686528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G30</td>\n",
       "      <td>3325</td>\n",
       "      <td>0.060793</td>\n",
       "      <td>0.852332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G67</td>\n",
       "      <td>2534</td>\n",
       "      <td>0.046330</td>\n",
       "      <td>0.696891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G200</td>\n",
       "      <td>2136</td>\n",
       "      <td>0.039054</td>\n",
       "      <td>0.650259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G112</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.035982</td>\n",
       "      <td>0.308290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gcaps</td>\n",
       "      <td>1844</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.652850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G74</td>\n",
       "      <td>1656</td>\n",
       "      <td>0.030278</td>\n",
       "      <td>0.533679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G95</td>\n",
       "      <td>1406</td>\n",
       "      <td>0.025707</td>\n",
       "      <td>0.507772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code  quantity         %      fail\n",
       "0     G27      8485  0.155136  0.878238\n",
       "1  Gfrags      7400  0.135298  0.862694\n",
       "2  Gfoams      5559  0.101638  0.686528\n",
       "3     G30      3325  0.060793  0.852332\n",
       "4     G67      2534  0.046330  0.696891\n",
       "5    G200      2136  0.039054  0.650259\n",
       "6    G112      1968  0.035982  0.308290\n",
       "7   Gcaps      1844  0.033715  0.652850\n",
       "8     G74      1656  0.030278  0.533679\n",
       "9     G95      1406  0.025707  0.507772"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_most_common = abundant[(abundant.quantity > abundant.loc[10, \"quantity\" ]) | (abundant[\"%\"] >= 0.5)]\n",
    "the_most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a06c9-fbc2-4764-b7d7-9074b43df7d8",
   "metadata": {},
   "source": [
    "### Results by groupname and feature boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe56bb84-94e3-4b2e-8a7a-73228a0691b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>aare</th>\n",
       "      <th>linth</th>\n",
       "      <th>rhone</th>\n",
       "      <th>ticino</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groupname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>agriculture</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food and drink</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure</th>\n",
       "      <td>0.140</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro plastics (&lt; 5mm)</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packaging non food</th>\n",
       "      <td>0.090</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal items</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plastic pieces</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreation</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tobacco</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unclassified</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste water</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label                    aare  linth  rhone  ticino\n",
       "groupname                                          \n",
       "agriculture             0.060  0.030  0.140   0.060\n",
       "food and drink          0.250  0.280  0.700   0.280\n",
       "infrastructure          0.140  0.120  0.545   0.205\n",
       "micro plastics (< 5mm)  0.010  0.000  0.115   0.000\n",
       "packaging non food      0.090  0.130  0.205   0.075\n",
       "personal items          0.040  0.040  0.100   0.065\n",
       "plastic pieces          0.185  0.105  0.480   0.095\n",
       "recreation              0.060  0.040  0.165   0.035\n",
       "tobacco                 0.150  0.265  0.500   0.180\n",
       "unclassified            0.000  0.000  0.020   0.000\n",
       "waste water             0.030  0.005  0.190   0.020"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate by parent_boundary\n",
    "\n",
    "unit_columns = [\"parent_boundary\", \"loc_date\", \"groupname\"]\n",
    "boundary_columns = [\"groupname\"]\n",
    "boundary_labels = code_result_df.parent_boundary.unique()\n",
    "\n",
    "boundary_summaries = aggregate_boundaries(code_result_df.copy(), unit_columns, unit_agg, boundary_labels, boundary_columns, agg_groups)\n",
    "boundary_summaries.pivot(index=\"groupname\", columns=\"label\", values=\"pcs_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fba949-faaf-45c5-a4b7-f0111a5c8872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: hammerdirt-analyst\n",
      "\n",
      "conda environment: cantonal_report\n",
      "\n",
      "numpy : 1.25.2\n",
      "pandas: 2.0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a hammerdirt-analyst -co --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707fca05-4940-4cb6-8e2d-1b897aacd8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
