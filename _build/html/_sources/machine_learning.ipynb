{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c6bfd7-6b8a-4bec-82a4-2a34360f2ddb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from userdisplay import highlight_max, style_negative\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import session_config\n",
    "from session_config import  collect_survey_data, feature_variables\n",
    "from reports import make_report_objects, reports_and_forecast\n",
    "from reports import admin_report, features_present, histograms_standard\n",
    "from reports import ecdf_plots_standard, scatter_plot_standard\n",
    "from reports import labels_for_display, make_standard_report, make_report_objects\n",
    "# import userdisplay\n",
    "# import geospatial\n",
    "import gridforecast as gfcast\n",
    "import datetime as dt\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from featureevaluator import FeatureEvaluation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, TheilSenRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, VotingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from myst_nb import glue\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "datax = collect_survey_data()\n",
    "codes = pd.read_csv('data/end_process/codes.csv').set_index('code')\n",
    "\n",
    "# from use_cases example\n",
    "ooi = ['G10',  'G30', 'G31', 'G33', 'G34', 'G35', 'G8', 'G7', 'G6', 'G5', 'G4', 'G37', 'G2', 'G27', 'G25', 'G26', 'G11']\n",
    "# more refined search\n",
    "tobo_snacks = ['G27', 'G30', 'G35']\n",
    "# unidentified, plastic, different uses\n",
    "# udi = ['Gfrags', 'Gfoams']\n",
    "# industrial\n",
    "indus = ['G89', 'G67', 'G112', 'G93' , 'G66','G74', 'G72', 'G87', 'G65', 'G69', 'G68', 'G43', 'G41', 'G38', 'G36', 'G19', 'G17', 'Gfrags']\n",
    "\n",
    "# features\n",
    "land_covers = ['buildings', 'forest', 'undefined', 'public-services', 'recreation', 'streets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5472bb-35f0-4642-b5da-fb16e9a46920",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_feature_importance(best_model, model_name, X_test, y_test, X_train, y_train):\n",
    "\n",
    "    # the permuation importance of the variables\n",
    "    if model_name in ['Random Forest Regression', 'Linear Regression']:\n",
    "        perm_importance = permutation_importance(best_model, X_test, y_test, n_repeats=30, random_state=42)\n",
    "        perm_importance_df = pd.DataFrame({\n",
    "            'Feature': X_test.columns,\n",
    "            'Importance': perm_importance.importances_mean\n",
    "            }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    try:\n",
    "    # model feature importance\n",
    "        feature_importances_rf = best_model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': X_test.columns,\n",
    "            'Importance': feature_importances_rf\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        return feature_importance_df, perm_importance_df\n",
    "    except AttributeError:\n",
    "    # if feature importance not avaialable try the coefficients\n",
    "        try:\n",
    "            params = best_model.coef_\n",
    "            feature_importances_rf = params\n",
    "            feature_importance_df = pd.DataFrame({'feature':X_test.columns, 'Coeficient':feature_importances_rf})\n",
    "            return feature_importance_df, perm_importance_df\n",
    "        except AttributeError:\n",
    "            #return an empty DataFrame\n",
    "            return pd.DataFrame(), perm_importance_df\n",
    "\n",
    "def find_elbow_point(sse):\n",
    "    n_points = len(sse)\n",
    "    all_coords = np.vstack((range(n_points), sse)).T\n",
    "    first_point = all_coords[0]\n",
    "    last_point = all_coords[-1]\n",
    "\n",
    "    line_vec = last_point - first_point\n",
    "    line_vec_norm = line_vec / np.sqrt(np.sum(line_vec**2))\n",
    "\n",
    "    vec_from_first = all_coords - first_point\n",
    "    scalar_product = np.sum(vec_from_first * line_vec_norm, axis=1)\n",
    "    vec_from_first_parallel = np.outer(scalar_product, line_vec_norm)\n",
    "    vec_to_line = vec_from_first - vec_from_first_parallel\n",
    "\n",
    "    dist_to_line = np.sqrt(np.sum(vec_to_line**2, axis=1))\n",
    "    elbow_point = np.argmax(dist_to_line)\n",
    "    \n",
    "    return elbow_point + 1\n",
    "\n",
    "def filter_features(data, threshold: float = 0.2, terms: [] = None ):\n",
    "\n",
    "    filtered_columns = [col for col in terms if (data[col] > 0).mean() >= threshold]\n",
    "    return data[['pcs/m', 'canton', 'use', *filtered_columns]], filtered_columns\n",
    "    \n",
    "\n",
    "def determine_optimal_clusters(d):\n",
    "\n",
    "  \n",
    "    sse = []\n",
    "    k_range = range(1, 11)\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(d)\n",
    "        sse.append(kmeans.inertia_)\n",
    "    \n",
    "    optimal_k = find_elbow_point(sse)\n",
    "    return optimal_k, sse\n",
    "\n",
    "def kmeans_clustering(n_clusters, w_interactions: bool = False):\n",
    "    \n",
    "    kmeans = kmeans_plusplus(n_clusters=n_clusters, random_state=42)\n",
    "    \n",
    "        \n",
    "    d['clusters'] = kmeans.fit_predict(d)\n",
    "    some_features = [x for x in d.columns if x not in ['pcs/m','clusters', 'streets']]\n",
    "    \n",
    "    means = d.groupby(['clusters'])['pcs/m'].mean()\n",
    "    means_unscaled = self.unscale_target(means)\n",
    "    \n",
    "    counts = d.groupby(['clusters'])['pcs/m'].count()\n",
    "    \n",
    "    cluster_summary = d.groupby('clusters').agg({x:'mean' for x in some_features}).reset_index()\n",
    "    cluster_summary = self.unscale_values(cluster_summary, columns=some_features, w_interactions=w_interactions)\n",
    "    cluster_summary['pcs/m'] = means_unscaled\n",
    "    cluster_summary['samples'] = counts.values\n",
    "    cluster_summary = cluster_summary[['samples', 'pcs/m', *cluster_summary.columns[:-2]]]\n",
    "           \n",
    "    return cluster_summary, kmeans, d\n",
    "\n",
    "def unscale_target(means, ascaler):\n",
    "    means = means.values\n",
    "    means_shape = means.shape\n",
    "    if means.ndim == 1:\n",
    "        means = means.reshape(1, -1)\n",
    "\n",
    "    means_unscaled = ascaler.inverse_transform(means)\n",
    "        \n",
    "    means_unscaled.reshape(means_shape)\n",
    "    return means_unscaled[0]\n",
    "\n",
    "def perform_regression_analysis(d, features: [] = None, target_var: str = 'pcs/m'):\n",
    "    params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 4,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"loss\": \"huber\",\n",
    "        \"alpha\": .9\n",
    "       \n",
    "        }\n",
    "    these_models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest Regression': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting Regression': GradientBoostingRegressor(**params),\n",
    "        'Theil-Sen Regressor': TheilSenRegressor(random_state=42)\n",
    "        }\n",
    "      \n",
    "    \n",
    "    X = d[features]\n",
    "    y = d[target_var].values\n",
    "       \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    regression_results = []\n",
    "    best_model = None\n",
    "    best_r2 = -np.inf\n",
    "    the_name = None\n",
    "    \n",
    "    # sklearn - linear models        \n",
    "    for model_name, model in these_models.items():\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            regression_results.append({'Model': model_name, 'R²': r2, 'MSE': mse})\n",
    "            \n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_model = model\n",
    "                the_name = model_name\n",
    "    # bagging\n",
    "    bag_estimator = these_models[the_name]\n",
    "    bag = BaggingRegressor(estimator=bag_estimator)\n",
    "    bag.fit(X_train, y_train)\n",
    "    y_pred = bag.predict(X_test)\n",
    "    predictions = {\n",
    "        the_name: best_model.predict(X_test),\n",
    "        'Bagging': y_pred\n",
    "    }\n",
    "\n",
    "    regression_results.append({'Model': f'Bagging:{the_name}', 'R²': bag.score(X_test, y_test), 'MSE':mean_squared_error(y_test, y_pred)})\n",
    "    # voting\n",
    "\n",
    "    lnr = these_models['Linear Regression']\n",
    "    rf = these_models['Random Forest Regression']\n",
    "    gbr = these_models['Gradient Boosting Regression']\n",
    "    voting = VotingRegressor([('lnr', lnr), ('rf', rf), ('gbr', gbr)])\n",
    "    voting.fit(X_train, y_train)\n",
    "    y_pred = voting.predict(X_test)\n",
    "    predictions.update({'voting': y_pred})\n",
    "    \n",
    "    regression_results.append({'Model': 'Voting', 'R²': voting.score(X_test, y_test), 'MSE':mean_squared_error(y_test, y_pred)})    \n",
    "    \n",
    "    return regression_results, best_model, the_name, predictions, X_test, y_test, X_train, y_train\n",
    "\n",
    "def create_interaction_terms(data, interaction_terms=None, target='pcs/m'):\n",
    "    if interaction_terms is None:\n",
    "        interaction_terms = ['streets', 'public-services', 'recreation']\n",
    "    \n",
    "    \n",
    "    d_cols = [x for x in data.columns if x not in [target, 'use']]\n",
    "    interaction_data = {}\n",
    "    interaction_columns = []\n",
    "    # print(interaction_columns)\n",
    "    for col in d_cols:\n",
    "        if col not in interaction_terms:\n",
    "            feature_value = data[col].values\n",
    "            interaction_name = f'{col}'\n",
    "            for term in interaction_terms:\n",
    "                feature_value += data[col].values * data[term].values\n",
    "                interaction_name += f'_inter_{term}'\n",
    "                \n",
    "            interaction_data[interaction_name] = feature_value\n",
    "            interaction_columns.append(interaction_name)\n",
    "    \n",
    "    interaction_data = pd.DataFrame(interaction_data)\n",
    "    interaction_data[target] = data[target]\n",
    "    interaction_data['use'] = data['use']\n",
    "    return interaction_data, interaction_columns\n",
    "\n",
    "\n",
    "\n",
    "def clusters_by_use_case(cluster_data, use: str = 'pro', scaled_cols: [] = None, columns_to_cluster: [] = None, interaction_terms: bool = False):\n",
    "\n",
    "    if interaction_terms:\n",
    "        print(scaled_cols)\n",
    "        cluster_p = cluster_data[cluster_data.use == use].copy()\n",
    "        nclusters = determine_optimal_clusters(cluster_p[columns_to_cluster])\n",
    "        kmeans = KMeans(n_clusters=nclusters[0], random_state=42).fit(cluster_p[columns_to_cluster])\n",
    "        cluster_p['cluster'] = kmeans.labels_\n",
    "        scaler = int_minmax.fit(cluster_p[scaled_cols])\n",
    "        cluster_p.loc[:, scaled_cols] = scaler.transform(cluster_p[scaled_cols])\n",
    "        cluster_p['pcs/m'] = interaction_target.inverse_transform(cluster_p['pcs/m'].values.reshape(-1,1))\n",
    "        df = cluster_p.drop_duplicates('cluster').sort_values('cluster').set_index('cluster', drop=True)\n",
    "        pcs_m = cluster_p.groupby(['use', 'cluster'], as_index=False).agg({'pcs/m': 'mean'}).set_index('cluster', drop=True)\n",
    "        samps = cluster_p.groupby(['use', 'cluster'], as_index=False).agg({'pcs/m': 'count'}).rename(columns={'pcs/m':'nsamples'}).set_index('cluster', drop=True)\n",
    "        pcs_m['nsamps'] =samps.nsamples.values\n",
    "        df = pcs_m.merge(df[columns_to_cluster], left_index=True, right_index=True)\n",
    "    else:    \n",
    "\n",
    "        cluster_p = cluster_data[cluster_data.use == use].copy()\n",
    "        nclusters = determine_optimal_clusters(cluster_p[columns_to_cluster])\n",
    "        kmeans = KMeans(n_clusters=nclusters[0], random_state=42).fit(cluster_p[columns_to_cluster])\n",
    "        cluster_p['cluster'] = kmeans.labels_\n",
    "        cluster_p[scaled_cols] = feature_scaler.inverse_transform(cluster_p[scaled_cols])\n",
    "        cluster_p['pcs/m'] = target_scaler.inverse_transform(cluster_p['pcs/m'].values.reshape(-1,1))\n",
    "        cluster_p['streets'] = street_scaler.inverse_transform(cluster_p['streets'].values.reshape(-1,1))\n",
    "        scaler = MinMaxScaler().fit(cluster_p['streets'].values.reshape(-1,1))\n",
    "        cluster_p['streets'] = scaler.transform(cluster_p['streets'].values.reshape(-1,1))\n",
    "        df = cluster_p.drop_duplicates('cluster').sort_values('cluster').set_index('cluster', drop=True)\n",
    "        pcs_m = cluster_p.groupby(['use', 'cluster'], as_index=False).agg({'pcs/m': 'mean'}).set_index('cluster', drop=True)\n",
    "        samps = cluster_p.groupby(['use', 'cluster'], as_index=False).agg({'pcs/m': 'count'}).rename(columns={'pcs/m':'nsamples'}).set_index('cluster', drop=True)\n",
    "        pcs_m['nsamps'] =samps.nsamples.values\n",
    "        df = pcs_m.merge(df[columns_to_cluster], left_index=True, right_index=True)\n",
    "\n",
    "    return cluster_p, df\n",
    "\n",
    "\n",
    "\n",
    "def append_to_markdown(filename, content):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(content + \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_narrative_from_table(client, messages, model):\n",
    "   \n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        \n",
    "        messages=messages,\n",
    "        max_tokens=1100\n",
    "    )\n",
    "     \n",
    "    return response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "507138ef-b6e9-498a-ac9b-1009975ef9e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "o_dates = {'start':'2020-01-01', 'end':'2021-12-31'}\n",
    "prior_dates = {'start':'2015-11-15', 'end':'2019-12-31'}\n",
    "\n",
    "# 'Neuchâtel', 'Zürich', \n",
    "\n",
    "\n",
    "canton = 'Bern'\n",
    "this_feature_type = 'l'\n",
    "\n",
    "d= datax.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# make complete report\n",
    "params_l = {'canton':canton, 'date_range':o_dates, 'feature_type': this_feature_type}\n",
    "params_p = {'canton':canton, 'date_range':prior_dates, 'feature_type':this_feature_type}\n",
    "\n",
    "# set the parameters for the weighted prior\n",
    "# exclude records in the likelihood, set date range and feature type\n",
    "# make the land-use-inventory, exclude any likelihood values\n",
    "lu_catalogue = d[(d.canton != canton)&(d['date'] <= o_dates['end'])&(d.feature_type == 'l')].copy()\n",
    "catalog_surveys, catalog_features = make_report_objects(lu_catalogue)\n",
    "prior_feature = catalog_features.df_cat\n",
    "prior_feature['feature_type'] = 'l'\n",
    "\n",
    "\n",
    "# the prior and likelihood data from the region of interest\n",
    "all_data_of_interest = d[(d['date'] >= prior_dates['start']) & (d['date'] <= o_dates['end'])&(d.feature_type == 'l')].copy()\n",
    "all_data_of_interest = all_data_of_interest[all_data_of_interest.canton == 'Bern'].copy()\n",
    "\n",
    "# create a variable for different code group totals\n",
    "all_data_of_interest = all_data_of_interest[all_data_of_interest.code.isin([*indus, *tobo_snacks])].copy()\n",
    "\n",
    "all_data_of_interest_i = all_data_of_interest[all_data_of_interest.code.isin(indus)].copy()\n",
    "all_data_of_interest_i['use'] = 'pro'\n",
    "\n",
    "all_data_of_interest_p = all_data_of_interest[all_data_of_interest.code.isin(tobo_snacks)].copy()\n",
    "all_data_of_interest_p['use'] = 'pers'\n",
    "\n",
    "# all_data_of_interest_o = all_data_of_interest[~all_data_of_interest.code.isin([*tobo_snacks, *indus])].copy()\n",
    "# print(all_data_of_interest_o.quantity.sum())\n",
    "# all_data_of_interest_o['use'] = 'other'\n",
    "\n",
    "all_data_of_interest = pd.concat([all_data_of_interest_i, all_data_of_interest_p])\n",
    "\n",
    "all_data_of_interest.reset_index(inplace=True, drop=True)\n",
    "\n",
    "land_covers = ['buildings', 'forest', 'undefined', 'public-services', 'streets', 'orchards', 'use', 'canton', 'city', 'feature_name']\n",
    "\n",
    "all_report, all_land_use = make_report_objects(all_data_of_interest, info_columns = ['use', 'canton', 'city', 'feature_name'])\n",
    "\n",
    "\n",
    "args = {\n",
    "    'likelihood': {'canton':canton, 'date_range':o_dates},\n",
    "    'prior' : {'canton':canton, 'date_range':prior_dates},\n",
    "    'data' : all_data_of_interest.copy(),\n",
    "    'land-use-inventory' : prior_feature.copy()\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "combined_results = reports_and_forecast(args['likelihood'], args['prior'], ldata=args['data'])\n",
    "standard_combined = make_standard_report(combined_results, args)\n",
    "\n",
    "\n",
    "lake_report = combined_results['this_report']\n",
    "lake_prior_report = combined_results['prior_report']\n",
    "lake_land_use = combined_results['this_land_use']\n",
    "\n",
    "scaled_cols = ['public-services', 'buildings', 'forest', 'undefined', 'vineyards', 'orchards', 'streets', 'recreation']\n",
    "\n",
    "d = all_land_use.df_cont.copy()\n",
    "\n",
    "cluster_d, filtered_columns = filter_features(d.copy(), terms=scaled_cols)\n",
    "\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "feature_scaler = StandardScaler()\n",
    "street_scaler = StandardScaler()\n",
    "interaction_target = StandardScaler()\n",
    "interaction_scaler = StandardScaler()\n",
    "int_minmax = MinMaxScaler()\n",
    "\n",
    "cluster_i, i_columns = create_interaction_terms(cluster_d[['pcs/m', 'use', *filtered_columns]].copy())\n",
    "cluster_i[i_columns] = interaction_scaler.fit_transform(cluster_i[i_columns])\n",
    "cluster_i['pcs/m'] = interaction_target.fit_transform(cluster_i['pcs/m'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b1b15f-583c-40fc-a8c3-08ad51d1f276",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "lake_profile = lake_land_use.n_samples_per_feature()/lake_report.number_of_samples\n",
    "\n",
    "lake_rates = lake_land_use.rate_per_feature()\n",
    "lake_rate = \"### Objects per meter of shoreline by magnitude of feature\\n\" + lake_rates.to_markdown() + '\\n\\n\\n' + \"### Proportion of samples by magnitude of feature\\n\" + lake_profile.to_markdown()\n",
    "\n",
    "indus_code_defs = codes.loc[indus, 'en']\n",
    "pro_codes = (', ').join(indus_code_defs.values)\n",
    "\n",
    "rec_code_defs = codes.loc[tobo_snacks, 'en']\n",
    "rec_codes = (', ').join(rec_code_defs.values)\n",
    "\n",
    "\n",
    "d = lake_report.sample_results(info_columns=['use'])\n",
    "di = d.groupby(['use', 'sample_id']).agg(session_config.unit_agg)\n",
    "di = di.groupby(['use'])['pcs/m'].describe()\n",
    "di = di.to_markdown()\n",
    "\n",
    "# summary of sample results\n",
    "lake_combined_summary = all_report.sampling_results_summary.to_markdown()\n",
    "start, end = all_report.date_range['start'][:4], all_report.date_range['end'][:4]\n",
    "lc = lake_combined_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa617e9b-78a3-440a-b883-dba31121bf3c",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "\"\\n\\n## Litter surveys in Switzerland 2020-2021 - IQAASL\\n\\nIdentification, quantification and analysis of anthropogenic Swiss litter (IQAASL) is a project commissioned by the Swiss \\nFederal Office for the Environment to collect data concerning visible pollutants along Swiss lakes and rivers. All \\ndiscarded materials were collected and identified using litter survey techniques. in total there were 406 samples from 163 \\nlocations in 95 municipalities.\\n\\nThis report is a summary and analysis of the litter surveys conducted and the methods employed in Switzerland from March\\n2020 through August 2021. This sampling phase overlaps with the Swiss Litter Report (SLR) survey period, which ran\\nfrom April 2017 to March 2018. The SLR was the first project on a national level to use the standard protocol described in \\nthe Guide to monitoring beach litter or any other comparable method. This overlap allows the results of the \\npresent study to be compared with those of the SLR.\\n\\n## Lakes and rivers\\n\\nThe lakes and rivers were sampled from 2020-03 through 2021-05, a total of 54,744 objects were removed and classified over \\nthe course of 386 surveys. The survey locations were divided into survey areas for regional analysis and defined by the Aare, \\nRhône, Ticino and Linth/Limmat rivers. Surveys were conducted at 143 different locations, representing 77 municipalities. \\nThe total linear distance surveyed was 20 km with a surface area of 9 hectares and a total municipal population of 1.7 million.\\n\\nMost surveys were along lake shorelines (331 samples) as lakes offer more consistent and safe year-round access with \\nrespect to rivers. Additionally, lakes are large areas of reduced flow that receive input from multiple rivers, streams \\nand drainage systems providing ideal locations to assess the variety of objects in and around the water bodies.\\n\\nIn total 316 samples came from seven principal lakes in 3 major river basins. Twenty locations were selected to sample \\nmonthly for a twelve-month period with the exception of Lago Maggiore, which was sampled every three months. \\nSurveys were also conducted on Lago di Lugano, Lac des Quatre cantons, Brienzersee and Zugersee. In addition, there \\nwere 55 surveys on 16 rivers.\\n\\n### The sampling locations - type and description\\n\\nThe land use is reported as the percent of total area attributed to each land use category within a 1500m radius of the \\nsurvey location. The ratio of the number of samples completed at the different land use profiles is an indicator of the \\nenvironmental and economic conditions around the survey locations.\\n\\nThe land use around the survey locations had a higher attribution to buildings as opposed to agriculture and woods. For \\nexample, half of all the surveys had at least 37% of land use devoted to buildings as opposed to 19% for agriculture or \\n13% to woods. Land use devoted to recreation was at least 6% for half of all samples.\\n\\nThe length of the road network within the buffer zone differentiates between locations that have other wise similar land \\nuse characteristics. The length of road per buffer ranges from 13km to 212km, 50% of the surveys had less than 67km of road network.\\n\\nThe number of intersections ranges from zero to 23, 50% of the surveys had 3 or fewer intersections within 1500m of the \\nsurvey location. The size of the intersecting river or canal was not taken into consideration. Survey locations on rivers \\nhave zero intersections.\\n\\nThe population (not shown) is taken from statpop 2018 and represents the population of the municipality surrounding the \\nsurvey location. The smallest population was 442 and the maximum was 415,367, 50% of the surveys come from \\nmunicipalities with a population of at least 12,812.\\n\\nOverall, surveys at locations with more buildings and more recreation sites were more likely to facilitate the accumulation \\nof trash on the shoreline. When the most common objects are considered, only four of the twelve were found at higher rates \\nin the presence of more buildings. All of those objects are likely related to food or tobacco consumption near the location. \\nSuggesting that there are still gains to be made in prevention and attenuation efforts in areas of high traffic near the water.\\n\\nHowever, six of the twelve objects have no positive association to land use attributed to buildings but were found in at \\nleast 50% of all the surveys. These objects are generally associated with professional use or in the case of cotton swabs \\npersonal hygiene:\\n\\n* plastic construction waste\\n* fragmented plastics\\n* industrial sheeting\\n* expanded polystyrene\\n* cotton bud/swabs\\n* insulation, includes spray foams\\n\\nFurthermore, compared to products related to tobacco or food consumption these objects have fewer positive associations in \\ngeneral. Indicating that the appropriate land use feature is not currently accounted for and/or these objects are found \\nat similar quantities indifferent of the land use features. Suggesting that these objects are ubiquitous in the environment.\\n\\nFinally, two of the twelve most common objects were found in less than 50% of the surveys and have few positive associations:\\n\\n* industrial pellets\\n* expanded foams < 5mm\\n\\nThese objects are found in large quantities sporadically at specific locations. They have been found in all survey areas \\nand in all lakes. Industrial pellets have a very specific use and client base making it possible to find partners based \\non the density of the pellets found and the location of the nearest consumer or producer of pellets, see Shared responsibility.\\n\\n### Median survey total\\n\\nThe results are in units of pieces of litter per 100 meters (p/100m). The median survey result of all data was approximately\\n189 p/100m. The maximum recorded value was 6,617 p/100m (Rhône survey area) and the minimum recorded was 2p/100m (Aare survey area).\\nThe Rhône survey area had the highest median survey total of 442p/100m, this can in part be explained by the high number\\nof urban survey locations with respect to the other survey areas and the deposition of fragmented plastics and foamed \\nplastics at the Rhône River out flow in the upper lake region.\\n\\nA reference value was calculated excluding the results from samples that were less than 10m and objects less than 2.5cm. \\nThis method, described in EU Marine Beach Litter Baselines was used to calculate the reference and threshold \\nvalues for all European beaches in 2015 and 2016 resulting in a median value of 131 p/100m. The results from the European \\nbaseline value lie outside the 95% confidence interval (CI) of 147 - 213p/100m established using the data from IQAASL.\\n\\nSurveys in Switzerland were on average, smaller scale than in marine environments and in locations that would be \\nconsidered urban under most circumstances. To date monitoring of lakes and rivers upstream of coastal regions has \\nnot generalized on the European continent. However, there is a concerted effort by a group of associations in \\nSwitzerland and France to establish a common monitoring and data exchange protocol for the Rhône basin. Additionally, \\nthe Wageningen University & Research has begun analyzing data collected in the Meusse - Rhine delta using \\nprotocols like those in IQAASL.\\n\\n### The most common objects\\n\\nThe most common objects are defined as those objects identified in at least 50% of all surveys and/or are among the ten \\nmost abundant by quantity. As a group the most common objects represent 68% of all objects identified in the sampling period. \\nOf the most common items 27% are food, drink and tobacco related and 24% are infrastructure and agriculture related.\\n\\nObjects related to food, drink and tobacco are identified at higher rates at survey locations with a greater percentage \\nof land attributed to buildings or fixed infrastructure, the inverse is true of the locations with a higher percentage \\nof land attributed to woods or agriculture. However, infrastructure material and fragmented plastics, are found at similar \\nrates throughout all survey areas indifferent of land use surrounding the survey locations.\\n\\nThe most common objects identified in the surveys were:\\n\\n* cigarette ends: total 8'485, % of all objects 15.5%, fail-rate 87%, p/100m 20\\n* fragmented plastics: total 7'400, 13% of all objects, fail-rate 86%, p/100m 18\\n* expanded polystyrene: total 5'563, 10% of all objects, fail-rate 68%, p/100m ,\\n* snack wrappers: total 3'325, 6% of all objects, fail-rate 85%, p/100m 9\\n* industrial sheeting: total 2'534, 4% of all objects, fail-rate 69%, p/100m 5\\n* glass drink bottles, pieces: total 2'136, 3% of all objects, fail-rate 65%, p/100m 3\\n* industrial pellets: total 1'968, 3% of all objects, fail-rate 30%, p/100m 4\\n* insulation, includes spray foams: total 1'702, 3% of all objects, fail-rate 53%, p/100m 1\\n* cotton bud/swabs: total 1'406, 2% of all objects, fail-rate 50%, p/100m 1\\n* expanded foams < 5mm: total 1'209, 2% of all objects, fail-rate 25%, p/100m 0\\n* plastic construction waste: total 992, 1% of all objects, fail-rate 52%, p/100m 1\\n* metal bottle caps: total 700, 1% of all objects, fail-rate 52%, p/100m 1\\n\\n\\n\\nIndustrial pellets and expanded foams < 5mm both occurred in significant quantities but identified in less than 50% of \\nthe surveys (median of 0), indicating high counts at specific locations. While both are micro plastics, their use, \\norigin and rate of occurrence are different depending on the survey area region. Industrial pellets are raw materials \\nused in injection molding processes whereas foamed plastic beads are the result of fragmentation of expanded polystyrene.\\n\\n### Conclusions\\n\\nAt the national level, the IQAASL results are stable compared to the surveys that were carried out in 2017 as part of the \\nSLR study. However, there was a general decrease in the quantity of food, drink and tobacco objects. Infrastructure \\nobjects and fragmented plastics and foams did not decline and some locations may have experienced sharp increases. \\nPandemic restrictions limiting large outdoor gatherings may have had a beneficial effect on the reduction of food, drink \\nand tobacco items. The greatest increases in infrastructure related objects were in Valais, Vaud and Brienz, which are \\nlocations near the Rhône and Aare rivers discharge points.\\n\\nThe land use around a survey location has a measurable effect on the deposition of certain objects. The more buildings \\nand fixed infrastructure there are the more tobacco and food products are found. Objects like fragmented plastics and \\nindustrial sheeting do not have the same association and are identified at approximately equal rates indifferent of the \\nland use with increases near river/canal discharge points.\\n\\nCurrently three of the four survey areas in the IQAASL are actively monitored by research and governmental agencies \\ndownstream of Switzerland using similar methods presented in this report. Additionally, regional associations in \\nSwitzerland are actively pursuing a standardization of reporting and protocols with partner organizations in the EU.\\n\\nThe IQAASL is a citizen-science project that only uses open-source tools and shares data on GNU public license, \\nenabling collaboration with stakeholders. At the end of the mandate, December 31, 2021, Hammerdirt will assume the \\nresponsibility of maintaining the code and data repository which is hosted publicly on Github.\\n\\nThe associations that participated in the IQAASL are actively seeking ways to incorporate the data collection process \\nand/or the results into their own business model. However, there is a shortage of data scientists within many regional \\nassociations which may lengthen the process of integration and stifle the rate of innovation at the level where it is needed most.\\n\""
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "context-r"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_r = f\"\"\"\n",
    "\n",
    "## Litter surveys in Switzerland 2020-2021 - IQAASL\n",
    "\n",
    "Identification, quantification and analysis of anthropogenic Swiss litter (IQAASL) is a project commissioned by the Swiss \n",
    "Federal Office for the Environment to collect data concerning visible pollutants along Swiss lakes and rivers. All \n",
    "discarded materials were collected and identified using litter survey techniques. in total there were 406 samples from 163 \n",
    "locations in 95 municipalities.\n",
    "\n",
    "This report is a summary and analysis of the litter surveys conducted and the methods employed in Switzerland from March\n",
    "2020 through August 2021. This sampling phase overlaps with the Swiss Litter Report (SLR) survey period, which ran\n",
    "from April 2017 to March 2018. The SLR was the first project on a national level to use the standard protocol described in \n",
    "the Guide to monitoring beach litter or any other comparable method. This overlap allows the results of the \n",
    "present study to be compared with those of the SLR.\n",
    "\n",
    "## Lakes and rivers\n",
    "\n",
    "The lakes and rivers were sampled from 2020-03 through 2021-05, a total of 54,744 objects were removed and classified over \n",
    "the course of 386 surveys. The survey locations were divided into survey areas for regional analysis and defined by the Aare, \n",
    "Rhône, Ticino and Linth/Limmat rivers. Surveys were conducted at 143 different locations, representing 77 municipalities. \n",
    "The total linear distance surveyed was 20 km with a surface area of 9 hectares and a total municipal population of 1.7 million.\n",
    "\n",
    "Most surveys were along lake shorelines (331 samples) as lakes offer more consistent and safe year-round access with \n",
    "respect to rivers. Additionally, lakes are large areas of reduced flow that receive input from multiple rivers, streams \n",
    "and drainage systems providing ideal locations to assess the variety of objects in and around the water bodies.\n",
    "\n",
    "In total 316 samples came from seven principal lakes in 3 major river basins. Twenty locations were selected to sample \n",
    "monthly for a twelve-month period with the exception of Lago Maggiore, which was sampled every three months. \n",
    "Surveys were also conducted on Lago di Lugano, Lac des Quatre cantons, Brienzersee and Zugersee. In addition, there \n",
    "were 55 surveys on 16 rivers.\n",
    "\n",
    "### The sampling locations - type and description\n",
    "\n",
    "The land use is reported as the percent of total area attributed to each land use category within a 1500m radius of the \n",
    "survey location. The ratio of the number of samples completed at the different land use profiles is an indicator of the \n",
    "environmental and economic conditions around the survey locations.\n",
    "\n",
    "The land use around the survey locations had a higher attribution to buildings as opposed to agriculture and woods. For \n",
    "example, half of all the surveys had at least 37% of land use devoted to buildings as opposed to 19% for agriculture or \n",
    "13% to woods. Land use devoted to recreation was at least 6% for half of all samples.\n",
    "\n",
    "The length of the road network within the buffer zone differentiates between locations that have other wise similar land \n",
    "use characteristics. The length of road per buffer ranges from 13km to 212km, 50% of the surveys had less than 67km of road network.\n",
    "\n",
    "The number of intersections ranges from zero to 23, 50% of the surveys had 3 or fewer intersections within 1500m of the \n",
    "survey location. The size of the intersecting river or canal was not taken into consideration. Survey locations on rivers \n",
    "have zero intersections.\n",
    "\n",
    "The population (not shown) is taken from statpop 2018 and represents the population of the municipality surrounding the \n",
    "survey location. The smallest population was 442 and the maximum was 415,367, 50% of the surveys come from \n",
    "municipalities with a population of at least 12,812.\n",
    "\n",
    "Overall, surveys at locations with more buildings and more recreation sites were more likely to facilitate the accumulation \n",
    "of trash on the shoreline. When the most common objects are considered, only four of the twelve were found at higher rates \n",
    "in the presence of more buildings. All of those objects are likely related to food or tobacco consumption near the location. \n",
    "Suggesting that there are still gains to be made in prevention and attenuation efforts in areas of high traffic near the water.\n",
    "\n",
    "However, six of the twelve objects have no positive association to land use attributed to buildings but were found in at \n",
    "least 50% of all the surveys. These objects are generally associated with professional use or in the case of cotton swabs \n",
    "personal hygiene:\n",
    "\n",
    "* plastic construction waste\n",
    "* fragmented plastics\n",
    "* industrial sheeting\n",
    "* expanded polystyrene\n",
    "* cotton bud/swabs\n",
    "* insulation, includes spray foams\n",
    "\n",
    "Furthermore, compared to products related to tobacco or food consumption these objects have fewer positive associations in \n",
    "general. Indicating that the appropriate land use feature is not currently accounted for and/or these objects are found \n",
    "at similar quantities indifferent of the land use features. Suggesting that these objects are ubiquitous in the environment.\n",
    "\n",
    "Finally, two of the twelve most common objects were found in less than 50% of the surveys and have few positive associations:\n",
    "\n",
    "* industrial pellets\n",
    "* expanded foams < 5mm\n",
    "\n",
    "These objects are found in large quantities sporadically at specific locations. They have been found in all survey areas \n",
    "and in all lakes. Industrial pellets have a very specific use and client base making it possible to find partners based \n",
    "on the density of the pellets found and the location of the nearest consumer or producer of pellets, see Shared responsibility.\n",
    "\n",
    "### Median survey total\n",
    "\n",
    "The results are in units of pieces of litter per 100 meters (p/100m). The median survey result of all data was approximately\n",
    "189 p/100m. The maximum recorded value was 6,617 p/100m (Rhône survey area) and the minimum recorded was 2p/100m (Aare survey area).\n",
    "The Rhône survey area had the highest median survey total of 442p/100m, this can in part be explained by the high number\n",
    "of urban survey locations with respect to the other survey areas and the deposition of fragmented plastics and foamed \n",
    "plastics at the Rhône River out flow in the upper lake region.\n",
    "\n",
    "A reference value was calculated excluding the results from samples that were less than 10m and objects less than 2.5cm. \n",
    "This method, described in EU Marine Beach Litter Baselines was used to calculate the reference and threshold \n",
    "values for all European beaches in 2015 and 2016 resulting in a median value of 131 p/100m. The results from the European \n",
    "baseline value lie outside the 95% confidence interval (CI) of 147 - 213p/100m established using the data from IQAASL.\n",
    "\n",
    "Surveys in Switzerland were on average, smaller scale than in marine environments and in locations that would be \n",
    "considered urban under most circumstances. To date monitoring of lakes and rivers upstream of coastal regions has \n",
    "not generalized on the European continent. However, there is a concerted effort by a group of associations in \n",
    "Switzerland and France to establish a common monitoring and data exchange protocol for the Rhône basin. Additionally, \n",
    "the Wageningen University & Research has begun analyzing data collected in the Meusse - Rhine delta using \n",
    "protocols like those in IQAASL.\n",
    "\n",
    "### The most common objects\n",
    "\n",
    "The most common objects are defined as those objects identified in at least 50% of all surveys and/or are among the ten \n",
    "most abundant by quantity. As a group the most common objects represent 68% of all objects identified in the sampling period. \n",
    "Of the most common items 27% are food, drink and tobacco related and 24% are infrastructure and agriculture related.\n",
    "\n",
    "Objects related to food, drink and tobacco are identified at higher rates at survey locations with a greater percentage \n",
    "of land attributed to buildings or fixed infrastructure, the inverse is true of the locations with a higher percentage \n",
    "of land attributed to woods or agriculture. However, infrastructure material and fragmented plastics, are found at similar \n",
    "rates throughout all survey areas indifferent of land use surrounding the survey locations.\n",
    "\n",
    "The most common objects identified in the surveys were:\n",
    "\n",
    "* cigarette ends: total 8'485, % of all objects 15.5%, fail-rate 87%, p/100m 20\n",
    "* fragmented plastics: total 7'400, 13% of all objects, fail-rate 86%, p/100m 18\n",
    "* expanded polystyrene: total 5'563, 10% of all objects, fail-rate 68%, p/100m ,\n",
    "* snack wrappers: total 3'325, 6% of all objects, fail-rate 85%, p/100m 9\n",
    "* industrial sheeting: total 2'534, 4% of all objects, fail-rate 69%, p/100m 5\n",
    "* glass drink bottles, pieces: total 2'136, 3% of all objects, fail-rate 65%, p/100m 3\n",
    "* industrial pellets: total 1'968, 3% of all objects, fail-rate 30%, p/100m 4\n",
    "* insulation, includes spray foams: total 1'702, 3% of all objects, fail-rate 53%, p/100m 1\n",
    "* cotton bud/swabs: total 1'406, 2% of all objects, fail-rate 50%, p/100m 1\n",
    "* expanded foams < 5mm: total 1'209, 2% of all objects, fail-rate 25%, p/100m 0\n",
    "* plastic construction waste: total 992, 1% of all objects, fail-rate 52%, p/100m 1\n",
    "* metal bottle caps: total 700, 1% of all objects, fail-rate 52%, p/100m 1\n",
    "\n",
    "\n",
    "\n",
    "Industrial pellets and expanded foams < 5mm both occurred in significant quantities but identified in less than 50% of \n",
    "the surveys (median of 0), indicating high counts at specific locations. While both are micro plastics, their use, \n",
    "origin and rate of occurrence are different depending on the survey area region. Industrial pellets are raw materials \n",
    "used in injection molding processes whereas foamed plastic beads are the result of fragmentation of expanded polystyrene.\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "At the national level, the IQAASL results are stable compared to the surveys that were carried out in 2017 as part of the \n",
    "SLR study. However, there was a general decrease in the quantity of food, drink and tobacco objects. Infrastructure \n",
    "objects and fragmented plastics and foams did not decline and some locations may have experienced sharp increases. \n",
    "Pandemic restrictions limiting large outdoor gatherings may have had a beneficial effect on the reduction of food, drink \n",
    "and tobacco items. The greatest increases in infrastructure related objects were in Valais, Vaud and Brienz, which are \n",
    "locations near the Rhône and Aare rivers discharge points.\n",
    "\n",
    "The land use around a survey location has a measurable effect on the deposition of certain objects. The more buildings \n",
    "and fixed infrastructure there are the more tobacco and food products are found. Objects like fragmented plastics and \n",
    "industrial sheeting do not have the same association and are identified at approximately equal rates indifferent of the \n",
    "land use with increases near river/canal discharge points.\n",
    "\n",
    "Currently three of the four survey areas in the IQAASL are actively monitored by research and governmental agencies \n",
    "downstream of Switzerland using similar methods presented in this report. Additionally, regional associations in \n",
    "Switzerland are actively pursuing a standardization of reporting and protocols with partner organizations in the EU.\n",
    "\n",
    "The IQAASL is a citizen-science project that only uses open-source tools and shares data on GNU public license, \n",
    "enabling collaboration with stakeholders. At the end of the mandate, December 31, 2021, Hammerdirt will assume the \n",
    "responsibility of maintaining the code and data repository which is hosted publicly on Github.\n",
    "\n",
    "The associations that participated in the IQAASL are actively seeking ways to incorporate the data collection process \n",
    "and/or the results into their own business model. However, there is a shortage of data scientists within many regional \n",
    "associations which may lengthen the process of integration and stifle the rate of innovation at the level where it is needed most.\n",
    "\"\"\"\n",
    "\n",
    "glue('context-r', context_r, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bb047-b19b-4251-a59e-23e0d555df64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Context: Litter surveys in Switzerland 2020-2021 - IQAASL\n",
    "\n",
    "We provide one document for the context here. It is indexed with \n",
    "\n",
    "Identification, quantification and analysis of anthropogenic Swiss litter (IQAASL) is a project commissioned by the Swiss \n",
    "Federal Office for the Environment to collect data concerning visible pollutants along Swiss lakes and rivers. All \n",
    "discarded materials were collected and identified using litter survey techniques. in total there were 406 samples from 163 \n",
    "locations in 95 municipalities.\n",
    "\n",
    "This report is a summary and analysis of the litter surveys conducted and the methods employed in Switzerland from March\n",
    "2020 through August 2021. This sampling phase overlaps with the Swiss Litter Report (SLR) survey period, which ran\n",
    "from April 2017 to March 2018. The SLR was the first project on a national level to use the standard protocol described in \n",
    "the Guide to monitoring beach litter or any other comparable method. This overlap allows the results of the \n",
    "present study to be compared with those of the SLR.\n",
    "\n",
    ":::{dropdown} See the rest of the context document\n",
    "\n",
    "```{glue:md} contex-r\n",
    ":format: myst\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0322c8f-9b29-4d13-816e-302f4d8e70f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## System prompts\n",
    "\n",
    "This is a retireval augmented generation application (RAG) for this analysis there is only one document. Their is a system prompt and a prompt to consider the question in the relation to recent chat history.\n",
    "\n",
    "````{dropdown} System and chat prompts\n",
    "\n",
    "### Basic langchain recipe\n",
    "\n",
    "```python\n",
    "system_prompt = (\n",
    "    \"You are a research assistant assigned the results section of a manuscript. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use paragraphs please\"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(client, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    client, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(client, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "```\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b6aab29-880a-4195-bba1-f1fe909cc255",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "client = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "headers_to_split = [('##', 'Lakes and rivers'), ('##', 'Land use profile lakes and rivers'),  ('##', 'Median survey total'), ('##', 'The most common objects')]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(context_r)\n",
    "vectorstore = Chroma.from_documents(documents=md_header_splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "report_file_name = 'generated_report.md'\n",
    "f = open(report_file_name, \"w\")\n",
    "f.write(context_r + \"\\n\\n\" + \"Response:\\n\\n\")\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a research assistant assigned the results section of a manuscript. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use paragraphs please\"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(client, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    client, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(client, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710b26b-f4ab-451e-9263-378cef29e197",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Questions\n",
    "\n",
    "### What is IQAASL ? What was the median survey total in IQAASL?  What were the most common objects ?\n",
    "\n",
    "answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f74a9e0-c87a-47af-9115-c47a9ea84ff1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "question = \"What is IQAASL ? What was the median survey total in IQAASL?  What were the most common objects ?\"\n",
    "# context = get_context_for_question(question)  # Retrieve context\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "append_to_markdown(report_file_name,ai_msg_1[\"answer\"] + \"\\n\\n\")\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_1[\"answer\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a79f02-a157-4be3-95f4-02028810e13a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "IQAASL stands for Identification, quantification and analysis of anthropogenic Swiss litter. The median survey total in IQAASL was approximately 189 pieces of litter per 100 meters. The most common objects identified in the surveys were cigarette ends, fragmented plastics, expanded polystyrene, snack wrappers, industrial sheeting, glass drink bottles, industrial pellets, insulation (including spray foams), cotton bud/swabs, expanded foams < 5mm, plastic construction waste, and metal bottle caps."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(ai_msg_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db54c2b-0c3a-4e18-945c-11a909b3aa3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### What types of locations were sampled ? What was the land-use of the locations surveyed ? Was it mostly buildings or forest?\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c253223a-be05-44d3-ab86-48a1bfd21ed5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    }
   ],
   "source": [
    "second_question = \"What types of locations were sampled ? What was the land-use of the locations surveyed ? Was it mostly buildings or forest?\"\n",
    "# context = get_context_for_question(second_question)  # Retrieve context for the second question\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "append_to_markdown(report_file_name, ai_msg_1[\"answer\"] + \"\\n\\n\")\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_2[\"answer\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def1c47b-717f-4b0d-b652-1cc119a20296",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The locations sampled included lakes, rivers, and shorelines. The land use around the survey locations had a higher attribution to buildings compared to agriculture and woods. For example, half of all surveys had at least 37% of land use devoted to buildings as opposed to 19% for agriculture or 13% for woods. Additionally, land use devoted to recreation was at least 6% for half of all samples."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8baf17f1-303d-4293-b221-33be80212a37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "application/papermill.record/text/markdown": "\n1. Objects of professional origin, objects not directly associated with consumption on location. This includes the following items:\n\nPlastic construction waste, Industrial sheeting, Industrial pellets (nurdles), Cable ties; steggel, zip, zap straps, Straps/bands;  hard, plastic package fastener, Foam packaging/insulation/polyurethane, Traffic cones, Tape, masking/duct/packing, Buckets, Helmets or hardhats, Fiberglass fragments, Tags fishing or industry (security tags, seals), Glove industrial/professional, Coverings; plastic packaging, sheeting for protecting large cargo items, Bags/sacks heavy duty plastic for 25 Kg or more; animal feed, fertilizers, garden trash etc., Car parts, Injection gun cartridge, Fragmented plastics\n\n2. Objects of personal consumption , objects that are most likely consumed on location. This includes the following items:\n\nCigarette filters, Food wrappers; candy, snacks, Straws and stirrers\n\nThese are observed results of the personal and professional groups combined for the canton of Bern. The groups are defined by the members as above.\n\nCan you summarize the sample totals of the combined results in one paragraph?\n\n|          | result              |\n|:---------|:--------------------|\n| total    | 5678                |\n| nsamples | 98                  |\n| average  | 1.6162244897959186  |\n| 5th      | 0.10850000000000001 |\n| 25th     | 0.3525              |\n| 50th     | 0.98                |\n| 75th     | 2.5625              |\n| 95th     | 4.763999999999992   |\n| std      | 1.6470570633747013  |\n| max      | 7.75                |\n| start    | 2017-04-16          |\n| end      | 2021-04-08          |\n\n\n\n\nThe following table separates the combined in to the two use groups. The units are pieces per meter of trash (pcs/m). Recall that pers = personal and pro = profesional please refer to them\nby their proper label. Note that 'count' = the number of samples, which is the same for both groups you do not need to mention\nthat. Can you summarize these results in a separate paragraph and compare them to combined summary ? \n\n| use   |   count |     mean |      std |   min |   25% |   50% |   75% |   max |\n|:------|--------:|---------:|---------:|------:|------:|------:|------:|------:|\n| pers  |      74 | 0.710946 | 0.918461 |     0 | 0.145 | 0.355 | 0.745 |  4.04 |\n| pro   |      74 | 1.04311  | 1.13764  |     0 | 0.28  | 0.64  | 1.49  |  5.32 |\n\n\n\n2",
      "application/papermill.record/text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "prompt-3"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "observed_results = f\"\"\"\n",
    "1. Objects of professional origin, objects not directly associated with consumption on location. This includes the following items:\n",
    "\n",
    "{pro_codes}\n",
    "\n",
    "2. Objects of personal consumption , objects that are most likely consumed on location. This includes the following items:\n",
    "\n",
    "{rec_codes}\n",
    "\n",
    "These are observed results of the personal and professional groups combined for the canton of Bern. The groups are defined by the members as above.\n",
    "\n",
    "Can you summarize the sample totals of the combined results in one paragraph?\n",
    "\n",
    "{lake_combined_summary}\\n\\n\n",
    "\n",
    "\n",
    "The following table separates the combined in to the two use groups. The units are pieces per meter of trash (pcs/m). Recall that pers = personal and pro = profesional please refer to them\n",
    "by their proper label. Note that 'count' = the number of samples, which is the same for both groups you do not need to mention\n",
    "that. Can you summarize these results in a separate paragraph and compare them to combined summary ? \n",
    "\n",
    "{di}\n",
    "\\n\\n\n",
    "2\"\"\"\n",
    "ai_msg_3 = rag_chain.invoke({\"input\": observed_results , \"chat_history\": chat_history})\n",
    "append_to_markdown(report_file_name,ai_msg_3[\"answer\"] + \"\\n\\n\")\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_3[\"answer\"])]\n",
    ")\n",
    "\n",
    "\n",
    "glue('prompt-3', Markdown(observed_results), display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a5b9e-a46e-4a6a-8b9d-c5f426240e38",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Can you summarise the survey results?\n",
    "\n",
    "````{dropdown} Prompt\n",
    "\n",
    "```{glue:md} prompt-3\n",
    ":format: myst\n",
    "``` \n",
    "````\n",
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4f1384-a0c9-4241-90a5-f48510c7ab45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The combined sample totals for the canton of Bern showed a total of 5678 pieces collected over 98 samples with an average of approximately 1.62 pieces per meter of trash. The 50th percentile was 0.98 pieces per meter, with a maximum of 7.75 pieces per meter observed during the sampling period from April 16, 2017, to April 8, 2021.\n",
       "\n",
       "When comparing the results of the two use groups, the personal consumption group (pers) had a mean of 0.71 pieces per meter with a standard deviation of 0.92, while the professional origin group (pro) had a higher mean of 1.04 pieces per meter with a standard deviation of 1.14. The 50th percentile for the personal group was 0.355 pieces per meter, while for the professional group it was 0.64 pieces per meter. The maximum number of pieces per meter was higher in the professional group at 5.32 compared to the personal group's maximum of 4.04. The results indicate that the professional origin group generally had a higher mean and maximum number of pieces per meter compared to the personal consumption group."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(ai_msg_3['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd7cea3-5e04-4c3b-a2c1-d4bcee752567",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|          | result              |\\n|:---------|:--------------------|\\n| total    | 5678                |\\n| nsamples | 98                  |\\n| average  | 1.6162244897959186  |\\n| 5th      | 0.10850000000000001 |\\n| 25th     | 0.3525              |\\n| 50th     | 0.98                |\\n| 75th     | 2.5625              |\\n| 95th     | 4.763999999999992   |\\n| std      | 1.6470570633747013  |\\n| max      | 7.75                |\\n| start    | 2017-04-16          |\\n| end      | 2021-04-08          |'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_combined_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a3e2732-b4d4-4da2-a23a-ed2066ce8ffd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| use   |   count |     mean |      std |   min |   25% |   50% |   75% |   max |\\n|:------|--------:|---------:|---------:|------:|------:|------:|------:|------:|\\n| pers  |      74 | 0.710946 | 0.918461 |     0 | 0.145 | 0.355 | 0.745 |  4.04 |\\n| pro   |      74 | 1.04311  | 1.13764  |     0 | 0.28  | 0.64  | 1.49  |  5.32 |'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21451ad2-c805-464a-bad0-0d7dccb9ac0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "application/papermill.record/text/markdown": "\n### Land use \n\nLand use refers to the measurable topographic features within a cirlce of r = 1 500 m and area = $\\pi r²$ with the survey location in the middle (the buffer). \nThe features, measured in meters squared, are given as a ratio <area of feature>/<area of buffer>. Thus a location with high percentage of buildings (an index of 4 or 5),\nwill have 60 - 100% of the land in the buffer dedicated to buildings.\n\nThe land use is further divided in to two groups: 1.cover , 2.use. Cover refers to those topographical features that do not overlap on a map. That is cover features are mutually \nexclusive, a given area of the buffer is either one or the other of the cover features but never both. The cover features are:\n\n* Buildings, orchards, forest, undefined, vineyards\n\nOn the other hand use refers to the activities or features that are present in the buffer and overlap the cover features. For example public services can be located within buildings \n(hospitals, schools) or in a forest (parks, nature areas). These features represent activites or, the features are:\n\n* Pubilc-services, streets, recreation\n\n#### Streets\n\nThe streets are measured as the length of the road network in the buffer. The lengths for each location are normalized from 0 - 1. Thus in the table below, the locations \nthat have the shortest road net work will be in category 1, the those with a more dense network will be higher.\n\n#### Sampling profile\n\nThe sampling profile details the proportion of samples conducted for each land use and magnitude. For example if the column is Forest and the index is 1 and the value is .3, that means\nthat 30% of the samples were taken from locations that had between 0 and 20% of the buffer dedicated to forest. \n\nThe sample results profile is the average pcs/m for each land use and magnitude. For example if For example if the column is Forest and the index is 1 and the value is .3, that means\nthat 30% of the samples were taken from locations that had between 0 and 20% of the buffer dedicated to forest. \n\nThere are two tables below. The firs table is the sample results profile and the second is the sampling profile.The index is the magnitude of the feature on a scale of 1-5.\nIn the first table the average pcs/trash per meter of the combined results is given for each land-use (columns) and magnitude (index, 1-5). \n\n### Objects per meter of shoreline by magnitude of feature\n|    |   buildings |   wetlands |   forest |   public-services |   recreation |   undefined |   streets |   vineyards |   orchards |\n|---:|------------:|-----------:|---------:|------------------:|-------------:|------------:|----------:|------------:|-----------:|\n|  1 |     1.47783 |    1.75405 | 2.02556  |           1.75405 |      1.75405 |     2.08231 |         0 |     1.75405 |    1.75405 |\n|  2 |     1.35393 |    0       | 1.81082  |           0       |      0       |     3.04333 |         0 |     0       |    0       |\n|  3 |     3.24188 |    0       | 0.658571 |           0       |      0       |     1.36667 |         0 |     0       |    0       |\n|  4 |     0.878   |    0       | 0        |           0       |      0       |     0       |         0 |     0       |    0       |\n|  5 |     0.82    |    0       | 0        |           0       |      0       |     0       |         0 |     0       |    0       |\n\n\n### Proportion of samples by magnitude of feature\n|    |   buildings |   wetlands |    forest |   public-services |   recreation |   undefined |   streets |   vineyards |   orchards |\n|---:|------------:|-----------:|----------:|------------------:|-------------:|------------:|----------:|------------:|-----------:|\n|  2 |   0.378378  |          0 | 0.662162  |                 0 |            0 |   0.0810811 |         0 |           0 |          0 |\n|  1 |   0.310811  |          1 | 0.243243  |                 1 |            1 |   0.351351  |         0 |           1 |          1 |\n|  3 |   0.216216  |          0 | 0.0945946 |                 0 |            0 |   0.567568  |         0 |           0 |          0 |\n|  4 |   0.0675676 |          0 | 0         |                 0 |            0 |   0         |         0 |           0 |          0 |\n|  5 |   0.027027  |          0 | 0         |                 0 |            0 |   0         |         0 |           0 |          0 |\n\n\n\n\nIn paragraph form:\n\ncan you summarize the definition of land-use ? \n\nCan you summarize the two tables (one paragraph each) ? Under what conditions were the most samples taken? Under what conditions do we expect to find the most or least?\n\n",
      "application/papermill.record/text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "prompt-4"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "introduction = f\"\"\"\n",
    "### Land use \n",
    "\n",
    "Land use refers to the measurable topographic features within a cirlce of r = 1 500 m and area = $\\pi r²$ with the survey location in the middle (the buffer). \n",
    "The features, measured in meters squared, are given as a ratio <area of feature>/<area of buffer>. Thus a location with high percentage of buildings (an index of 4 or 5),\n",
    "will have 60 - 100% of the land in the buffer dedicated to buildings.\n",
    "\n",
    "The land use is further divided in to two groups: 1.cover , 2.use. Cover refers to those topographical features that do not overlap on a map. That is cover features are mutually \n",
    "exclusive, a given area of the buffer is either one or the other of the cover features but never both. The cover features are:\n",
    "\n",
    "* Buildings, orchards, forest, undefined, vineyards\n",
    "\n",
    "On the other hand use refers to the activities or features that are present in the buffer and overlap the cover features. For example public services can be located within buildings \n",
    "(hospitals, schools) or in a forest (parks, nature areas). These features represent activites or, the features are:\n",
    "\n",
    "* Pubilc-services, streets, recreation\n",
    "\n",
    "#### Streets\n",
    "\n",
    "The streets are measured as the length of the road network in the buffer. The lengths for each location are normalized from 0 - 1. Thus in the table below, the locations \n",
    "that have the shortest road net work will be in category 1, the those with a more dense network will be higher.\n",
    "\n",
    "#### Sampling profile\n",
    "\n",
    "The sampling profile details the proportion of samples conducted for each land use and magnitude. For example if the column is Forest and the index is 1 and the value is .3, that means\n",
    "that 30% of the samples were taken from locations that had between 0 and 20% of the buffer dedicated to forest. \n",
    "\n",
    "The sample results profile is the average pcs/m for each land use and magnitude. For example if For example if the column is Forest and the index is 1 and the value is .3, that means\n",
    "that 30% of the samples were taken from locations that had between 0 and 20% of the buffer dedicated to forest. \n",
    "\n",
    "There are two tables below. The firs table is the sample results profile and the second is the sampling profile.The index is the magnitude of the feature on a scale of 1-5.\n",
    "In the first table the average pcs/trash per meter of the combined results is given for each land-use (columns) and magnitude (index, 1-5). \n",
    "\n",
    "{lake_rate}\n",
    "\\n\\n\n",
    "\n",
    "In paragraph form:\n",
    "\n",
    "can you summarize the definition of land-use ? \n",
    "\n",
    "Can you summarize the two tables (one paragraph each) ? Under what conditions were the most samples taken? Under what conditions do we expect to find the most or least?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ai_msg_4 = rag_chain.invoke({\"input\": introduction, \"chat_history\": chat_history})\n",
    "append_to_markdown(report_file_name,ai_msg_4[\"answer\"] + \"\\n\\n\")\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_4[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "glue('prompt-4', Markdown(introduction), display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11bbe52-f481-4964-bc74-ce8e1670a771",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## land use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ac7c4-90b7-48ad-a94c-ab63974b9e4a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### What kind of locations were surveyed in the canton of Bern ? How does that compare to the national results?\n",
    "\n",
    "````{dropdown} Prompt\n",
    "\n",
    "```{glue:md} prompt-4\n",
    ":format: myst\n",
    "```\n",
    "````\n",
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72d4a6f5-3dac-44d6-a57d-a6e6843d71a9",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Land use refers to the measurable topographic features within a specific radius around the survey location, with different features categorized into cover and use groups. Cover features are mutually exclusive and include buildings, orchards, forest, undefined areas, and vineyards. Use features represent activities or features that overlap cover features, such as public services, streets, and recreation areas. Streets are measured by the length of the road network within the buffer zone, normalized on a scale from 0 to 1.\n",
       "\n",
       "The first table provides the average number of pieces of trash per meter of shoreline for different land uses and magnitudes, ranging from 1 to 5. For example, buildings with a magnitude of 1 had an average of 1.48 pieces of trash per meter, while at magnitude 5, it was 0.82. The second table shows the proportion of samples taken at different magnitudes of features, indicating the distribution of sampling efforts. The highest proportion of samples were taken in areas with buildings at magnitude 2, while the least samples were taken in forest areas at magnitude 4 and 5. \n",
       "\n",
       "The most samples were taken in areas with buildings at magnitude 2, suggesting that these locations were prioritized for sampling. We expect to find the most litter per meter of shoreline in areas with buildings at magnitude 1, and the least in areas with forest at magnitudes 4 and 5, where the average was 0 pieces per meter."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(ai_msg_4[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6381424-ae9f-4789-a619-7bd9633dd1ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buildings</th>\n",
       "      <th>wetlands</th>\n",
       "      <th>forest</th>\n",
       "      <th>public-services</th>\n",
       "      <th>recreation</th>\n",
       "      <th>undefined</th>\n",
       "      <th>streets</th>\n",
       "      <th>vineyards</th>\n",
       "      <th>orchards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.477826</td>\n",
       "      <td>1.754054</td>\n",
       "      <td>2.025556</td>\n",
       "      <td>1.754054</td>\n",
       "      <td>1.754054</td>\n",
       "      <td>2.082308</td>\n",
       "      <td>0</td>\n",
       "      <td>1.754054</td>\n",
       "      <td>1.754054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.353929</td>\n",
       "      <td>0</td>\n",
       "      <td>1.810816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.043333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.241875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.658571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buildings  wetlands    forest public-services recreation undefined streets  \\\n",
       "1  1.477826  1.754054  2.025556        1.754054   1.754054  2.082308       0   \n",
       "2  1.353929         0  1.810816               0          0  3.043333       0   \n",
       "3  3.241875         0  0.658571               0          0  1.366667       0   \n",
       "4     0.878         0         0               0          0         0       0   \n",
       "5      0.82         0         0               0          0         0       0   \n",
       "\n",
       "  vineyards  orchards  \n",
       "1  1.754054  1.754054  \n",
       "2         0         0  \n",
       "3         0         0  \n",
       "4         0         0  \n",
       "5         0         0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b36dcb9-d8aa-4f20-9c9d-0a28cd849c85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buildings</th>\n",
       "      <th>wetlands</th>\n",
       "      <th>forest</th>\n",
       "      <th>public-services</th>\n",
       "      <th>recreation</th>\n",
       "      <th>undefined</th>\n",
       "      <th>streets</th>\n",
       "      <th>vineyards</th>\n",
       "      <th>orchards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.310811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buildings  wetlands    forest  public-services  recreation  undefined  \\\n",
       "2   0.378378       0.0  0.662162              0.0         0.0   0.081081   \n",
       "1   0.310811       1.0  0.243243              1.0         1.0   0.351351   \n",
       "3   0.216216       0.0  0.094595              0.0         0.0   0.567568   \n",
       "4   0.067568       0.0  0.000000              0.0         0.0   0.000000   \n",
       "5   0.027027       0.0  0.000000              0.0         0.0   0.000000   \n",
       "\n",
       "   streets  vineyards  orchards  \n",
       "2      0.0        0.0       0.0  \n",
       "1      0.0        1.0       1.0  \n",
       "3      0.0        0.0       0.0  \n",
       "4      0.0        0.0       0.0  \n",
       "5      0.0        0.0       0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51ca14-3bbc-4556-822e-4f99738dda6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Cluster analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8043837-189e-4846-88d5-1289863e6609",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# cluster_d['pcs/m'] = target_scaler.fit_transform(cluster_d[['pcs/m']])\n",
    "cluster_d['pcs/m'] = target_scaler.fit_transform(cluster_d[['pcs/m']])\n",
    "cluster_d['streets'] = street_scaler.fit_transform(cluster_d[['streets']])\n",
    "# these_cols = [x for x in filtered_columns if x != 'streets']\n",
    "cluster_d[filtered_columns] = feature_scaler.fit_transform(cluster_d[filtered_columns])\n",
    "\n",
    "cluster_pro, summary_pro = clusters_by_use_case(cluster_d, use='pro',scaled_cols=filtered_columns, columns_to_cluster=filtered_columns)\n",
    "cluster_rec, summary_rec = clusters_by_use_case(cluster_d, use='pers', scaled_cols=filtered_columns, columns_to_cluster=filtered_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6de3951-cf10-4244-a251-a926b7d16691",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "summary_pro['pers'] = summary_rec['pcs/m']\n",
    "summary_pro.rename(columns={'pcs/m':'pro'}, inplace=True)\n",
    "summary_pro.drop(['use', 'nsamps'], inplace=True, axis=1)\n",
    "cols = [x for x in summary_pro.columns if x not in ['pro','pers']]\n",
    "cluster_features = summary_pro[cols].copy()\n",
    "cluster_results = summary_pro[['pro', 'pers']].copy()\n",
    "\n",
    "cf = cluster_features.to_markdown()\n",
    "cr = cluster_results.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c528bb9-70ed-4476-bb0d-80a9d547db70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "application/papermill.record/text/markdown": "\n#### Cluster Analysis\n\nmethod : [kmeans scikit learn](kmeans https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n\nThe following are the results of the cluster analysis. The columns are the features that were used to make the clusters. The optimal number of clusters was\ndetermined using the elbow method (you can check the docs for this: https://hammerdirt-analyst.github.io/feb_2024/titlepage.html). \n\nTable has the following format:\n\n1. the columns are the measured land use features\n2. the index is the cluster number\n3. the value is the proportion that is attributed to that column. For example if buildings in cluster 1 = .17 it means that the locations in that cluster had\non average 17% of the buffer attributed to buildings\n\ncan you please summarize kmeans clustering, with reference to scikit learn (provide link) and explain the elbow method in paragraph form ? \n\nIn a separate paragraph please summarize the componsition of each cluster in paragraph form. Be specific and use the values from the table. Be sure to account for\nat least 50% of each cluster in your summary.\n\n\n\n|   cluster |   public-services |   buildings |   forest |   undefined |   vineyards |   streets |   recreation |\n|----------:|------------------:|------------:|---------:|------------:|------------:|----------:|-------------:|\n|         0 |             0.038 |       0.167 |    0.559 |       0.133 |       0     | 0.096574  |        0.002 |\n|         1 |             0.003 |       0.3   |    0.213 |       0.486 |       0     | 0.0628621 |        0     |\n|         2 |             0.061 |       0.309 |    0.107 |       0.541 |       0.02  | 0.49708   |        0.025 |\n|         3 |             0.044 |       0.682 |    0.153 |       0.149 |       0.015 | 0.251846  |        0.005 |\n|         4 |             0.003 |       0.047 |    0.271 |       0.55  |       0     | 0         |        0.155 |\n|         5 |             0.188 |       0.14  |    0.308 |       0.297 |       0.192 | 0.273278  |        0.014 |\n\n\n",
      "application/papermill.record/text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "prompt-5"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_5 = f\"\"\"\n",
    "#### Cluster Analysis\n",
    "\n",
    "method : [kmeans scikit learn](kmeans https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "\n",
    "The following are the results of the cluster analysis. The columns are the features that were used to make the clusters. The optimal number of clusters was\n",
    "determined using the elbow method (you can check the docs for this: https://hammerdirt-analyst.github.io/feb_2024/titlepage.html). \n",
    "\n",
    "Table has the following format:\n",
    "\n",
    "1. the columns are the measured land use features\n",
    "2. the index is the cluster number\n",
    "3. the value is the proportion that is attributed to that column. For example if buildings in cluster 1 = .17 it means that the locations in that cluster had\n",
    "on average 17% of the buffer attributed to buildings\n",
    "\n",
    "can you please summarize kmeans clustering, with reference to scikit learn (provide link) and explain the elbow method in paragraph form ? \n",
    "\n",
    "In a separate paragraph please summarize the componsition of each cluster in paragraph form. Be specific and use the values from the table. Be sure to account for\n",
    "at least 50% of each cluster in your summary.\n",
    "\n",
    "\n",
    "\n",
    "{cf}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ai_msg_5 = rag_chain.invoke({\"input\": prompt_5, \"chat_history\": chat_history})\n",
    "append_to_markdown(report_file_name,ai_msg_5[\"answer\"] + \"\\n\\n\")\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_5[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "glue('prompt-5', Markdown(prompt_5), display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92fc20-249f-4338-8a91-c51daa8b86df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### What are results of the cluster analysis ?\n",
    "\n",
    "````{dropdown} Prompt\n",
    "\n",
    "```{glue:md} prompt-5\n",
    ":format: myst\n",
    "```\n",
    "````\n",
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a55b535-acae-4028-ac11-9e6170c20e75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "KMeans clustering is a popular unsupervised machine learning technique available in scikit-learn. It is used for clustering data points into a specified number of clusters based on similarity. The algorithm aims to partition the data into clusters in such a way that the distance between data points within a cluster is minimized, and the distance between data points of different clusters is maximized. The elbow method is a technique used to determine the optimal number of clusters in KMeans clustering. It involves plotting the sum of squared distances between data points and their assigned cluster centroids for different numbers of clusters. The \"elbow\" point on the graph, where the rate of decrease in the sum of squared distances sharply changes, indicates the optimal number of clusters.\n",
       "\n",
       "Analyzing the composition of each cluster based on the provided table, we can observe the following:\n",
       "- Cluster 0: This cluster is characterized by a high proportion of forest (55.9%) and buildings (16.7%), with a moderate amount of streets (9.7%). Undefined areas and public services also make up a significant portion.\n",
       "- Cluster 1: Buildings dominate this cluster at 30%, followed by undefined areas at 48.6%. Forest and streets have lower proportions in this cluster.\n",
       "- Cluster 2: This cluster has a relatively balanced distribution across various land use features, with significant proportions of buildings (30.9%), forest (10.7%), and streets (49.7%). Vineyards and public services also contribute.\n",
       "- Cluster 3: Buildings have the highest proportion in this cluster at 68.2%, with forest making up 15.3%. Streets and public services are also notable contributors.\n",
       "- Cluster 4: Forest is the most prominent feature in this cluster at 55%, followed by buildings at 4.7%. Recreation areas have a significant presence in this cluster.\n",
       "- Cluster 5: This cluster shows a mix of land use features, with vineyards having a substantial proportion (19.2%), along with forest, buildings, and streets. Public services and recreation areas are present but in smaller amounts."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(ai_msg_5[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a18ded7b-4dce-445d-bfe3-36317fdc50c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>public-services</th>\n",
       "      <th>buildings</th>\n",
       "      <th>forest</th>\n",
       "      <th>undefined</th>\n",
       "      <th>vineyards</th>\n",
       "      <th>streets</th>\n",
       "      <th>recreation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.096574</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062862</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.497080</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.251846</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.188</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.273278</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         public-services  buildings  forest  undefined  vineyards   streets  \\\n",
       "cluster                                                                       \n",
       "0                  0.038      0.167   0.559      0.133      0.000  0.096574   \n",
       "1                  0.003      0.300   0.213      0.486      0.000  0.062862   \n",
       "2                  0.061      0.309   0.107      0.541      0.020  0.497080   \n",
       "3                  0.044      0.682   0.153      0.149      0.015  0.251846   \n",
       "4                  0.003      0.047   0.271      0.550      0.000  0.000000   \n",
       "5                  0.188      0.140   0.308      0.297      0.192  0.273278   \n",
       "\n",
       "         recreation  \n",
       "cluster              \n",
       "0             0.002  \n",
       "1             0.000  \n",
       "2             0.025  \n",
       "3             0.005  \n",
       "4             0.155  \n",
       "5             0.014  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae2c5f65-3ab1-4554-be1f-ce8e67c2bfce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "application/papermill.record/text/markdown": "\n#### Cluster Analysis\n\nThe following table is the average pcs/m per cluster, where the clusters were defined in the previous table. In this case we consider\nthe survey results for different objects groups in the same cluster. For example if the column = 'pers' and cluster = 2 and the value is\n1.23 that means that for survey locations in cluster 2 the average pcs/m for these locations is 1.23. Cluster 2 is defined in the previous table.\n\nTable has the following format:\n\n1. the columns are the use group\n2. the index is the cluster number\n3. the value is the average pcs/m found in that cluster for that use group\n\n\n|   cluster |      pro |     pers |\n|----------:|---------:|---------:|\n|         0 | 0.422857 | 0.235714 |\n|         1 | 0.1225   | 0.11625  |\n|         2 | 1.86448  | 0.281034 |\n|         3 | 1.12522  | 1.39217  |\n|         4 | 0.540833 | 0.695833 |\n|         5 | 2.82667  | 1.53667  |\n\n\n\n\nCan you please summarize the results ? Be sure to note where each use group has the highest and lowest pcs/m ? Identify where there is\nsigniifgant difference between personal and profesional use. Make sure to summarize the dominant components of each cluster in reference\nto this table that defines the composition of each cluster:\n\n|   cluster |   public-services |   buildings |   forest |   undefined |   vineyards |   streets |   recreation |\n|----------:|------------------:|------------:|---------:|------------:|------------:|----------:|-------------:|\n|         0 |             0.038 |       0.167 |    0.559 |       0.133 |       0     | 0.096574  |        0.002 |\n|         1 |             0.003 |       0.3   |    0.213 |       0.486 |       0     | 0.0628621 |        0     |\n|         2 |             0.061 |       0.309 |    0.107 |       0.541 |       0.02  | 0.49708   |        0.025 |\n|         3 |             0.044 |       0.682 |    0.153 |       0.149 |       0.015 | 0.251846  |        0.005 |\n|         4 |             0.003 |       0.047 |    0.271 |       0.55  |       0     | 0         |        0.155 |\n|         5 |             0.188 |       0.14  |    0.308 |       0.297 |       0.192 | 0.273278  |        0.014 |\n",
      "application/papermill.record/text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "prompt-6"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_6 = f\"\"\"\n",
    "#### Cluster Analysis\n",
    "\n",
    "The following table is the average pcs/m per cluster, where the clusters were defined in the previous table. In this case we consider\n",
    "the survey results for different objects groups in the same cluster. For example if the column = 'pers' and cluster = 2 and the value is\n",
    "1.23 that means that for survey locations in cluster 2 the average pcs/m for these locations is 1.23. Cluster 2 is defined in the previous table.\n",
    "\n",
    "Table has the following format:\n",
    "\n",
    "1. the columns are the use group\n",
    "2. the index is the cluster number\n",
    "3. the value is the average pcs/m found in that cluster for that use group\n",
    "\n",
    "\n",
    "{cr}\n",
    "\\n\\n\n",
    "\n",
    "Can you please summarize the results ? Be sure to note where each use group has the highest and lowest pcs/m ? Identify where there is\n",
    "signiifgant difference between personal and profesional use. Make sure to summarize the dominant components of each cluster in reference\n",
    "to this table that defines the composition of each cluster:\n",
    "\n",
    "{cf}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ai_msg_6 = rag_chain.invoke({\"input\": prompt_6, \"chat_history\": chat_history})\n",
    "append_to_markdown(report_file_name,ai_msg_6[\"answer\"] + \"\\n\\n\")\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_6[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "glue('prompt-6', Markdown(prompt_6), display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca2b959-b735-4dfb-8143-6c305bdf3bc9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### What are the differences between the two use groups?\n",
    "\n",
    "````{dropdown} Prompt\n",
    "\n",
    "```{glue:md} prompt-6\n",
    ":format: myst\n",
    "```\n",
    "````\n",
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "433964a4-2c91-4acb-add5-387ba6f0ce03",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Cluster 0 has the highest average pieces per meter (pcs/m) for professional use at 0.422857, while personal use has the lowest at 0.235714. In Cluster 1, professional use has the lowest pcs/m at 0.1225, and personal use is slightly higher at 0.11625. Cluster 2 shows a significant difference between professional and personal use, with professional use having a much higher average pcs/m of 1.86448 compared to personal use at 0.281034. \n",
       "\n",
       "In Cluster 3, personal use has the highest average pcs/m at 1.39217, while professional use is lower at 1.12522. Cluster 4 has personal use with the highest pcs/m at 0.695833, and professional use is lower at 0.540833. Cluster 5 shows a similar pattern to Cluster 3, with personal use having a higher average pcs/m of 1.53667 compared to professional use at 2.82667.\n",
       "\n",
       "Analyzing the dominant components of each cluster based on the composition table, we can infer the following:\n",
       "- Cluster 0: Dominated by forest and buildings, with streets also contributing significantly. Public services and undefined areas play minor roles.\n",
       "- Cluster 1: Characterized by a high proportion of undefined areas, with buildings and streets also present. Public services have a minimal contribution.\n",
       "- Cluster 2: Shows a mix of land use features, with streets having a major impact along with forest and buildings. Vineyards and public services also play a role.\n",
       "- Cluster 3: Predominantly composed of buildings, with forest and streets also significant. Public services and undefined areas have minor contributions.\n",
       "- Cluster 4: Forest is the most dominant feature, followed by buildings. Recreation areas also have a substantial presence in this cluster.\n",
       "- Cluster 5: Features a variety of land use components, with streets and forest being notable. Vineyards and public services are also part of this cluster's composition."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(ai_msg_6[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edda4bf8-2615-4b51-8171-33c3827d38cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro</th>\n",
       "      <th>pers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.422857</td>\n",
       "      <td>0.235714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.116250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.864483</td>\n",
       "      <td>0.281034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.125217</td>\n",
       "      <td>1.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.540833</td>\n",
       "      <td>0.695833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.826667</td>\n",
       "      <td>1.536667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pro      pers\n",
       "cluster                    \n",
       "0        0.422857  0.235714\n",
       "1        0.122500  0.116250\n",
       "2        1.864483  0.281034\n",
       "3        1.125217  1.392174\n",
       "4        0.540833  0.695833\n",
       "5        2.826667  1.536667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44ba3f-8372-451f-afa4-71078100924e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
