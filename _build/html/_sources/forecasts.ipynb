{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c16819-72da-4b47-a3aa-988d3f5a8203",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "%load_ext watermark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import dirichlet\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "import session_config\n",
    "import reports\n",
    "import geospatial\n",
    "import userdisplay as disp\n",
    "from myst_nb import glue\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from scipy.stats import halfnorm, multinomial\n",
    "import gridforecast as gfcast\n",
    "\n",
    "# available data\n",
    "\n",
    "columns =  [\n",
    "    'sample_id',\n",
    "    'code',\n",
    "    'quantity',\n",
    "    'pcs/m',\n",
    "    'feature_name',\n",
    "    'location',\n",
    "    'parent_boundary',\n",
    "    'city', \n",
    "    'canton',\n",
    "    'feature_type',\n",
    "    'date'\n",
    "]\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='app.log', \n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_jeffreys_prior_matrix(index_range, categories, epsilon=0.01):\n",
    "    # Initialize the matrix\n",
    "    jeffreys_prior_matrix = np.zeros((len(index_range), len(categories)))\n",
    "    \n",
    "    # Calculate Jeffreys prior values using the modified formula\n",
    "    for i, x in enumerate(index_range):\n",
    "        prior = 1 / (x + epsilon)  # Adding epsilon to avoid division by zero\n",
    "        # Assign this value to all categories for this index\n",
    "        jeffreys_prior_matrix[i, :] = prior\n",
    "    \n",
    "    return jeffreys_prior_matrix"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "37231c12-ec0a-4fe6-909f-1c83bc069660",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(gridforecaster)=\n",
    "# Grid forecast\n",
    "\n",
    "For many forecasting and predicting are interchangeable terms. We consider that forecasting or predicting is the process of making statements about events that have yet to occurr. In this case we are using historical results to form our opinion about what might happen in the future. The question we are answering is fairly simple:\n",
    "\n",
    "> What will I find at __this__ beach today, given what has been found at __other similar__ beaches ?\n",
    "\n",
    "Note that this question has condtions: _given what has been found at other similar beaches_. Which means we are assuming that the density of litter from beaches is conditioned or dependent on the attributes or feature that describe the beach. Features are the measured attributes or characteristics of a survey location that are used to compare one survey location to another.\n",
    "\n",
    "## Assumptions of the model about the sample data\n",
    "\n",
    "## Conditional probability\n",
    "\n",
    "[Conditional probability](https://en.wikipedia.org/wiki/Conditional_probability) is a fundamental concept in probability theory that describes the probability of an event occurring given that another event has already occurred. It is denoted as $P(Aâˆ£B)$, which reads as \"the probability of A given B.\"\n",
    "\n",
    "### Formal Definition\n",
    "\n",
    "The conditional probability of event \\(A\\) given event \\(B\\) is defined as:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $P(A|B)$ is the conditional probability of $A$ given $B$.\n",
    "- $P(A \\cap B)$ is the joint probability of both $A$ and $B$ occurring.\n",
    "- $P(B)$ is the probability of event $B$ occurring, provided that $P(B) > 0$.\n",
    "\n",
    "\n",
    "### Bayes' theorem\n",
    "\n",
    "[Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) is a fundamental principle in probability theory and statistics that describes the probability of an event based on __prior__ knowledge of conditions that might be related to the event. It allows for the updating of probabilities as new evidence or information becomes available. It is derived from the definition of conditional probability.\n",
    "\n",
    "__Deriving Bayes theorem__\n",
    "\n",
    "::::{grid} 2 2 2 2\n",
    ":gutter: 1\n",
    "\n",
    ":::{grid-item-card} Define conditional probability\n",
    "\n",
    "For events \\(A\\) and \\(B\\):\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "$$P(B|A) = \\frac{P(A \\cap B)}{P(A)}$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} The joint probability $P(A \\cap B)$\n",
    "\n",
    "From the first equation:\n",
    "\n",
    "$$P(A \\cap B) = P(A|B) \\cdot P(B)$$\n",
    "\n",
    "From the second equation:\n",
    "\n",
    "$$P(A \\cap B) = P(B|A) \\cdot P(A)$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} Equate the two expressions\n",
    "\n",
    "$$P(A|B) \\cdot P(B) = P(B|A) \\cdot P(A)$$\n",
    "\n",
    "Solve for $P(A|B)$\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} This is Bayes' Theorem\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    ":::\n",
    "::::\n",
    "\n",
    "#### Prior knowledge\n",
    "\n",
    "In the context of Bayes' theorem, the term \"prior\" refers to the prior probability, which is the probability of an event or hypothesis before any new evidence or data is taken into account. It represents the initial degree of belief in a particular outcome based on existing knowledge or assumptions.\n",
    "\n",
    "> In this use case the __prior__ is what we __beleive__ we will find at the beach, before we get to the beach, given everything we know about beaches and litter in Switzerland. Our beliefs are based on the cumulative experience from all previous visits to the beach, or beaches that are similar. Our beliefs come from what we have actually experienced.\n",
    "\n",
    "Mathematically, if we are trying to determine the probability of a hypothesis A given new evidence B, the prior probability is denoted as P(A). It is the baseline probability of A before considering the new evidence provided by B.\n",
    "\n",
    "Bayes' Theorem uses the prior probability along with the likelihood of the evidence given the hypothesis and the marginal probability of the evidence to update the probability of the hypothesis. This updated probability is called the posterior probability.\n",
    "\n",
    "### Empirical Bayes\n",
    "\n",
    "Empirical Bayes methods are statistical techniques that combine the principles of Bayesian inference with empirical data. These methods use data to estimate the prior distribution, which is then used in the Bayesian framework to update probabilities and make inferences.\n",
    "\n",
    "In traditional Bayesian analysis, the prior distribution is chosen based on subjective beliefs or historical data. In contrast, empirical Bayes methods __estimate the prior distribution directly from the observed data, making the process more objective and often more practical in large-scale problems__. ([Petrone, S. et al, 2014](https://link.springer.com/article/10.1007/s40300-014-0044-1))\n",
    "\n",
    "#### Conjugate prior\n",
    "\n",
    "In Bayesian statistics, a [conjugate prior](https://en.wikipedia.org/wiki/Conjugate_prior) is a prior distribution that, when combined with a given likelihood through Bayes' theorem, results in a [posterior distribution](https://en.wikipedia.org/wiki/Posterior_probability) of the same family as the prior. This property simplifies the computation of the posterior distribution.\n",
    "\n",
    "1. Jaynes, E.T.: [\"Probability Theory: The Logic of Science\"](https://bayes.wustl.edu/etj/prob/book.pdf): Emphasized the logical consistency and practical advantages of conjugate priors.\n",
    "2. Gelman, A. et al.: [\"Bayesian Data Analysis\"](http://www.stat.columbia.edu/~gelman/book/) : discusses conjugate priors in the context of hierarchical models and practical Bayesian analysis.\n",
    "\n",
    "#### Grid Approximation\n",
    "\n",
    "Grid approximation is a technique used in numerical analysis and statistical inference to approximate the values of a continuous function or parameter by evaluating it at a discrete set of points. This involves creating a grid of possible values within a defined range and calculating the function or parameter at each grid point.\n",
    "\n",
    "### Empirical Bayes grid approximation using a conjugate prior\n",
    "\n",
    "Empirical Bayes grid approximations involve estimating the prior and posterior distributions of parameters using a discretized set of values. In the context of the multinomial-Dirichlet conjugate relationship, this method is particularly effective. The Dirichlet distribution serves as the prior for the multinomial likelihood, and empirical Bayes methods estimate this prior directly from the data. By defining a grid of possible parameter values, often spaced every 0.1 units from 0 to the maximum observed value, the posterior distribution is approximated by evaluating the likelihood and updating the Dirichlet prior at each grid point.\n",
    "\n",
    "This approach simplifies the computational complexity of Bayesian inference. Instead of integrating over a continuous parameter space, which can be analytically challenging, grid approximation transforms the problem into a finite summation. The [multinomial-Dirichlet conjugate pair](https://en.wikipedia.org/wiki/Dirichlet-multinomial_distribution) ensures that the posterior remains in the Dirichlet family, making the updates straightforward.\n",
    "\n",
    "#### Deriving conjugate relationship\n",
    "\n",
    "The [binomial](https://en.wikipedia.org/wiki/Binomial_distribution), [multinomial](https://en.wikipedia.org/wiki/Multinomial_distribution), and [Dirichlet](https://en.wikipedia.org/wiki/Dirichlet_distribution) distributions are intrinsically linked through the concept of conjugate priors in Bayesian statistics. The binomial distribution describes the probability of a fixed number of successes in a series of independent trials, with a success probability _p_. When modeling this in a Bayesian framework, the Beta distribution is used as a conjugate prior for _p_. This means that the posterior distribution, after observing data, remains a Beta distribution, simplifying the update process.\n",
    "\n",
    "Extending this to multiple categories, the multinomial distribution generalizes the binomial by modeling the counts of outcomes across multiple categories. The Dirichlet distribution serves as the conjugate prior for the multinomial distribution, just as the Beta distribution does for the binomial. When using a Dirichlet prior, the posterior distribution after observing data also remains a Dirichlet distribution.\n",
    "\n",
    "::::{grid} 2 2 2 2\n",
    ":gutter: 1\n",
    "\n",
    ":::{grid-item-card} Binomial Likelihood:\n",
    "\n",
    "The binomial distribution models the number of successes in _n_ trials, given a success probability _p_:\n",
    "\n",
    "$$P(X = k | p) = \\binom{n}{k} p^k (1 - p)^{n - k}$$\n",
    "\n",
    "The Beta distribution is a conjugate prior for the binomial likelihood, parameterized by $\\alpha$ and $\\beta$:\n",
    "\n",
    "$$P(p | \\alpha, \\beta) = \\frac{p^{\\alpha - 1} (1 - p)^{\\beta - 1}}{B(\\alpha, \\beta)}$$\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} Posterior Distribution:\n",
    "\n",
    "Combining the likelihood and prior using Bayes' theorem gives the posterior distribution:\n",
    "\n",
    "$$P(p | k, n) \\propto p^k (1 - p)^{n - k} \\cdot p^{\\alpha - 1} (1 - p)^{\\beta - 1}$$\n",
    "\n",
    "$$P(p | k, n) \\propto p^{k + \\alpha - 1} (1 - p)^{n - k + \\beta - 1}$$\n",
    "\n",
    "Which is a Beta distribution:\n",
    "\n",
    "$$P(p | k, n) = \\text{Beta}(p | k + \\alpha, n - k + \\beta)$$\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} Generalize binomial to multinomial\n",
    "\n",
    "The multinomial distribution generalizes the binomial to more than two categories. For counts \n",
    "$\\mathbf{x} = (x_1, x_2, \\ldots, x_K) \\quad \\text{in} \\quad K \\quad \\text{categories, given probabilities} \\quad \\mathbf{p} = (p_1, p_2, \\ldots, p_K)$:\n",
    "\n",
    "$$P(\\mathbf{x} | \\mathbf{p}) = \\frac{n!}{x_1! x_2! \\cdots x_K!} p_1^{x_1} p_2^{x_2} \\cdots p_K^{x_K}$$\n",
    "\n",
    "where: $n = \\sum_{i=1}^K x_i$\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} The conjugate prior to the multinomial\n",
    "\n",
    "The Dirichlet distribution is a conjugate prior for the multinomial distribution, parameterized by Î±=(Î±1â€‹,Î±2â€‹,â€¦,Î±Kâ€‹):\n",
    "\n",
    "$P(\\mathbf{p} | \\boldsymbol{\\alpha}) = \\frac{1}{B(\\boldsymbol{\\alpha})} \\prod_{i=1}^K p_i^{\\alpha_i - 1}$\n",
    "\n",
    "where B(Î±) is the multivariate Beta function.\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} Posterior Distribution\n",
    "The posterior distribution is a combination of the likelihood and prior:\n",
    "\n",
    "$$P(\\mathbf{p} | \\mathbf{x}) \\propto \\left( \\prod_{i=1}^K p_i^{x_i} \\right) \\left( \\prod_{i=1}^K p_i^{\\alpha_i - 1} \\right)$$\n",
    "\n",
    "Which is a Dirichlet distribution:\n",
    "\n",
    "$P(\\mathbf{p} | \\mathbf{x}) \\propto \\prod_{i=1}^K p_i^{x_i + \\alpha_i - 1}$\n",
    "\n",
    ":::\n",
    ":::{grid-item-card} Posterior with updated parameters\n",
    "\n",
    "$$P(\\mathbf{p}|\\mathbf{x}) = \\text{D}(\\mathbf{p}|x_1 + \\alpha_1, \\ldots, x_K + \\alpha_K)$$\n",
    "\n",
    "Where D is a _Dirichlet_ distribution\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16592a7-8dd4-46c6-9314-265d7e433239",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Examples\n",
    "\n",
    "### The probability of finding one object\n",
    "\n",
    "Here we consider the following question:\n",
    "\n",
    "1. What are the chances of finding at least one _O_ if I go to the beach at _C_ ?\n",
    "\n",
    "Where _O_ is some object of interest that is in the list of items identified on the beach (there are 229 options) and C is a lake or municipality on a lake.\n",
    "\n",
    "This example was first tested in November 2021 at the request of members from an environmental organization that was visiting Lake Geneva, [finding one object](https://hammerdirt-analyst.github.io/finding-one-object/titlepage.html). This value was initially expected to be approximately 40%. The method of calculation was the Beta-Binomial conjugate pair. Instead of considering all the values on the grid we consider only two results: was the number found greater than zero or not. From the general form in (1) we get:\n",
    "\n",
    "> What is the chance of finding at least one feminine hygiene product at the beach on Lac LÃ©man ?\n",
    "\n",
    "\n",
    "````{tab-set}\n",
    "\n",
    "```{tab-item} Steps to complete the calculation\n",
    "\n",
    "1. identify the codes for the items of interest: `G96` and `G144`\n",
    "2. define the region of interest: `lac-leman`\n",
    "3. define the date range of the likelihood : `{'start':'2020-01-01', 'end':'2021-11-01'}`\n",
    "4. define the date range of the prior :  `{'start':'2015-11-15', 'end':'2019-12-31'}`\n",
    "\n",
    "### The likelihood and prior\n",
    "\n",
    "The likelihood data is defined as all the data collected durring the current sampling campaign, up to one week before the planned event in Geneva. The prior data is all collected in the previous sampling campaigns, not including results from locations in the likelihod. In both cases we are considering only the codes G96 and G144.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "```{tab-item} Default parameters and methods\n",
    "\n",
    "__Default parameters__\n",
    "\n",
    "1. range of the default index $X = \\{ x \\in \\mathbb{R} \\mid x = 0.1k, \\; k \\in \\mathbb{Z}, \\; 0 \\leq x < 100 \\}$\n",
    "   * or `np.arange(0, 100, 0.1)`\n",
    "2. Max range of forecast grid = $\\max_{i} \\{ x_i \\} \\text{ or } P_{99} = \\text{percentile}_{99} \\{ x_i \\}$\n",
    "3. The magnitude of the land use for each survey location is categorized in the following manner:\n",
    "\n",
    "$$\n",
    "\\text{binning}(x) = \n",
    "\\begin{cases} \n",
    "1 & \\text{if } -1 \\leq x < 0.2 \\\\\n",
    "2 & \\text{if } 0.2 \\leq x < 0.4 \\\\\n",
    "3 & \\text{if } 0.4 \\leq x < 0.6 \\\\\n",
    "4 & \\text{if } 0.6 \\leq x < 0.8 \\\\\n",
    "5 & \\text{if } 0.8 \\leq x \\leq 1 \n",
    "\\end{cases},\n",
    "\\text{ where x is the \\% of land occupied by a land-use feature } \n",
    "$$\n",
    "\n",
    "__Distributions__\n",
    "\n",
    "The posterior distribution is $P(\\text{Likelihood} \\mid \\text{Prior}) \\approx \\text{Dirichlet}(\\alpha)$ or more commonly: $P(\\theta \\mid \\mathbf{X}) \\approx  text{Dirichlet}(\\alpha + \\mathbf{n})$\n",
    "\n",
    "1. $\\theta$ is the parameters of the Dirichlet distribution\n",
    "2. $\\mathbf{X}$ is the observed data\n",
    "3. $\\alpha$ is the parameters of the prior Dirichlet distribution\n",
    "4. $\\mathbf{n}$ is the count data from the likelihood\n",
    "\n",
    "__Forecasted samples__\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\theta &\\sim \\text{Dirichlet}(\\alpha) \\\\\n",
    "\\mathbf{X} \\mid \\theta &\\sim \\text{Multinomial}(N, \\theta)\n",
    "\\end{align*}\n",
    "$$\n",
    "```\n",
    "````\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e87cfc-6c1b-4d3b-a1ee-5483ecf2d548",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# user selects survey area\n",
    "# user selects all dates\n",
    "# prior = survey results from other survey areas\n",
    "# prior = same land use composition\n",
    "# same feature types\n",
    "\n",
    "fname_ftype = pd.read_csv('data/end_process/beaches.csv')\n",
    "fname_ftype = fname_ftype[['feature_name', 'feature_type']]\n",
    "fname_ftype.drop_duplicates('feature_name',inplace=True)\n",
    "fname_ftype.set_index('feature_name', inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955bae5f-53b6-42c8-9e3a-b5b8d4e08c49",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "surveys = session_config.collect_survey_data()\n",
    "\n",
    "survey_area = 'rhone'\n",
    "feature_name = None\n",
    "canton = None\n",
    "muni = None\n",
    "river = None\n",
    "lake = None\n",
    "park = None\n",
    "\n",
    "# boundaries / search parameters\n",
    "survey_area_s = {'parent_boundary': survey_area}\n",
    "feature_name_s = {'feature_name': feature_name}\n",
    "canton_s = {'canton':canton}\n",
    "muni_s = {'city': muni}\n",
    "river_s = {'river':river}\n",
    "lake_s = {'lake':lake}\n",
    "park_s = {'park':park}\n",
    "feature_type_s = {'feature_type': None}\n",
    "\n",
    "a_query = [survey_area_s, canton_s, muni_s, river_s, lake_s, park_s, feature_type_s]\n",
    "\n",
    "feature_name = 'lac-leman'\n",
    "use_case = 'l'\n",
    "dates = {'start':'2020-01-01', 'end':'2021-12-31'}\n",
    "prior_dates = {'start':'2015-11-15', 'end':'2019-12-31'}\n",
    "\n",
    "codes = [\"Gfrags\"]\n",
    "\n",
    "l_query_params = dict(feature_name=feature_name, date_range=dates)\n",
    "p_query_params = dict(feature_name= feature_name, date_range=prior_dates)\n",
    "\n",
    "new_index = surveys[surveys.code.isin(codes)][columns].reset_index(drop=True)\n",
    "results = gfcast.reports_and_forecast(l_query_params, p_query_params, ldata=new_index, logger=logger)\n",
    "\n",
    "# collect the results from the prior and the likelihood\n",
    "prr = results['prior_report'].sample_results.groupby('sample_id')['pcs/m'].sum()\n",
    "lkl = results['this_report'].sample_results.groupby('sample_id')['pcs/m'].sum()\n",
    "\n",
    "# consider all values\n",
    "xii = results['posterior_no_limit'].sample_posterior()\n",
    "\n",
    "# limit to the 99th percentile\n",
    "sample_values, posterior, summary_simple = gfcast.dirichlet_posterior(results['posterior_99'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45eb86-a5a9-43b5-bf84-e10144da2b89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.ecdfplot(prr, label='prior', ls='-', ax=ax)\n",
    "sns.ecdfplot(lkl, label='observed', ls='-', ax=ax)\n",
    "sns.ecdfplot(sample_values, label='expected 99%', ls=':')\n",
    "sns.ecdfplot(xii, label='expected max', ls='-.')\n",
    "ax.set_xlim(-.1, 10)\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f390557-16b1-4888-bbfe-b2794e2c0c6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# prior_locations = other_report.df[(other_report.df.parent_boundary == 'aare')&(other_report.df.feature_type == 'l')].location.unique()\n",
    "# prior_data = other_land_use.df_cat[other_land_use.df_cat.location.isin(prior_locations)]\n",
    "# prior_data.to_csv('sample_by_weight.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91fa9ce-29f0-4187-ba07-519447514b12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "n = 1\n",
    "\n",
    "prior_mle = round(np.mean(prr > n), 2)\n",
    "likelihood_mle = round(np.mean(lkl > n), 2)\n",
    "\n",
    "forecasted_mle2 = round(np.mean(xii > n), 2)\n",
    "\n",
    "forecasted_mle = round(np.mean(sample_values > n), 2)\n",
    "\n",
    "results_l = pd.DataFrame([[prior_mle, likelihood_mle, forecasted_mle, forecasted_mle2]], columns = ['prior', 'likelihood', 'P(A|B)', 'Pmax(A|B)'], index = [feature_name])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c647801-0fda-499e-831b-148012a18d82",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "city = 'Vevey'\n",
    "\n",
    "l_query_params = dict(city=city, date_range=dates)\n",
    "p_query_params = dict(city=city, date_range=prior_dates, feature_type='l')\n",
    "new_indexi = new_index[new_index.parent_boundary == 'rhone'].reset_index().copy()    \n",
    "\n",
    "results_vevey = gfcast.reports_and_forecast(l_query_params, p_query_params, ldata=new_indexi, feature_columns=session_config.feature_variables, logger=logger)\n",
    "\n",
    "# collect the results from the prior and the likelihood\n",
    "prr = results_vevey['prior_report'].sample_results.groupby('sample_id')['pcs/m'].sum()\n",
    "lkl = results_vevey['this_report'].sample_results.groupby('sample_id')['pcs/m'].sum()\n",
    "\n",
    "# consider all values\n",
    "xii = results_vevey['posterior_no_limit'].sample_posterior()\n",
    "\n",
    "# limit to the 99th percentile\n",
    "sample_values, posterior, summary_simple = gfcast.dirichlet_posterior(results_vevey['posterior_99'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc754baa-acd7-491c-b3ee-387e28b24b32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "prior_mle = round(np.mean(prr > n), 2)\n",
    "likelihood_mle = round(np.mean(lkl > n), 2)\n",
    "forecasted_mle2 = round(np.mean(xii > n), 2)\n",
    "forecasted_mle = round(np.mean(sample_values >n), 2)\n",
    "\n",
    "results_g = pd.DataFrame([[prior_mle, likelihood_mle, forecasted_mle, forecasted_mle2]], columns = ['prior', 'likelihood', 'P(A|B)', 'Pmax(A|B)'], index = [city])\n",
    "\n",
    "results = pd.concat([results_l, results_g])\n",
    "results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f422f-5a6a-4348-98ac-2f0d9c414e03",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f063e04-eb9d-423b-a4e0-c853f81d69fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
