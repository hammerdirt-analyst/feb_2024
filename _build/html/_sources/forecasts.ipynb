{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c16819-72da-4b47-a3aa-988d3f5a8203",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import dirichlet\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from myst_nb import glue\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from scipy.stats import halfnorm, multinomial\n",
    "import gridforecast as gfcast\n",
    "\n",
    "# available data\n",
    "\n",
    "columns =  [\n",
    "    'sample_id',\n",
    "    'code',\n",
    "    'quantity',\n",
    "    'pcs/m',\n",
    "    'feature_name',\n",
    "    'location',\n",
    "    'parent_boundary',\n",
    "    'city', \n",
    "    'canton',\n",
    "    'feature_type',\n",
    "    'date'\n",
    "]\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='app.log', \n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_jeffreys_prior_matrix(index_range, categories, epsilon=0.01):\n",
    "    # Initialize the matrix\n",
    "    jeffreys_prior_matrix = np.zeros((len(index_range), len(categories)))\n",
    "    \n",
    "    # Calculate Jeffreys prior values using the modified formula\n",
    "    for i, x in enumerate(index_range):\n",
    "        prior = 1 / (x + epsilon)  # Adding epsilon to avoid division by zero\n",
    "        # Assign this value to all categories for this index\n",
    "        jeffreys_prior_matrix[i, :] = prior\n",
    "    \n",
    "    return jeffreys_prior_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37231c12-ec0a-4fe6-909f-1c83bc069660",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(gridforecaster)=\n",
    "# Grid forecast\n",
    "\n",
    "We consider that forecasting or predicting is the process of making statements about events that have yet to occurr. In this case we are using historical results to form our opinion about the probability of an event in the future. The event we considering is rather pedestrian:\n",
    "\n",
    "> What will I find at the beach today, given what has been found at __other similar__ beaches or what was found at the beach in the past ?\n",
    "\n",
    "Which means that our estimation of the objects we are likely to find is based on our own experience as well as the experience of others under similar conditions. This reasoning does not tell us about the reason why the object has bypassed the elaborate system put in place to prevent it from ending up on the beach. \n",
    "\n",
    "We do, however, identify quantifiable vectors that certainly contain the cause. The vectors come directly from the official topographical map for the territory. As a result locations can be grouped according to the magnitude of the vector that has been derived from the topographical map. By comparing local results to national results with a quantifiable vector we have a very efficient way to combine experiences beyond a geographic limit. Thus we can estimate the comparison from one location using the results from locations that have similar attributes but not geographically related.\n",
    "\n",
    "Here we show how the `gridforecast` module works. Specifically the different methods of the  `gridforecast.MulitnomialDirichlet` class. It is a grid aproximation in Bayesien framework. We start the process with conditional probability, make the connection with Bayes` theorem and finish with the conjugate relationship Dirichlet-Multinomial. The application to survey data is implemented in scipy and numpy. \n",
    "\n",
    "Our first consideration, however, is wether or not our research question is comensurate with our assumptions of the model. Otherwise no amount of mathematical manipulation will persuade a reasonable individual that an outstanding or extreme result is probable when there is no evidence that rises to the same level.\n",
    "\n",
    "## Assumptions of the model about the sample data\n",
    "\n",
    "The data is assumed to be subject to the experience of the surveyor and each survey is independent and identically distributed. We add to these basic assumptions the particularities of the domain:\n",
    "\n",
    "1. Locations that have similar environmental conditions will yield similar survey results\n",
    "2. There is an exchange of material (trash) between the beach and body of water\n",
    "3. Following from two, the material recovered at the beach is a result of the assumed exchange\n",
    "4. The type of activities adjacent to the survey location are an indicator of the trash that will be found there\n",
    "5. Following from four and three, the local environmental conditions are an indicator of the local contribution to the mix of objects at the beach\n",
    "6. Surveys are not accurate\n",
    "   * Some objects will be misidentified\n",
    "   * Not all objects will be found\n",
    "   * There will be inaccuracies in object counts or data entry\n",
    "\n",
    "**Following 1 through 6:** the survey results are a reasonable estimate of the minimum number of objects that were present at the time the survey was completed. \n",
    "\n",
    "\n",
    "## Conditional probability\n",
    "\n",
    "[Conditional probability](https://en.wikipedia.org/wiki/Conditional_probability) is a fundamental concept in probability theory that describes the probability of an event occurring given that another event has already occurred. It is denoted as $P(A∣B)$, which reads as \"the probability of A given B\". \n",
    "\n",
    "The conditional probability of event \\(A\\) given event \\(B\\) is defined as:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $P(A|B)$ is the conditional probability of $A$ given $B$.\n",
    "- $P(A \\cap B)$ is the joint probability of both $A$ and $B$ occurring.\n",
    "- $P(B)$ is the probability of event $B$ occurring, provided that $P(B) > 0$.\n",
    "\n",
    "\n",
    "### Bayes' theorem\n",
    "\n",
    "[Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) is a fundamental principle in probability theory and statistics that describes the probability of an event based on __prior__ knowledge of conditions that might be related to the event. It allows for the updating of probabilities as new evidence or information becomes available. It is derived from the definition of conditional probability.\n",
    "\n",
    "__Deriving Bayes theorem__\n",
    "\n",
    "::::{grid} 2 2 2 2\n",
    ":gutter: 1\n",
    "\n",
    ":::{grid-item-card} Define conditional probability\n",
    "\n",
    "For events \\(A\\) and \\(B\\):\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "$$P(B|A) = \\frac{P(A \\cap B)}{P(A)}$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} The joint probability $P(A \\cap B)$\n",
    "\n",
    "From the first equation:\n",
    "\n",
    "$$P(A \\cap B) = P(A|B) \\cdot P(B)$$\n",
    "\n",
    "From the second equation:\n",
    "\n",
    "$$P(A \\cap B) = P(B|A) \\cdot P(A)$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} Equate the two expressions\n",
    "\n",
    "$$P(A|B) \\cdot P(B) = P(B|A) \\cdot P(A)$$\n",
    "\n",
    "Solve for $P(A|B)$\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} This is Bayes' Theorem\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    ":::\n",
    "::::\n",
    "\n",
    "#### Prior knowledge\n",
    "\n",
    "In the context of Bayes' theorem, the term \"prior\" refers to the prior probability, which is the probability of an event or hypothesis before any new evidence or data is taken into account. It represents the initial degree of belief in a particular outcome based on existing knowledge or assumptions.\n",
    "\n",
    "> In this use case the __prior__ is what we __beleive__ we will find at the beach, before we get to the beach, given everything we know about beaches and litter in Switzerland. Our beliefs are based on the cumulative experience from all previous visits to the beach, or beaches that are similar. Our beliefs come from what we have actually experienced.\n",
    "\n",
    "Mathematically, if we are trying to determine the probability of a hypothesis A given new evidence B, the prior probability is denoted as P(A). It is the baseline probability of A before considering the new evidence provided by B.\n",
    "\n",
    "Bayes' Theorem uses the prior probability along with the likelihood of the evidence given the hypothesis and the marginal probability of the evidence to update the probability of the hypothesis. This updated probability is called the posterior probability.\n",
    "\n",
    "### Empirical Bayes\n",
    "\n",
    "Empirical Bayes methods are statistical techniques that combine the principles of Bayesian inference with empirical data. These methods use data to estimate the prior distribution, which is then used in the Bayesian framework to update probabilities and make inferences. Using this method means that our prior distribution is testable in the sense of Jaynes\n",
    "\n",
    "> A piece of information _I_ concerning a parameter $\\theta$\u0012 will be called __testable__ if, given any proposed prior probability assignment  $f( \\theta )$ $d\\theta$, there is a procedure which will determine unambiguously whether $f( \\theta )$ does or does not agree with the information _I_. ([Jaynes,1968](https://bayes.wustl.edu/etj/articles/prior.pdf))\n",
    "\n",
    "In traditional Bayesian analysis, the prior distribution is chosen based on subjective beliefs or historical data. In contrast, empirical Bayes methods __estimate the prior distribution directly from the observed data, making the process more objective and often more practical in large-scale problems__. ([Petrone, S. et al, 2014](https://link.springer.com/article/10.1007/s40300-014-0044-1))\n",
    "\n",
    "#### Conjugate prior\n",
    "\n",
    "In Bayesian statistics, a [conjugate prior](https://en.wikipedia.org/wiki/Conjugate_prior) is a prior distribution that, when combined with a given likelihood through Bayes' theorem, results in a [posterior distribution](https://en.wikipedia.org/wiki/Posterior_probability) of the same family as the prior. This property simplifies the computation of the posterior distribution.\n",
    "\n",
    "1. Jaynes, E.T.: [\"Probability Theory: The Logic of Science\"](https://bayes.wustl.edu/etj/prob/book.pdf): Emphasized the logical consistency and practical advantages of conjugate priors.\n",
    "2. Gelman, A. et al.: [\"Bayesian Data Analysis\"](http://www.stat.columbia.edu/~gelman/book/) : discusses conjugate priors in the context of hierarchical models and practical Bayesian analysis.\n",
    "\n",
    "#### Deriving conjugate relationship\n",
    "\n",
    "The [binomial](https://en.wikipedia.org/wiki/Binomial_distribution), [multinomial](https://en.wikipedia.org/wiki/Multinomial_distribution), and [Dirichlet](https://en.wikipedia.org/wiki/Dirichlet_distribution) distributions are intrinsically linked through the concept of conjugate priors in Bayesian statistics. The binomial distribution describes the probability of a fixed number of successes in a series of independent trials, with a success probability _p_. When modeling this in a Bayesian framework, the Beta distribution is used as a conjugate prior for _p_. This means that the posterior distribution, after observing data, remains a Beta distribution, simplifying the update process.\n",
    "\n",
    "Extending this to multiple categories, the multinomial distribution generalizes the binomial by modeling the counts of outcomes across multiple categories. The Dirichlet distribution serves as the conjugate prior for the multinomial distribution, just as the Beta distribution does for the binomial. When using a Dirichlet prior, the posterior distribution after observing data also remains a Dirichlet distribution.\n",
    "\n",
    "::::{grid} 2 2 2 2\n",
    ":gutter: 1\n",
    "\n",
    ":::{grid-item-card} Binomial Likelihood:\n",
    "\n",
    "The binomial distribution models the number of successes in _n_ trials, given a success probability _p_:\n",
    "\n",
    "$$P(X = k | p) = \\binom{n}{k} p^k (1 - p)^{n - k}$$\n",
    "\n",
    "The Beta distribution is a conjugate prior for the binomial likelihood, parameterized by $\\alpha$ and $\\beta$:\n",
    "\n",
    "$$P(p | \\alpha, \\beta) = \\frac{p^{\\alpha - 1} (1 - p)^{\\beta - 1}}{B(\\alpha, \\beta)}$$\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} Posterior Distribution:\n",
    "\n",
    "Combining the likelihood and prior using Bayes' theorem gives the posterior distribution:\n",
    "\n",
    "$$P(p | k, n) \\propto p^k (1 - p)^{n - k} \\cdot p^{\\alpha - 1} (1 - p)^{\\beta - 1}$$\n",
    "\n",
    "$$P(p | k, n) \\propto p^{k + \\alpha - 1} (1 - p)^{n - k + \\beta - 1}$$\n",
    "\n",
    "Which is a Beta distribution:\n",
    "\n",
    "$$P(p | k, n) = \\text{Beta}(p | k + \\alpha, n - k + \\beta)$$\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} Generalize binomial to multinomial\n",
    "\n",
    "The multinomial distribution generalizes the binomial to more than two categories. For counts \n",
    "$\\mathbf{x} = (x_1, x_2, \\ldots, x_K) \\quad \\text{in} \\quad K \\quad \\text{categories, given probabilities} \\quad \\mathbf{p} = (p_1, p_2, \\ldots, p_K)$:\n",
    "\n",
    "$$P(\\mathbf{x} | \\mathbf{p}) = \\frac{n!}{x_1! x_2! \\cdots x_K!} p_1^{x_1} p_2^{x_2} \\cdots p_K^{x_K}$$\n",
    "\n",
    "where: $n = \\sum_{i=1}^K x_i$\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} The conjugate prior to the multinomial\n",
    "\n",
    "The Dirichlet distribution is a conjugate prior for the multinomial distribution, parameterized by α=(α1​,α2​,…,αK​):\n",
    "\n",
    "$P(\\mathbf{p} | \\boldsymbol{\\alpha}) = \\frac{1}{B(\\boldsymbol{\\alpha})} \\prod_{i=1}^K p_i^{\\alpha_i - 1}$\n",
    "\n",
    "where B(α) is the multivariate Beta function.\n",
    ":::\n",
    "\n",
    ":::{grid-item-card} Posterior Distribution\n",
    "The posterior distribution is a combination of the likelihood and prior:\n",
    "\n",
    "$$P(\\mathbf{p} | \\mathbf{x}) \\propto \\left( \\prod_{i=1}^K p_i^{x_i} \\right) \\left( \\prod_{i=1}^K p_i^{\\alpha_i - 1} \\right)$$\n",
    "\n",
    "Which is a Dirichlet distribution:\n",
    "\n",
    "$P(\\mathbf{p} | \\mathbf{x}) \\propto \\prod_{i=1}^K p_i^{x_i + \\alpha_i - 1}$\n",
    "\n",
    ":::\n",
    ":::{grid-item-card} Posterior with updated parameters\n",
    "\n",
    "$$P(\\mathbf{p}|\\mathbf{x}) = \\text{D}(\\mathbf{p}|x_1 + \\alpha_1, \\ldots, x_K + \\alpha_K)$$\n",
    "\n",
    "Where D is a _Dirichlet_ distribution\n",
    ":::\n",
    "::::\n",
    "\n",
    "#### Grid Approximation\n",
    "\n",
    "Grid approximation is a technique used in numerical analysis and statistical inference to approximate the values of a continuous function or parameter by evaluating it at a discrete set of points. This involves creating a grid of possible values within a defined range and calculating the function or parameter at each grid point. We are using $P(\\mathbf{p}|\\mathbf{x}) = \\text{D}(\\mathbf{p}|x_1 + \\alpha_1, \\ldots, x_K + \\alpha_K)$ to approximate the grid.\n",
    "\n",
    "### Empirical Bayes grid approximation using a conjugate prior\n",
    "\n",
    "Empirical Bayes grid approximations involves estimating the prior and posterior distributions of parameters using a discretized set of values. In the context of the multinomial-Dirichlet conjugate relationship, this method is particularly effective. The Dirichlet distribution serves as the prior for the multinomial likelihood, and empirical Bayes methods estimate this prior directly from the data. By defining a grid of possible parameter values, in this case spaced every 0.1 units from 0 to the maximum observed value or 100, the posterior distribution is approximated by evaluating the likelihood and updating the Dirichlet prior at each grid point.\n",
    "\n",
    "This approach simplifies the computational complexity of Bayesian inference. Instead of integrating over a continuous parameter space, which can be analytically challenging, grid approximation transforms the problem into a finite summation. The [multinomial-Dirichlet conjugate pair](https://en.wikipedia.org/wiki/Dirichlet-multinomial_distribution) ensures that the posterior remains in the Dirichlet family, making the updates straightforward.\n",
    "\n",
    "__Adding probability__\n",
    "\n",
    "We have noticed that using this method is sensitive to the max value of the likelihood. The further out the maximum is the more likely elevated values appear. This may be the case, but there is also the chance that extreme elements are just that.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244e5d0-e474-4fdf-9920-e66361fb59a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## The grid forecaster\n",
    "\n",
    "The _grid forecaster_ refers to the methods defined in `gridforecast.py`. The main purpose of the _grid forecaster_ is to implement the process described in the preceding sections. Here we define three methods for making a forecast for a particular region that are inline with the assumptions.\n",
    "\n",
    "__Given the experience in the past__\n",
    "\n",
    "1. The prior probability is based on the collection of all previous experiences in the region\n",
    "2. The prior probability is based on the 99th percentile of all previous experiences in the region\n",
    "\n",
    "__Given the experience in similar locations__\n",
    "\n",
    "3. The prior probability is based on the collection of experiences from locations with similar land use\n",
    "\n",
    "### Predict density from past experiences\n",
    "\n",
    "For regions that have a sampling history, previous to the most recent set of survey data, a forecast can be implemented by designating or selecting all the data in the region prior to the most recent survey results.\n",
    "\n",
    "__Example creating reports and forecasts__\n",
    "\n",
    "```python\n",
    "# collecting the default data\n",
    "data = session_config.collect_survey_data()\n",
    "\n",
    "# the likelihood: the dates of the most recent samples\n",
    "recent_dates = {'start':'2020-01-01', 'end':'2021-12-31'}\n",
    "# the prior: the dates prior to the most recent samples\n",
    "prior_dates = {'start':'2015-11-15', 'end':'2019-12-31'}\n",
    "# the region of interest\n",
    "canton = 'Vaud'\n",
    "\n",
    "# the search parameters for the prior and likelihood\n",
    "likelihood_params = {'canton':canton, 'date_range':recent_dates}\n",
    "prior_params = {'canton':canton, 'date_range':prior_dates}\n",
    "\n",
    "# verify the parameters exist in the data\n",
    "# checking the parameters will verify that the requested data\n",
    "# exists. If the query is possible it is executed and the value of\n",
    "# comments='ok', if not empty arrays are returned with the message\n",
    "# 'no survey results found'. The method returns the query data, a list\n",
    "# of the sample locations and the comment.\n",
    "likelihood_data, likelihood_locations, likelihood_comments = check_params(likelihood_params, data, logger)\n",
    "prior_data, prior_locations, prior_comments = check_params(prior_params, data, logger)\n",
    "\n",
    "# if there is data for both the likelihood and the prior\n",
    "# make a survey report and a land use report for both sets of data\n",
    "likelihood_report, likelihood_land_use = make_report_objects(likelihood_data)\n",
    "prior_report, prior_land_use = make_report_objects(likelihood_data)\n",
    "\n",
    "# make forecast from all the available liklihood data\n",
    "forecast_object = MulitnomialDirichlet('comb', prior_report.sample_results['pcs/m'], likelihood_report.sample_results['pcs/m'], logger)\n",
    "\n",
    "# make forecast limiting the likelihood to the 99the percentile\n",
    "posterior_counts, comments = posterior_dirichlet_counts(lkl, prr, max_range=0.99)\n",
    "\n",
    "# forecasts from all the data\n",
    "forecasted_samples = forecast_object.sample_posterior()\n",
    "forecasted_summary = forecast_object.get_descriptive_statistics()\n",
    "\n",
    "# forecasts limited to the 99th percentile\n",
    "sample_values_99, posterior_99, summary_99 = gfcast.dirichlet_posterior(posterior_counts)\n",
    "```\n",
    "\n",
    "### Predict density given similar locations\n",
    "\n",
    "To predict density given similar locations we need to create another prior experience, that does not include any of the locations that are in the likelihood. Furthermore, we need to ensure that the land-use conditions in the likelihood are reflected in the prior.\n",
    "\n",
    "```python\n",
    "# determine the proportion of each land-use feature in the likelihood\n",
    "weights = land_use_weights(likelihood_land_use, session_config.feature_variables)\n",
    "\n",
    "# from the pool of available data select records that are not included in the likelihood\n",
    "# in this case we eliminate the canton of interest, limit the date to the end date of the prior\n",
    "# and create a survey report and land use report for *the other prior data*\n",
    "other_data = data[(data.canton != canton)&(data['date'] <= prior_dates['end'])].copy()\n",
    "other_prior_report, other_prior_land_use = gfcast.make_report_objects(other_prior_data)\n",
    "\n",
    "# using the weights from the likelihood and the other_prior_land_use\n",
    "other_prior_data, prior_weights = select_prior_data_by_feature_weight(other_prior_land_use, weights, session_config.feature_variables)\n",
    "posterior_by_weight, weighted_comments = posterior_dirichlet_counts(likelihood_data, g['pcs/m'].values)\n",
    "posterior_sample_values, weighted_dist, weighted_summary = dirichlet_posterior(posterior_by_weight)\n",
    "\n",
    "```\n",
    "### Different priors = different points of view\n",
    "\n",
    "The three models are based off the experiences from the field and for the most part all give a reasonable estimate of what we would expect to find. The differences between the expected outcomes may or may not be of importance. We won't know untill we sample again.\n",
    "\n",
    "## Using the grid forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08211a6b-e1e9-4f98-bc27-1a377efefe43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import session_config\n",
    "import reports\n",
    "import geospatial\n",
    "import userdisplay as disp\n",
    "import gridforecast as gfcast\n",
    "\n",
    "# collecting the default data\n",
    "data = session_config.collect_survey_data()\n",
    "data = data.reset_index()\n",
    "\n",
    "# the likelihood: the dates of the most recent samples\n",
    "recent_dates = {'start':'2020-01-01', 'end':'2021-12-31'}\n",
    "# the prior: the dates prior to the most recent samples\n",
    "prior_dates = {'start':'2015-11-15', 'end':'2019-12-31'}\n",
    "# the region of interest\n",
    "canton = 'Vaud'\n",
    "\n",
    "# the search parameters for the prior and likelihood\n",
    "likelihood_params = {'canton':canton, 'date_range':recent_dates}\n",
    "prior_params = {'canton':canton, 'date_range':prior_dates}\n",
    "\n",
    "# verify the parameters exist in the data\n",
    "# checking the parameters will verify that the requested data\n",
    "# exists. If the query is possible it is executed and the value of\n",
    "# comments='ok', if not empty arrays are returned with the message\n",
    "# 'no survey results found'. The method returns the query data, a list\n",
    "# of the sample locations and the comment.\n",
    "likelihood_data, likelihood_locations, likelihood_comments = gfcast.check_params(likelihood_params, data, logger)\n",
    "prior_data, prior_locations, prior_comments = gfcast.check_params(prior_params, data, logger)\n",
    "\n",
    "# if there is data for both the likelihood and the prior\n",
    "# make a survey report and a land use report for both sets of data\n",
    "likelihood_report, likelihood_land_use = gfcast.make_report_objects(likelihood_data)\n",
    "prior_report, prior_land_use = gfcast.make_report_objects(prior_data)\n",
    "\n",
    "# make forecast from all the available liklihood data\n",
    "forecast_object = gfcast.MulitnomialDirichlet('comb', prior_report.sample_results['pcs/m'], likelihood_report.sample_results['pcs/m'], logger)\n",
    "\n",
    "# make forecast limiting the likelihood to the 99the percentile\n",
    "posterior_counts, comments = gfcast.posterior_dirichlet_counts(likelihood_report.sample_results['pcs/m'], prior_report.sample_results['pcs/m'], max_range=0.99)\n",
    "\n",
    "# forecasts from all the data\n",
    "forecasted_samples = forecast_object.sample_posterior()\n",
    "forecasted_summary = forecast_object.get_descriptive_statistics()\n",
    "\n",
    "# forecasts limited to the 99th percentile\n",
    "sample_values_99, posterior_99, summary_99 = gfcast.dirichlet_posterior(posterior_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f748fa9-f06b-423e-b92f-625c88ab6a38",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The grid size\n",
    "\n",
    "The grid size for each combination is based on the maximum value of either the likelihood or the prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206d8a29-58a9-48c8-b0bb-1cd1c1b6536d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 1.000e-02, 2.000e-02, ..., 7.707e+01, 7.708e+01,\n",
       "       7.709e+01])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9d5e8-f262-4dfb-afdf-e9b9cd379d9d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The counts\n",
    "\n",
    "The number of times that a survey result was either equal to zero or any other place on the grid can be accessed with `forecastobject.prior` or `forecastobject.compute_counts(forecast_object.prior_data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1034c511-5426-439e-a126-69dc42c7f8ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.prior_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d88436-fae1-42f9-82be-67a3d1f138c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The posterior parameters\n",
    "\n",
    "The parameters for the Dirichlet posterior: `forecastobject.compute_posterior_params(self)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "031d0089-a494-4944-8b03-02658f8655f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, ..., 0.01, 0.01, 1.  ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_posterior_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbddc94-6891-43b1-93b7-0ac635a81ba8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The posterior distribution\n",
    "\n",
    "The posterior distribution : `forecastobject.posterior_dist` is a `scipy.stats.dirichlet` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc590e3c-5db0-41ec-8102-9e29ff6228dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26850793e-05, 3.26850793e-05, 3.26850793e-05, ...,\n",
       "       3.26850793e-05, 3.26850793e-05, 3.26850793e-03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.posterior_dist.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f5c14-2a18-43fe-aa76-68e3e2832454",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Sample the posterior distribution\n",
    "\n",
    "Sample the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82a61b6a-b615-4068-8267-93ea238e0b37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1 ,  0.47,  0.71,  0.99,  1.16,  1.26,  1.65,  1.86,  1.86,\n",
       "        1.89,  1.89,  2.03,  2.1 ,  2.1 ,  2.21,  2.21,  2.21,  2.21,\n",
       "        2.29,  2.29,  2.56,  2.56,  2.6 ,  2.68,  2.75,  2.75,  2.77,\n",
       "        3.11,  3.19,  3.27,  3.35,  3.59,  3.73,  3.73,  3.81,  3.81,\n",
       "        4.  ,  4.  ,  4.  ,  4.17,  4.22,  4.42,  4.55,  4.59,  5.12,\n",
       "        5.26,  5.34,  5.36,  5.43,  5.59,  5.8 ,  6.04,  6.04,  6.13,\n",
       "        6.15,  6.25,  6.59,  6.88,  6.97,  6.97,  7.26,  8.38,  8.92,\n",
       "        9.45,  9.45,  9.45, 10.07, 10.08, 10.67, 12.36, 15.01, 15.01,\n",
       "       16.36, 17.52, 17.52, 17.52, 17.89, 17.89, 18.36, 18.36, 18.97,\n",
       "       22.38, 23.18, 23.5 , 23.65, 23.65, 23.73, 23.73, 38.69, 41.85,\n",
       "       50.06, 53.78, 60.34, 60.61, 61.06, 61.06, 61.06, 62.89, 64.4 ,\n",
       "       75.67])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.sample_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd61195-625f-471d-b734-d13f205bb7b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The 90% interval of the predictions\n",
    "\n",
    "The 90% interval of the predictions : `forecast_object.compute_percentiles()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c992bb-936d-4dd0-818e-67370310d8f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.589,  2.77 ,  6.26 , 13.75 , 59.73 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_percentiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdbde354-e3e5-400f-b856-9195d364e827",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 44911,\n",
       " 'nsamples': 142,\n",
       " 'average': 8.371830985915492,\n",
       " 'quantiles': array([ 0.812 ,  2.6925,  4.905 ,  9.63  , 28.09  ]),\n",
       " 'std': 10.433750262241018,\n",
       " 'max': 77.1,\n",
       " 'start': Timestamp('2015-11-23 00:00:00'),\n",
       " 'end': Timestamp('2019-10-24 00:00:00')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_report.sampling_results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "555eaa93-2b68-4641-a818-4fac2c9a0ad3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7710\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "t = forecast_object.prior \n",
    "print(len(t))\n",
    "print(sum(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1efa0-9bdb-4da3-a3f5-ed7931e6a652",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c96e73-5c75-47cc-9f12-17e732394e87",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
