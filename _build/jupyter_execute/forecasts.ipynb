{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c16819-72da-4b47-a3aa-988d3f5a8203",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import dirichlet\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from myst_nb import glue\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from scipy.stats import halfnorm, multinomial\n",
    "import gridforecast as gfcast\n",
    "\n",
    "# available data\n",
    "\n",
    "columns =  [\n",
    "    'sample_id',\n",
    "    'code',\n",
    "    'quantity',\n",
    "    'pcs/m',\n",
    "    'feature_name',\n",
    "    'location',\n",
    "    'parent_boundary',\n",
    "    'city', \n",
    "    'canton',\n",
    "    'feature_type',\n",
    "    'date'\n",
    "]\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='app.log', \n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_jeffreys_prior_matrix(index_range, categories, epsilon=0.01):\n",
    "    # Initialize the matrix\n",
    "    jeffreys_prior_matrix = np.zeros((len(index_range), len(categories)))\n",
    "    \n",
    "    # Calculate Jeffreys prior values using the modified formula\n",
    "    for i, x in enumerate(index_range):\n",
    "        prior = 1 / (x + epsilon)  # Adding epsilon to avoid division by zero\n",
    "        # Assign this value to all categories for this index\n",
    "        jeffreys_prior_matrix[i, :] = prior\n",
    "    \n",
    "    return jeffreys_prior_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244e5d0-e474-4fdf-9920-e66361fb59a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(forecast-class)=\n",
    "# Grid forecast class\n",
    "\n",
    "The _grid forecaster_ refers to the methods defined in `gridforecast.py`. The main purpose of the _grid forecaster_ is to implement estimate the probability that a survey result _y_ from a collection of survey results _Y_ will exceed a value _x_ on the grid _X_ from 0 - max(_X_) for every _x_ spaced 0.1, where max(_X_) is defined by _Y_. This is called a grid approximation, in this case we use a Bayesien framework and implement _multinomila-Dirichlet_ conjugate to estimate the probabilities on each point of the grid. The complete method is a defined in [grid approximation](gridforecaster).\n",
    "\n",
    "The grid forecast for any two arrays can be initiated by calling `gridforecast.MulitnomialDirichlet` and providing two pd.series of float values. However, for reporting we use the grid forecast to supplement the [SurveyReport](surveyreporter) and the [LandUseReport](landusereporter).\n",
    "\n",
    "```{note}\n",
    "The grid forecast allows us to estimate the probability of a set of survey results given another set of survey results. Therefore, to interpret the results of a grid forecast the relationship between the two arrays must be well understood. Our focus has been on the structural and geographic similarities of the survey locations.\n",
    "```\n",
    "\n",
    "__Example creating reports and forecasts__\n",
    "\n",
    "```python\n",
    "# collecting the default data\n",
    "data = session_config.collect_survey_data()\n",
    "\n",
    "# the likelihood: the dates of the most recent samples\n",
    "recent_dates = {'start':'2020-01-01', 'end':'2021-12-31'}\n",
    "# the prior: the dates prior to the most recent samples\n",
    "prior_dates = {'start':'2015-11-15', 'end':'2019-12-31'}\n",
    "# the region of interest\n",
    "canton = 'Vaud'\n",
    "\n",
    "# the search parameters for the prior and likelihood\n",
    "likelihood_params = {'canton':canton, 'date_range':recent_dates}\n",
    "prior_params = {'canton':canton, 'date_range':prior_dates}\n",
    "\n",
    "# verify the parameters exist in the data\n",
    "# checking the parameters will verify that the requested data\n",
    "# exists. If the query is possible it is executed and the value of\n",
    "# comments='ok', if not empty arrays are returned with the message\n",
    "# 'no survey results found'. The method returns the query data, a list\n",
    "# of the sample locations and the comment.\n",
    "likelihood_data, likelihood_locations, likelihood_comments = check_params(likelihood_params, data, logger)\n",
    "prior_data, prior_locations, prior_comments = check_params(prior_params, data, logger)\n",
    "\n",
    "# if there is data for both the likelihood and the prior\n",
    "# make a survey report and a land use report for both sets of data\n",
    "likelihood_report, likelihood_land_use = make_report_objects(likelihood_data)\n",
    "prior_report, prior_land_use = make_report_objects(likelihood_data)\n",
    "\n",
    "# make forecast from all the available liklihood data\n",
    "forecast_object = MulitnomialDirichlet('comb', prior_report.sample_results['pcs/m'], likelihood_report.sample_results['pcs/m'], logger)\n",
    "\n",
    "# make forecast limiting the likelihood to the 99the percentile\n",
    "posterior_counts, comments = posterior_dirichlet_counts(lkl, prr, max_range=0.99)\n",
    "\n",
    "# forecasts from all the data\n",
    "forecasted_samples = forecast_object.sample_posterior()\n",
    "forecasted_summary = forecast_object.get_descriptive_statistics()\n",
    "\n",
    "# forecasts limited to the 99th percentile\n",
    "sample_values_99, posterior_99, summary_99 = gfcast.dirichlet_posterior(posterior_counts)\n",
    "```\n",
    "\n",
    "__Using a weighted prior__\n",
    "\n",
    "To predict density given similar locations use the land-use report from a set survey results that does not contain any of the survey locations from the likelihood. The default method is to also only select values that have the same use case ie. parks, lakes or rivers. \n",
    "\n",
    "```python\n",
    "# determine the proportion of each land-use feature in the likelihood\n",
    "weights = land_use_weights(likelihood_land_use, session_config.feature_variables)\n",
    "\n",
    "# from the pool of available data select records that are not included in the likelihood\n",
    "# in this case we eliminate the canton of interest, limit the date to the end date of the prior\n",
    "# and create a survey report and land use report for *the other prior data*\n",
    "other_data = data[(data.canton != canton)&(data['date'] <= prior_dates['end'])].copy()\n",
    "other_prior_report, other_prior_land_use = gfcast.make_report_objects(other_prior_data)\n",
    "\n",
    "# using the weights from the likelihood and the other_prior_land_use\n",
    "other_prior_data, prior_weights = select_prior_data_by_feature_weight(other_prior_land_use, weights, session_config.feature_variables)\n",
    "posterior_by_weight, weighted_comments = posterior_dirichlet_counts(likelihood_data, g['pcs/m'].values)\n",
    "posterior_sample_values, weighted_dist, weighted_summary = dirichlet_posterior(posterior_by_weight)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08211a6b-e1e9-4f98-bc27-1a377efefe43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import session_config\n",
    "import reports\n",
    "import geospatial\n",
    "import userdisplay as disp\n",
    "import gridforecast as gfcast\n",
    "\n",
    "# collecting the default data\n",
    "data = session_config.collect_survey_data()\n",
    "data = data.reset_index()\n",
    "\n",
    "# the likelihood: the dates of the most recent samples\n",
    "recent_dates = {'start':'2020-01-01', 'end':'2021-12-31'}\n",
    "# the prior: the dates prior to the most recent samples\n",
    "prior_dates = {'start':'2015-11-15', 'end':'2019-12-31'}\n",
    "# the region of interest\n",
    "canton = 'Vaud'\n",
    "\n",
    "# the search parameters for the prior and likelihood\n",
    "likelihood_params = {'canton':canton, 'date_range':recent_dates}\n",
    "prior_params = {'canton':canton, 'date_range':prior_dates}\n",
    "\n",
    "# verify the parameters exist in the data\n",
    "# checking the parameters will verify that the requested data\n",
    "# exists. If the query is possible it is executed and the value of\n",
    "# comments='ok', if not empty arrays are returned with the message\n",
    "# 'no survey results found'. The method returns the query data, a list\n",
    "# of the sample locations and the comment.\n",
    "likelihood_data, likelihood_locations, likelihood_comments = gfcast.check_params(likelihood_params, data, logger)\n",
    "prior_data, prior_locations, prior_comments = gfcast.check_params(prior_params, data, logger)\n",
    "\n",
    "# if there is data for both the likelihood and the prior\n",
    "# make a survey report and a land use report for both sets of data\n",
    "likelihood_report, likelihood_land_use = gfcast.make_report_objects(likelihood_data)\n",
    "prior_report, prior_land_use = gfcast.make_report_objects(prior_data)\n",
    "\n",
    "# make forecast from all the available liklihood data\n",
    "forecast_object = gfcast.MulitnomialDirichlet('comb', prior_report.sample_results['pcs/m'], likelihood_report.sample_results['pcs/m'], logger)\n",
    "\n",
    "# make forecast limiting the likelihood to the 99the percentile\n",
    "posterior_counts, comments = gfcast.posterior_dirichlet_counts(likelihood_report.sample_results['pcs/m'], prior_report.sample_results['pcs/m'], max_range=0.99)\n",
    "\n",
    "# forecasts from all the data\n",
    "forecasted_samples = forecast_object.sample_posterior()\n",
    "forecasted_summary = forecast_object.get_descriptive_statistics()\n",
    "\n",
    "# forecasts limited to the 99th percentile\n",
    "sample_values_99, posterior_99, summary_99 = gfcast.dirichlet_posterior(posterior_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f748fa9-f06b-423e-b92f-625c88ab6a38",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Grid forecaster methods\n",
    "\n",
    "The `gridforecast.MulitnomialDirichlet` is a class in `gridforecast.py` the built in methods are designed to generate forecasts under a variety of scenarios and provide the basic elements to evaluate those forecasts. In the examples below consider the forecast_object created in the previous example.\n",
    "\n",
    "__list of methods__\n",
    "\n",
    "1. MultinomialDirichlet\n",
    "   * compute_grid\n",
    "   * compute_counts\n",
    "   * compute_posterior_params\n",
    "   * sample_posterior\n",
    "   * compute_percentiles\n",
    "   * compute_hdi\n",
    "   * compute_expected_average\n",
    "   * probability_of_x\n",
    "   * get_descriptive_statistics\n",
    "2. select_prior_data_by_feature_weight\n",
    "3. posterior_dirichlet_counts\n",
    "4. dirichlet_posterior\n",
    "\n",
    "### The grid size\n",
    "\n",
    "The grid size for each combination is based on the maximum value of either the likelihood or the prior. \n",
    "\n",
    "```python\n",
    "def compute_grid(self):\n",
    "    max_value = round(max(self.prior_data.max(), self.likelihood_data.max()), 1)\n",
    "    return np.arange(0, max_value, 0.01)\n",
    "\n",
    "forecast_object.compute_grid()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206d8a29-58a9-48c8-b0bb-1cd1c1b6536d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 1.000e-02, 2.000e-02, ..., 7.707e+01, 7.708e+01,\n",
       "       7.709e+01])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9d5e8-f262-4dfb-afdf-e9b9cd379d9d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The counts\n",
    "\n",
    "The number of times that a survey result was either equal to zero or any other place on the grid can be accessed with `forecastobject.prior` or `forecastobject.likelihood`. This returns the value of `np.histogram`\n",
    "\n",
    "```python\n",
    "def compute_counts(self, data):\n",
    "    counts, _ = np.histogram(data, bins=np.append(self.grid, self.grid[-1] + 0.1))\n",
    "    return counts\n",
    "\n",
    "\n",
    "forecastobject.compute_counts(forecast_object.prior_data)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1034c511-5426-439e-a126-69dc42c7f8ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_counts(forecast_object.prior_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d88436-fae1-42f9-82be-67a3d1f138c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The posterior parameters\n",
    "\n",
    "The parameters for the Dirichlet posterior. This is the sum of `forecastobject.prior` and `forecastobject.likelihood`. Zero values of the sum are replaced with 0.01.\n",
    "\n",
    "```python\n",
    "def compute_posterior_params(self):\n",
    "    post_counts = self.likelihood + self.prior\n",
    "    post_counts = np.where(post_counts > 0, post_counts, 0.01)\n",
    "    return post_counts\n",
    "    \n",
    "forecastobject.compute_posterior_params()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031d0089-a494-4944-8b03-02658f8655f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, ..., 0.01, 0.01, 1.  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_posterior_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010dc2f7-db6b-433c-9e31-0fdd3f1e2607",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Sample the posterior distribution\n",
    "\n",
    "Sample the posterior distribution. Returns a set of expected survey values given the likelihood and the prior.\n",
    "\n",
    "```python\n",
    "def sample_posterior(self, num_samples=100):\n",
    "    adist_samples = self.posterior_dist.rvs(1)[0]\n",
    "    posterior_samples = multinomial.rvs(num_samples, adist_samples)\n",
    "    sample_values = np.repeat(self.grid, posterior_samples)\n",
    "    return sample_values\n",
    "    \n",
    "forecast_object.sample_posterior()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a61b6a-b615-4068-8267-93ea238e0b37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35,  0.47,  0.47,  0.47,  0.55,  0.75,  0.92,  0.99,  1.  ,\n",
       "        1.  ,  1.06,  1.89,  1.89,  1.99,  2.21,  2.23,  2.29,  2.32,\n",
       "        2.4 ,  2.56,  2.6 ,  2.61,  2.61,  2.64,  2.64,  2.68,  2.7 ,\n",
       "        2.74,  2.86,  3.19,  3.42,  3.46,  3.46,  4.17,  4.2 ,  4.55,\n",
       "        4.67,  4.67,  4.67,  4.74,  4.74,  4.76,  4.93,  5.43,  5.75,\n",
       "        5.87,  6.04,  6.04,  6.59,  6.83,  6.83,  7.04,  7.04,  7.85,\n",
       "        7.85,  8.19,  8.55,  8.55,  8.55,  8.55,  8.92,  9.05, 10.08,\n",
       "       10.08, 11.21, 13.6 , 14.61, 15.37, 16.36, 17.05, 17.4 , 17.54,\n",
       "       21.16, 23.18, 26.11, 26.41, 26.82, 27.33, 31.6 , 33.63, 38.  ,\n",
       "       39.84, 41.37, 47.28, 47.28, 47.28, 47.28, 49.68, 50.06, 50.6 ,\n",
       "       51.46, 51.46, 55.83, 57.71, 57.71, 65.91, 67.34, 69.75, 73.5 ,\n",
       "       73.5 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.sample_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15028961-3710-4bab-8f72-f8bb31b77689",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The 90% interval of the predictions\n",
    "\n",
    "The 90% interval of the predictions is set to the following percentiles: [5, 25, 50, 75, 95] \n",
    "\n",
    "```python\n",
    "def compute_percentiles(self, percentiles=[5, 25, 50, 75, 95]):\n",
    "    samples = self.sample_posterior(1000)\n",
    "    return np.percentile(samples, percentiles)\n",
    "\n",
    "forecast_object.compute_percentiles()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c992bb-936d-4dd0-818e-67370310d8f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75  ,  2.7   ,  5.36  , 13.85  , 62.3315])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_percentiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbddc94-6891-43b1-93b7-0ac635a81ba8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The 90% HDI\n",
    "\n",
    "The 90% highest density interval\n",
    "\n",
    "```python\n",
    "def compute_hdi(self, credibility_mass=0.95):\n",
    "    samples = self.sample_posterior(1000)\n",
    "    sorted_samples = np.sort(samples)\n",
    "    ci_idx_inc = int(np.floor(credibility_mass * len(sorted_samples)))\n",
    "    n_cis = len(sorted_samples) - ci_idx_inc\n",
    "    ci_width = sorted_samples[ci_idx_inc:] - sorted_samples[:n_cis]\n",
    "    min_ci_width_idx = np.argmin(ci_width)\n",
    "    hdi_min = sorted_samples[min_ci_width_idx]\n",
    "    hdi_max = sorted_samples[min_ci_width_idx + ci_idx_inc]\n",
    "    \n",
    "    return hdi_min, hdi_max\n",
    "    \n",
    "forecast_object.compute_hdi()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc590e3c-5db0-41ec-8102-9e29ff6228dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.1), np.float64(63.58))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_hdi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8cf38-afad-4478-bc3a-78d3b13696ac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The expected mean\n",
    "\n",
    "The 90% highest density interval\n",
    "\n",
    "```python\n",
    "forecast_object.compute_hdi()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3d7ed3a-db17-4b5b-922c-22fd67180839",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26850793e-05, 3.26850793e-05, 3.26850793e-05, ...,\n",
       "       3.26850793e-05, 3.26850793e-05, 3.26850793e-03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.compute_expected_average()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c307cb-55cf-479b-aa52-81f003d1805f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The probability of x\n",
    "\n",
    "The chance that a result will exceed a given value\n",
    "\n",
    "```python\n",
    "def probability_of_x(self, x):\n",
    "    if x < 0 or x > self.grid.max():\n",
    "        raise ValueError(\"x must be within the range of the grid.\")\n",
    "\n",
    "    posterior_samples = self.posterior_dist.rvs(1000)\n",
    "    mp = np.mean(posterior_samples, axis=0)\n",
    "    bin_index = np.digitize([x], self.grid)\n",
    "    \n",
    "    return mp, bin_index, posterior_samples\n",
    "\n",
    "# in this case we are asking what is the chance of finding\n",
    "# at least one piece per meter\n",
    "a, b, c = forecast_object.probability_of_x(1)\n",
    "sum(a[b[0]:])\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f30a4ec-095b-47f0-bff5-cdec32353bcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9290825128991368)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c = forecast_object.probability_of_x(1)\n",
    "sum(a[b[0]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff79642-0521-4b49-b91a-2481df990a9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The descriptive statistices\n",
    "\n",
    "The average, hdi and the 90% range of the expected distribution\n",
    "\n",
    "```python\n",
    "forecast_object.get_descriptive_statistics()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c96e73-5c75-47cc-9f12-17e732394e87",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 'comb',\n",
       " 'average': np.float64(11.853500000000002),\n",
       " 'hdi': (np.float64(0.1), np.float64(58.730000000000004)),\n",
       " 'range': array([ 0.9895,  2.57  ,  5.59  , 18.42  , 61.5595]),\n",
       " 'max_observed': np.float64(77.1)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_object.get_descriptive_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109016ba-7ff3-4fb9-a425-5acb8b107caf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Select prior data by feature weight\n",
    "\n",
    "\n",
    "The average, hdi and the 90% range of the expected distribution\n",
    "\n",
    "```python\n",
    "# get the land use weights from the observations of interest\n",
    "weights = land_use_weights(likelihood_land_use, feature_variables)\n",
    "\n",
    "# prior data does not include locations in canton\n",
    "# the surveys are limited to the prior date as defined\n",
    "other_data = data[(data.canton != canton)&(data['date'] <= prior_dates['end'])].copy()\n",
    "other_report, landuse_from_other = gfcast.make_report_objects(other_data)\n",
    "\n",
    "# use the land use object from the other data\n",
    "# and the weights from the likelihood to draw random\n",
    "# samples from the other data\n",
    "the_random_samples, w = select_prior_data_by_feature_weight(landuse_from_other, weights, feature_variables)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "768b10bc-a72e-4e38-b41e-bbfde0865818",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# get the land use weights from the observations of interest\n",
    "weights = gfcast.land_use_weights(likelihood_land_use, session_config.feature_variables)\n",
    "\n",
    "# prior data does not include locations in canton\n",
    "# the surveys are limited to the prior date as defined\n",
    "other_data = data[(data.canton != canton)&(data['date'] <= prior_dates['end'])].copy()\n",
    "other_report, landuse_from_other = gfcast.make_report_objects(other_data)\n",
    "\n",
    "# use the land use object from the other data\n",
    "# and the weights from the likelihood to draw random\n",
    "# samples from the other data\n",
    "the_random_samples, new_weights = gfcast.select_prior_data_by_feature_weight(landuse_from_other.df_cat, weights, session_config.feature_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb0e9b77-104e-4e3b-9a60-dd644df6d408",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>pcs/m</th>\n",
       "      <th>public services</th>\n",
       "      <th>streets</th>\n",
       "      <th>orchards</th>\n",
       "      <th>vineyards</th>\n",
       "      <th>buildings</th>\n",
       "      <th>forest</th>\n",
       "      <th>undefined</th>\n",
       "      <th>buildings_public services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('sihl_zuerich_eichenbergerd', '2018-03-30')</td>\n",
       "      <td>sihl_zuerich_eichenbergerd</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>17</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('emme_biberist_jennim', '2017-08-07')</td>\n",
       "      <td>emme_biberist_jennim</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>29</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('zuerichsee_staefa_hennm', '2017-05-22')</td>\n",
       "      <td>zuerichsee_staefa_hennm</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>65</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('langete_langenthal_geiserm', '2018-03-30')</td>\n",
       "      <td>langete_langenthal_geiserm</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>22</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('chriesbach_duebendorf_schneidera', '2018-02-...</td>\n",
       "      <td>chriesbach_duebendorf_schneidera</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>99</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample_id  \\\n",
       "0       ('sihl_zuerich_eichenbergerd', '2018-03-30')   \n",
       "1             ('emme_biberist_jennim', '2017-08-07')   \n",
       "2          ('zuerichsee_staefa_hennm', '2017-05-22')   \n",
       "3       ('langete_langenthal_geiserm', '2018-03-30')   \n",
       "4  ('chriesbach_duebendorf_schneidera', '2018-02-...   \n",
       "\n",
       "                           location       date  quantity  pcs/m  \\\n",
       "0        sihl_zuerich_eichenbergerd 2018-03-30        17   0.35   \n",
       "1              emme_biberist_jennim 2017-08-07        29   1.95   \n",
       "2           zuerichsee_staefa_hennm 2017-05-22        65   5.90   \n",
       "3        langete_langenthal_geiserm 2018-03-30        22   1.55   \n",
       "4  chriesbach_duebendorf_schneidera 2018-02-05        99   1.94   \n",
       "\n",
       "  public services streets orchards vineyards buildings forest undefined  \\\n",
       "0               1       2        1         1         2      2         2   \n",
       "1               1       1        1         1         3      2         2   \n",
       "2               1       1        1         1         2      1         3   \n",
       "3               1       2        1         1         3      1         2   \n",
       "4               1       2        1         1         4      1         1   \n",
       "\n",
       "  buildings_public services  \n",
       "0                         1  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_random_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9da42-da80-43ab-ae12-add35fdedb3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Posterior Dirichlet counts\n",
    "\n",
    "The posterior distribution from the likelihood and the weighted prior.\n",
    "\n",
    "```python\n",
    "# get the land use weights from the observations of interest\n",
    "likelihood = likelihood_report.sample_results['pcs/m'].values\n",
    "prior = the_random_samples['pcs/m'].values\n",
    "posterior_by_weight, comments = posterior_dirichlet_counts(likelihood, prior)\n",
    "sample_values, adist, summary = dirichlet_posterior(posterior_by_weight)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e065188-22ed-4494-98b5-7e16de471634",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'range': array([0.3 , 0.9 , 1.85, 4.7 , 9.18]),\n",
       " 'nsamples': 100,\n",
       " 'average': np.float64(3.5840000000000005),\n",
       " 'hdi': (np.float64(0.1), np.float64(10.700000000000001))}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = likelihood_report.sample_results['pcs/m'].values\n",
    "prior = the_random_samples['pcs/m'].values\n",
    "posterior_by_weight, comments = gfcast.posterior_dirichlet_counts(likelihood, prior)\n",
    "sample_values, adist, summary = gfcast.dirichlet_posterior(posterior_by_weight)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}