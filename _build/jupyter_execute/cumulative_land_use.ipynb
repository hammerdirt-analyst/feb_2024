{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e39e538-f20c-4fa0-954e-b17552001446",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "import pandas as pd\n",
    "import setvariables as conf_\n",
    "import reportclass as r_class\n",
    "from typing import Type, Optional, Callable\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb27b90-2bbe-4fc9-bb47-ed244e4bdba0",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def match_topo_attributes_to_surveys(topo_data: pd.DataFrame, survey_data: pd.DataFrame)-> Tuple[pd.DataFrame,List]:\n",
    "    \"\"\"\n",
    "    Match topographic attributes to survey data for specific locations.\n",
    "\n",
    "    This function takes topographic attribute data and survey data and matches them based on the unique locations (slugs).\n",
    "    \n",
    "    Parameters:\n",
    "        topo_data (pd.DataFrame): A DataFrame containing topographic attribute data.\n",
    "        survey_data (pd.DataFrame): A DataFrame containing survey data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, List]: A tuple containing two elements:\n",
    "            - A DataFrame containing topographic attribute data for locations found in both datasets.\n",
    "            - A list of locations (slugs) from the survey data for which there is no matching topographic data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    locations = survey_data.slug.unique()\n",
    "    available = topo_data.index\n",
    "    # identify the locations that have no topo data\n",
    "    no_data = [x for x in locations if x not in available]\n",
    "\n",
    "    # take the available data and names of locations with no data\n",
    "    locations_with_data = [x for x in locations if x in available]\n",
    "    \n",
    "    return topo_data.loc[locations_with_data], no_data\n",
    "\n",
    "def merge_topodata_and_surveydata(topo, surveys, columns: List[str] = conf_.work_columns)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge survey data with topographic data using location information.\n",
    "\n",
    "    This function merges survey data with topographic data using the 'slug' column in the survey data\n",
    "    and the index of the topographic data. The merged DataFrame will contain the specified columns from the survey data.\n",
    "\n",
    "    Parameters:\n",
    "        topo (pd.DataFrame): A DataFrame containing topographic data with the location index.\n",
    "        surveys (pd.DataFrame): A DataFrame containing survey data with a 'slug' column for location matching.\n",
    "        columns (List[str]): A list of column names to include in the merged DataFrame (default is defined in conf.work_columns).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A merged DataFrame containing the specified survey data columns and topographic data.\n",
    "    \"\"\"\n",
    "    # merges surveys to topo using the slug column in surveys\n",
    "    # and the index in topo\n",
    "    return surveys[columns].merge(topo, left_on='slug', right_index=True)\n",
    "\n",
    "def scale_a_column(df: pd.DataFrame, column_to_scale: str, column_name: str = 'length'):    \n",
    "\n",
    "    # Calculate the minimum and maximum values in the column\n",
    "    min_value = df[column_to_scale].min()\n",
    "    max_value = df[column_to_scale].max()\n",
    "\n",
    "    # Perform min-max scaling on a temp column\n",
    "    df['scalex'] = (df[column_to_scale] - min_value) / (max_value - min_value)\n",
    "    # reassign the value\n",
    "    df[column_name] = df['scalex']\n",
    "    # drop the temp\n",
    "    df.drop('scalex', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def group_topographic_attributes(df: pd.DataFrame, list_of_labels: List = None, locations: List = None, coi: str = 'scale')-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Group and aggregate topographic attributes in a DataFrame.\n",
    "\n",
    "    This function groups and aggregates topographic attributes in the provided DataFrame. You can specify a list of labels\n",
    "    to group attributes, filter locations, and choose the column of interest for aggregation.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): A DataFrame containing topographic attributes.\n",
    "        list_of_labels (List, optional): A list of dictionaries with keys as new attribute names and values as properties to group.\n",
    "        locations (List, optional): A list of locations to filter the data (default is None, no location filtering).\n",
    "        coi (str, optional): The column of interest for aggregation (default is 'scale').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with aggregated topographic attributes based on the specified grouping and filtering.\n",
    "   \"\"\"\n",
    "    \n",
    "    if locations is not None:\n",
    "        df = df.loc[df.slug.isin(locations)]    \n",
    "    # list of labels is a list of dictionaries\n",
    "    if list_of_labels is not None:\n",
    "        for new_labels in list_of_labels:\n",
    "            # the attributes, the dictionary values are \n",
    "            # properties being grouped\n",
    "            attributes = list(new_labels.values())\n",
    "            # the dictionary key is the new name of\n",
    "            # the attributes in the list\n",
    "            new_val = list(new_labels.keys())\n",
    "            df.loc[df['attribute'].isin(attributes[0]), 'attribute'] = new_val[0]\n",
    "    # sum the occurrences of the same attribute\n",
    "    r = df.groupby(['slug','attribute'], as_index=False)[coi].sum()\n",
    "\n",
    "    # pivot and set the index to the locations\n",
    "    # have the attributes\n",
    "    r = r.pivot(columns='attribute', index='slug')            \n",
    "            \n",
    "    return r.droplevel(0, axis=1).fillna(0)\n",
    "\n",
    "def statistic_of_critical_value(df, \n",
    "                                df_feature_columns, \n",
    "                                df_target_column, \n",
    "                                sample_id: str = 'loc_date',\n",
    "                                value_counts: bool = True,\n",
    "                                average: bool = False):\n",
    "    \"\"\"\n",
    "    Compute statistics of critical values for given data.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing the data.\n",
    "    df_feature_columns (list): A list of columns to be used as feature columns.\n",
    "    df_target_column (list): A list of columns to be used as target columns.\n",
    "    sample_id (str, optional): The column representing sample identifiers (default is 'loc_date').\n",
    "    value_counts (bool, optional): If True, compute value counts as weights (default is True).\n",
    "    average (bool, optional): If True, compute the median for the feature columns (default is False).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing computed statistics based on the specified options.\n",
    "    \"\"\"\n",
    "    d = pd.melt(df, value_vars=df_feature_columns, id_vars=[df_target_column, sample_id])\n",
    "    \n",
    "    if value_counts:\n",
    "        di = d.groupby('variable', as_index=False)['value'].value_counts()\n",
    "        di['weight'] = di['count']/d[sample_id].nunique()\n",
    "        di = di.pivot(columns='variable', index='value', values='weight')\n",
    "    if average:        \n",
    "        di = d.groupby(['variable', 'value'], as_index=False)[df_target_column].median()\n",
    "        di = di.pivot(columns='variable', index='value', values=df_target_column)\n",
    "                \n",
    "    return di\n",
    "\n",
    "class LandUse:\n",
    "    \"\"\"\n",
    "    A class for analyzing and transforming land use data.\n",
    "\n",
    "    This class provides methods to analyze land cover, land use, and transportation data.\n",
    "    It allows you to group attributes, scale data, and create ordinal rankings based on quantiles.\n",
    "\n",
    "    Parameters:\n",
    "        land_cover (pd.DataFrame): DataFrame containing land cover data.\n",
    "        land_use (pd.DataFrame): DataFrame containing land use data.\n",
    "        transportation (pd.DataFrame): DataFrame containing transportation data.\n",
    "        locations (List): List of locations for filtering data.\n",
    "        street_groups (List, optional): List of street groups (default is from configuration).\n",
    "        land_use_groups (List, optional): List of land use groups (default is from configuration).\n",
    "\n",
    "    Attributes:\n",
    "        quantiles (List): List of quantile values for ordinal ranking.\n",
    "        labels (List): List of labels corresponding to quantile groups.\n",
    "\n",
    "    Properties:\n",
    "        - land_cover: Grouped and aggregated land cover data.\n",
    "        - land_use: Grouped and aggregated land use data.\n",
    "        - trans: Grouped and aggregated transportation data.\n",
    "        - use_of_land: Combined data with the option to scale the columns between 0 and 1.\n",
    "        - ordinal_land_rank: Ordinal ranking based on quantiles for land use data.\n",
    "\n",
    "    Example:\n",
    "        land_use_data = LandUse(land_cover_data, land_use_data, transportation_data, locations)\n",
    "        land_cover = land_use_data.land_cover\n",
    "        land_use = land_use_data.land_use\n",
    "        trans_data = land_use_data.trans(new_labels=[{'new_attr': ['attr1', 'attr2']}])\n",
    "        land_rankings = land_use_data.ordinal_land_rank\n",
    "    \"\"\"\n",
    "    street_groups = conf_.street_groups\n",
    "    land_use_groups = conf_.lu_groups\n",
    "\n",
    "    def __init__(self, land_cover, land_use, transportation, locations, street_groups=street_groups, land_use_groups=land_use_groups):\n",
    "        self.lc = land_cover\n",
    "        self.lu = land_use\n",
    "        self.tr = transportation\n",
    "        self.locations = locations\n",
    "        self.lug = land_use_groups\n",
    "        self.stg = street_groups\n",
    "        self.quantiles = [0.0, 0.03, 0.25, 0.75, 0.97, 1.0]\n",
    "        self. labels = ['lowest', 'low', 'middle', 'high', 'highest']\n",
    "        \n",
    "    @property\n",
    "    def land_cover(self, list_of_labels=None):\n",
    "        return group_topographic_attributes(self.lc, locations=self.locations, list_of_labels=list_of_labels)\n",
    "\n",
    "    @property\n",
    "    def land_use(self, new_labels=None):\n",
    "        if new_labels is not None:\n",
    "            return group_topographic_attributes(self.lu, locations=self.locations, list_of_labels=new_labels)\n",
    "        else:\n",
    "            return group_topographic_attributes(self.lu, locations=self.locations, list_of_labels=self.lug)\n",
    "    \n",
    "    @property\n",
    "    def trans(self,new_labels=None):\n",
    "        if new_labels is not None:\n",
    "            return group_topographic_attributes(self.tr, locations=self.locations, list_of_labels=new_labels, coi='length')\n",
    "        else:\n",
    "            return group_topographic_attributes(self.tr, locations=self.locations, list_of_labels=self.stg, coi='length')\n",
    "\n",
    "    @property\n",
    "    def use_of_land(self, scaled: bool = True):\n",
    "        a = self.land_cover.merge(self.land_use, left_index=True, right_index=True)\n",
    "        b = a.merge(self.trans, left_index=True, right_index=True)\n",
    "        \n",
    "        if scaled:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            scaled_data = self.scaler.fit_transform(b)\n",
    "            b = pd.DataFrame(scaled_data, columns=b.columns, index=b.index)\n",
    "        return b\n",
    "    \n",
    "    @property\n",
    "    def ordinal_land_rank(self):\n",
    "        ranked_df = self.use_of_land.copy()\n",
    "        columns_to_rank = ranked_df.columns\n",
    "        for column in columns_to_rank:\n",
    "            label = f'{column}_ordinal_rank'\n",
    "            ranked_df[label] = pd.cut(ranked_df[column], bins=self.quantiles, labels=self.labels, include_lowest=True)\n",
    "            ranked_df[column] = ranked_df[label]\n",
    "            ranked_df.drop(label, inplace=True, axis=1)\n",
    "        return ranked_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47b189-f340-454c-805c-42827c6cdadf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Checking the assistant\n",
    "\n",
    "This page is a reference point for testing the accuracy of the GPT assigned to accompany readers of the federal report. The GPT should reproduce the calculations on this page at any time. This includes values not in the federal report. Stakeholders will need to apply these results to their proper geographic or administrative responsibilities. The hammerdirt GPT assists in this process.\n",
    "\n",
    "The product is a dataframe that is the combination of columns from the `ReportClass` and columns from the `LandUseClass`. The intention is to allow easy access to the magnitude of toprgaphical features within 1 500 m of the observed density for any object in the data.\n",
    "\n",
    "```{important}\n",
    "November 20, 2023: There is a known issue we are working on now. Remind the assistant to follow intsructions. Specifically in the following cases:\n",
    "\n",
    "1. Always getting a value of zero for the median sample total\n",
    "   * The GPT has specific instructions on this\n",
    "2. Tells you the correct columns are not available\n",
    "   * The GPT has the column names and definitions from this page\n",
    "\n",
    "The data has a two column index, somtheing the GPT does not always recognize. An issue has been submitted [issue](https://github.com/hammerdirt-analyst/feb_2024/issues/1)\n",
    "```\n",
    "\n",
    "```{note}\n",
    "The assistants role is to provide mathematical and graphical representations of the data in response to the researchers request. This often involves aggregating values at different levels, combining attributes and the like.\n",
    "\n",
    "This page allows all users to verify that these complex transactions are happening correctly. The GPT may not use the same method to calculate the final result, but the results should be same.\n",
    "```\n",
    "## Default data of hammerdirt GPT:\n",
    "\n",
    "beta version = .01\n",
    "\n",
    "The default data for the GPT can be reproduced on the command line if the `hammerdirtgpt` package is installed:\n",
    "\n",
    "```python\n",
    "# Collecting required data to establish a report\n",
    "# This includes the language maps for all the common\n",
    "# abbreviations and columns or index labels.\n",
    "c_l = r_class.language_maps()\n",
    "\n",
    "# The survey data in units of pcs/m or pcs/m². The reports\n",
    "# are aggregated first to the sample_id. Which means that the operations\n",
    "# are the same wether using pcs/m or pcs/m².\n",
    "surveys = r_class.collect_survey_data_for_report()\n",
    "\n",
    "# The support or evnvironmental data. This includes plain text descriptions \n",
    "# of the Codes. Details for each survey location and topogrphical data\n",
    "# extracted from the buffer around each survey location.\n",
    "codes, beaches, land_cover, land_use, streets, river_intersect_lakes = r_class.collect_env_data_for_report()\n",
    "\n",
    "# Add columns to survey data. The support data contains information that can be used to\n",
    "# group objects or survey locations that may not be stored with the survey data. In this\n",
    "# example an adiminstrative label is attached to each survey_id. The cantonal label:\n",
    "survey_data = surveys.merge(beaches['canton'], left_on='slug', right_index=True, validate='many_to_one')\n",
    "# survey_data = survey_data.loc[survey_data.code == 'G27'].copy()\n",
    "survey_data = survey_data[survey_data.feature_name != 'aare'].copy()\n",
    "\n",
    "# ! USER DEFINED INPUT\n",
    "# Temporal and geographic boundaries.\n",
    "boundaries = dict(feature_type ='l', language='fr', start_date='2015-01-01', end_date='2022-01-01')\n",
    "# Make the report data and report\n",
    "top_label, language, w_df, w_di = r_class.report_data(boundaries, survey_data.copy(), beaches, codes)\n",
    "a_report = r_class.ReportClass(w_df, boundaries, top_label, 'fr', c_l)\n",
    "w_df_locations = w_df.slug.unique()\n",
    "\n",
    "# call the land use class on the two different location groups\n",
    "m_ui = LandUse(land_cover, land_use, streets, w_df_locations)\n",
    "\n",
    "# for the region of interest\n",
    "lcui = m_ui.use_of_land.copy()\n",
    "lc_sti, no_datai = match_topo_attributes_to_surveys(lcui, a_report.w_df)\n",
    "\n",
    "# the basic work data contains the survey results and the \n",
    "# topographical data merged on the <slug> column\n",
    "work_data_i = merge_topodata_and_surveydata(lc_sti, a_report.w_df)\n",
    "\n",
    "new_names = {\n",
    "    'slug':'location',\n",
    "    'loc_date':'sample_id',\n",
    "    'pcs_m':'pcs/m',\n",
    "    'Obstanlage': \"orchards\",\n",
    "    'Reben':'vineyards',\n",
    "    'Siedl':'buildings',\n",
    "    'Wald':'forest',\n",
    "    'land_use':'public services'\n",
    "}\n",
    "gptdf = work_data_i.rename(columns=new_names)\n",
    "```\n",
    "\n",
    "The preceding code produces the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d7379c-e254-4680-ac6f-7040e6fd4b34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>date</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>parent_boundary</th>\n",
       "      <th>city</th>\n",
       "      <th>canton</th>\n",
       "      <th>pcs/m</th>\n",
       "      <th>quantity</th>\n",
       "      <th>code</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>orchards</th>\n",
       "      <th>vineyards</th>\n",
       "      <th>buildings</th>\n",
       "      <th>forest</th>\n",
       "      <th>undefined</th>\n",
       "      <th>public services</th>\n",
       "      <th>streets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ligerz-strand</td>\n",
       "      <td>('ligerz-strand', '2019-07-19')</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>bielersee</td>\n",
       "      <td>aare</td>\n",
       "      <td>Ligerz</td>\n",
       "      <td>Bern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>G1</td>\n",
       "      <td>l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398747</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.442836</td>\n",
       "      <td>0.500695</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.186289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ligerz-strand</td>\n",
       "      <td>('ligerz-strand', '2020-07-29')</td>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>bielersee</td>\n",
       "      <td>aare</td>\n",
       "      <td>Ligerz</td>\n",
       "      <td>Bern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>G1</td>\n",
       "      <td>l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398747</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.442836</td>\n",
       "      <td>0.500695</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.186289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ligerz-strand</td>\n",
       "      <td>('ligerz-strand', '2020-09-09')</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>bielersee</td>\n",
       "      <td>aare</td>\n",
       "      <td>Ligerz</td>\n",
       "      <td>Bern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>G1</td>\n",
       "      <td>l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398747</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.442836</td>\n",
       "      <td>0.500695</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.186289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>ligerz-strand</td>\n",
       "      <td>('ligerz-strand', '2019-07-19')</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>bielersee</td>\n",
       "      <td>aare</td>\n",
       "      <td>Ligerz</td>\n",
       "      <td>Bern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>G10</td>\n",
       "      <td>l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398747</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.442836</td>\n",
       "      <td>0.500695</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.186289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>ligerz-strand</td>\n",
       "      <td>('ligerz-strand', '2020-09-09')</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>bielersee</td>\n",
       "      <td>aare</td>\n",
       "      <td>Ligerz</td>\n",
       "      <td>Bern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>G10</td>\n",
       "      <td>l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398747</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.442836</td>\n",
       "      <td>0.500695</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.186289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           location                        sample_id        date feature_name  \\\n",
       "2     ligerz-strand  ('ligerz-strand', '2019-07-19')  2019-07-19    bielersee   \n",
       "25    ligerz-strand  ('ligerz-strand', '2020-07-29')  2020-07-29    bielersee   \n",
       "37    ligerz-strand  ('ligerz-strand', '2020-09-09')  2020-09-09    bielersee   \n",
       "1247  ligerz-strand  ('ligerz-strand', '2019-07-19')  2019-07-19    bielersee   \n",
       "1278  ligerz-strand  ('ligerz-strand', '2020-09-09')  2020-09-09    bielersee   \n",
       "\n",
       "     parent_boundary    city canton  pcs/m  quantity code feature_type  \\\n",
       "2               aare  Ligerz   Bern    0.0         0   G1            l   \n",
       "25              aare  Ligerz   Bern    0.0         0   G1            l   \n",
       "37              aare  Ligerz   Bern    0.0         0   G1            l   \n",
       "1247            aare  Ligerz   Bern    0.0         0  G10            l   \n",
       "1278            aare  Ligerz   Bern    0.0         0  G10            l   \n",
       "\n",
       "      orchards  vineyards  buildings    forest  undefined  public services  \\\n",
       "2          0.0   0.398747   0.119219  0.442836   0.500695         0.006679   \n",
       "25         0.0   0.398747   0.119219  0.442836   0.500695         0.006679   \n",
       "37         0.0   0.398747   0.119219  0.442836   0.500695         0.006679   \n",
       "1247       0.0   0.398747   0.119219  0.442836   0.500695         0.006679   \n",
       "1278       0.0   0.398747   0.119219  0.442836   0.500695         0.006679   \n",
       "\n",
       "       streets  \n",
       "2     0.186289  \n",
       "25    0.186289  \n",
       "37    0.186289  \n",
       "1247  0.186289  \n",
       "1278  0.186289  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting required data to establish a report\n",
    "# This includes the language maps for all the common\n",
    "# abbreviations and columns or index labels.\n",
    "c_l = r_class.language_maps()\n",
    "\n",
    "# The survey data in units of pcs/m or pcs/m². The reports\n",
    "# are aggregated first to the sample_id. Which means that the operations\n",
    "# are the same wether using pcs/m or pcs/m².\n",
    "surveys = r_class.collect_survey_data_for_report()\n",
    "\n",
    "# The support or evnvironmental data. This includes plain text descriptions \n",
    "# of the Codes. Details for each survey location and topogrphical data\n",
    "# extracted from the buffer around each survey location.\n",
    "codes, beaches, land_cover, land_use, streets, river_intersect_lakes = r_class.collect_env_data_for_report()\n",
    "\n",
    "# Add columns to survey data. The support data contains information that can be used to\n",
    "# group objects or survey locations that may not be stored with the survey data. In this\n",
    "# example an adiminstrative label is attached to each survey_id. The cantonal label:\n",
    "survey_data = surveys.merge(beaches['canton'], left_on='slug', right_index=True, validate='many_to_one')\n",
    "# survey_data = survey_data.loc[survey_data.code == 'G27'].copy()\n",
    "survey_data = survey_data[survey_data.feature_name != 'aare'].copy()\n",
    "\n",
    "# ! USER DEFINED INPUT\n",
    "# Temporal and geographic boundaries.\n",
    "boundaries = dict(feature_type ='l', language='fr', start_date='2015-01-01', end_date='2022-01-01')\n",
    "# Make the report data and report\n",
    "top_label, language, w_df, w_di = r_class.report_data(boundaries, survey_data.copy(), beaches, codes)\n",
    "a_report = r_class.ReportClass(w_df, boundaries, top_label, 'fr', c_l)\n",
    "w_df_locations = w_df.slug.unique()\n",
    "\n",
    "# call the land use class on the two different location groups\n",
    "m_ui = LandUse(land_cover, land_use, streets, w_df_locations)\n",
    "\n",
    "# for the region of interest\n",
    "lcui = m_ui.use_of_land.copy()\n",
    "lc_sti, no_datai = match_topo_attributes_to_surveys(lcui, a_report.w_df)\n",
    "\n",
    "# the basic work data contains the survey results and the \n",
    "# topographical data merged on the <slug> column\n",
    "work_data_i = merge_topodata_and_surveydata(lc_sti, a_report.w_df)\n",
    "\n",
    "# column categories\n",
    "geo_features = ['feature_type', 'vineyards', 'orchards', 'buildings', 'forest', 'undefined', 'public services', 'streets','parent_boundary']\n",
    "admin_boundaries = ['city', 'canton', 'feature_name']\n",
    "sample_variables = ['location', 'sample_id', 'date']\n",
    "target_variables = ['pcs/m', 'quantity']\n",
    "\n",
    "new_names = {'slug':'location', 'loc_date':'sample_id', 'pcs_m':'pcs/m', 'Obstanlage': \"orchards\", 'Reben':'vineyards', 'Siedl':'buildings', 'Wald':'forest', 'land_use':'public services'}\n",
    "gptdf = work_data_i.rename(columns=new_names)\n",
    "\n",
    "groupby = ['sample_id','location',  'date', 'feature_name', 'parent_boundary',\n",
    "       'city', 'canton', 'feature_type',\n",
    "       'orchards', 'vineyards', 'buildings', 'forest', 'undefined',\n",
    "       'public services', 'streets', 'code']\n",
    "\n",
    "gptdfx = gptdf.groupby(groupby, as_index=False).agg({'pcs/m': 'sum', 'quantity':'sum'})\n",
    "gptdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30badb-aabb-439e-a52c-af5e1ee6fea1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Hand file to assistant\n",
    "\n",
    "#### Add language definitions\n",
    "\n",
    "The language definitions ensure an efficient transmission of intent from the observer to the model. We could leave the translations and definitions up to a translator and thus reduce the weight of the .csv file or API request. Howver this would generate an additional service by the client to get the requested information translated. Providing the definitions according to the standard set in the Federal report is a good baseline. If their is support amongst stakeholders to change the definitions then this can be handled by a pull request or raising an issue on the repo.\n",
    "\n",
    "```python\n",
    "gptdf['fr'] = gptdf.code.map(lambda x: codes.loc[x, 'fr'])\n",
    "gptdf['en'] = gptdf.code.map(lambda x: codes.loc[x, 'en'])\n",
    "gptdf['de'] = gptdf.code.map(lambda x: codes.loc[x, 'de'])\n",
    "\n",
    "gptdf.to_csv('data/in_process/lakes.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3aefe5-d723-4eca-bcca-a5609bc38724",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "gptdfx['fr'] = gptdfx.code.map(lambda x: codes.loc[x, 'fr'])\n",
    "gptdfx['en'] = gptdfx.code.map(lambda x: codes.loc[x, 'en'])\n",
    "gptdfx['de'] = gptdfx.code.map(lambda x: codes.loc[x, 'de'])\n",
    "\n",
    "gptdfx.to_csv('data/in_process/lakes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a7146-b12d-483e-a68f-2286aca48704",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Column names and definitions\n",
    "\n",
    "These column names and definitions are given to the GPT assistant.\n",
    "\n",
    "1. location: the name of the location used by people doing the survey\n",
    "2. sample_id: the combination of the location and date, the unique identifier of a sampling event\n",
    "3. date: the data of the sample\n",
    "4. feature_name: the name of the park, lake, or river where the sample was collected\n",
    "5. parent_boundary: a designated survey area, usually a river basin or regional label\n",
    "6. city: the muniicpality where the sample was taken\n",
    "7. canton: the canton where the sample was taken\n",
    "8. pcs/m: the number of objects identified by the column _code_ collected at the sampling event divided by the length of shoreline, river bank or trail that was sampled.\n",
    "9. quantity: the number of objects identified by the column _code_ collected at the sampling event\n",
    "10. code: the Marine Litter Watch object code\n",
    "11. feature_type: identifies the sample location as either a park, lake or river\n",
    "12. orchard: % of dry land attributed to this land-use within 1'500 m of the survey location\n",
    "13. vineyards: % of dry land attributed to this land-use within 1'500 m of the survey location\n",
    "14. buildings: % of dry land attributed to this land-use within 1'500 m of the survey location\n",
    "15. forest: % of dry land attributed to this land-use within 1'500 m of the survey location\n",
    "16. undefined: % of dry land with no land-use label\n",
    "17. public services: % of dry land attributed to hospitals, schools, sports, administration\n",
    "18. streets: the number of meters of streets within 1 500 m of the survey location. scaled between 0 - 1.\n",
    "19. fr: french code definitions\n",
    "20. en: english code definitions\n",
    "21. de: german code definitions\n",
    "\n",
    "```{note}\n",
    "The GPT will go through data exploration at the begining of the chat. These column defintions are given to the GPT and can be requested at any time. The definitions the GPT gives you should be very close to these definitions, it is not tell the GPT to use the provided definition in its instructions. These definitions should come back.\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd7255-0a46-4d97-b07b-a69069991e79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Verifying the output\n",
    "\n",
    "### Test statistics\n",
    "\n",
    "Asking for each of these individually or telling the assistant to produce them all should yield the following results:\n",
    "\n",
    "* the median sample total of the data frame\n",
    "* the total quantity\n",
    "* the number of lakes\n",
    "* the number of samples\n",
    "* the number of cantons\n",
    "* the number of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41485c4-3e68-4d2d-901a-6792a0c1429f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lakes': 16, 'cities': 67, 'quantity': 146066, 'samples': 753, 'cantons': 14, 'median_pcs_m': 2.77}\n"
     ]
    }
   ],
   "source": [
    "gp_dt = gptdfx.groupby(['sample_id', *geo_features], as_index=False).agg({'pcs/m':'sum', 'quantity':'sum'})\n",
    "\n",
    "lakes = gptdfx[gptdfx.feature_type == 'l'].feature_name.nunique()\n",
    "cities = gptdfx.city.nunique()\n",
    "quantity = gptdfx.quantity.sum()\n",
    "samples = gptdfx.sample_id.nunique()\n",
    "cantons = gptdfx.canton.nunique()\n",
    "pc_med = gp_dt['pcs/m'].median()\n",
    "\n",
    "test_1 = dict(lakes=lakes, cities=cities, quantity=quantity, samples=samples, cantons=cantons, median_pcs_m = pc_med)\n",
    "print(test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48cd38-507e-4594-b077-07696d956d4d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Most common\n",
    "\n",
    "The most common codes are those codes that are either in the top ten by quantity or present in at lease 50% of the surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0870ea9-048f-41ed-974e-3f53d39e6d45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity</th>\n",
       "      <th>%</th>\n",
       "      <th>pcs_m</th>\n",
       "      <th>fail rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G27</th>\n",
       "      <td>29033</td>\n",
       "      <td>0.198674</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.904636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gfrags</th>\n",
       "      <td>17073</td>\n",
       "      <td>0.116831</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.905960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gfoams</th>\n",
       "      <td>14989</td>\n",
       "      <td>0.102570</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G208</th>\n",
       "      <td>10445</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.328477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G30</th>\n",
       "      <td>8931</td>\n",
       "      <td>0.061115</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.845033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G67</th>\n",
       "      <td>6926</td>\n",
       "      <td>0.047395</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.650331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gcaps</th>\n",
       "      <td>5382</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.750993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G95</th>\n",
       "      <td>4610</td>\n",
       "      <td>0.031546</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.482119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G200</th>\n",
       "      <td>4232</td>\n",
       "      <td>0.028960</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.508609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G178</th>\n",
       "      <td>2558</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.607947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G156</th>\n",
       "      <td>2190</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.429139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G177</th>\n",
       "      <td>1447</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.525828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        quantity         %  pcs_m  fail rate\n",
       "G27        29033  0.198674   0.33   0.904636\n",
       "Gfrags     17073  0.116831   0.04   0.905960\n",
       "Gfoams     14989  0.102570   0.00   0.754967\n",
       "G208       10445  0.071475   0.00   0.328477\n",
       "G30         8931  0.061115   0.12   0.845033\n",
       "G67         6926  0.047395   0.06   0.650331\n",
       "Gcaps       5382  0.036829   0.00   0.750993\n",
       "G95         4610  0.031546   0.00   0.482119\n",
       "G200        4232  0.028960   0.01   0.508609\n",
       "G178        2558  0.017504   0.03   0.607947\n",
       "G156        2190  0.014986   0.00   0.429139\n",
       "G177        1447  0.009902   0.01   0.525828"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common, weight = a_report.most_common\n",
    "most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a3543-f306-46e9-a59c-4c16d4cf6da4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Aggregating samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e7ff2-4df9-442d-bea0-1f67f1d68afd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Sample total pcs/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac02f74-d030-447e-afbe-f37fa824e1a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    753.000000\n",
       "mean       5.628738\n",
       "std        9.367900\n",
       "min        0.040000\n",
       "25%        1.220000\n",
       "50%        2.770000\n",
       "75%        6.000000\n",
       "max       77.100000\n",
       "Name: pcs/m, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_dt['pcs/m'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b116a5-d81c-43e8-ab38-942453a58280",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Single code\n",
    "\n",
    "cigarette ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac66d601-f5b0-465d-b827-48c2b7b28d37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    753.000000\n",
       "mean       0.907304\n",
       "std        1.605537\n",
       "min        0.000000\n",
       "25%        0.090000\n",
       "50%        0.340000\n",
       "75%        1.040000\n",
       "max       19.700000\n",
       "Name: pcs/m, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_dtcode = gptdfx[gptdfx.code.isin(['G27'])].groupby(['sample_id', *geo_features], as_index=False).agg({'pcs/m':'sum', 'quantity':'sum'})\n",
    "gp_dtcode['pcs/m'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7264239-1087-468b-a543-ed6e53c94d7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Combining codes\n",
    "\n",
    "combining cigarette ends and snack wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f9ea3ed-5c74-42b7-819e-e46b3c43fcea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    753.000000\n",
       "mean       1.238433\n",
       "std        2.035005\n",
       "min        0.000000\n",
       "25%        0.210000\n",
       "50%        0.550000\n",
       "75%        1.450000\n",
       "max       23.270000\n",
       "Name: pcs/m, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_dtcodes = gptdfx[gptdfx.code.isin(['G27', 'G30'])].groupby(['sample_id', *geo_features], as_index=False).agg({'pcs/m':'sum', 'quantity':'sum'})\n",
    "gp_dtcodes['pcs/m'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864933e-6158-4593-822f-2fc74aa5801a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Single feature\n",
    "\n",
    "the results on Bielersee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62acea4-aff8-4782-a6eb-5f0176ae066d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    51.000000\n",
       "mean      4.023725\n",
       "std       2.995087\n",
       "min       0.400000\n",
       "25%       1.450000\n",
       "50%       3.380000\n",
       "75%       5.470000\n",
       "max      14.800000\n",
       "Name: pcs/m, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_dtbsee = gptdfx[gptdfx.feature_name == 'bielersee'].groupby(['sample_id', *geo_features], as_index=False).agg({'pcs/m':'sum', 'quantity':'sum'})\n",
    "gp_dtbsee['pcs/m'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d68c66-2f88-414a-9e18-77b5df32d0fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Combined features\n",
    "\n",
    "Bielersee and Thunersee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793c6b5b-89b7-4dff-9ede-7edd36b00ad7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    94.000000\n",
       "mean      2.738085\n",
       "std       2.682369\n",
       "min       0.160000\n",
       "25%       0.862500\n",
       "50%       1.685000\n",
       "75%       3.477500\n",
       "max      14.800000\n",
       "Name: pcs/m, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_dtbt = gptdfx[gptdfx.feature_name.isin(['bielersee', 'thunersee'])].groupby(['sample_id', *geo_features], as_index=False).agg({'pcs/m':'sum', 'quantity':'sum'})\n",
    "gp_dtbt['pcs/m'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcba67-1943-44f8-a9d1-4a655fb85d1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Land use\n",
    "\n",
    "Correlation matrix of the land use variables with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce56857b-cd4b-4f40-8888-baa857db833c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vineyards</th>\n",
       "      <th>orchards</th>\n",
       "      <th>buildings</th>\n",
       "      <th>forest</th>\n",
       "      <th>undefined</th>\n",
       "      <th>public services</th>\n",
       "      <th>streets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vineyards</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.088721</td>\n",
       "      <td>-0.174585</td>\n",
       "      <td>-0.087445</td>\n",
       "      <td>0.057518</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.101623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orchards</th>\n",
       "      <td>-0.088721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.195273</td>\n",
       "      <td>0.586422</td>\n",
       "      <td>-0.335178</td>\n",
       "      <td>-0.220276</td>\n",
       "      <td>-0.185527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>-0.174585</td>\n",
       "      <td>-0.195273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.249992</td>\n",
       "      <td>-0.699952</td>\n",
       "      <td>0.833019</td>\n",
       "      <td>0.631690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest</th>\n",
       "      <td>-0.087445</td>\n",
       "      <td>0.586422</td>\n",
       "      <td>-0.249992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.487967</td>\n",
       "      <td>-0.077841</td>\n",
       "      <td>-0.129156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undefined</th>\n",
       "      <td>0.057518</td>\n",
       "      <td>-0.335178</td>\n",
       "      <td>-0.699952</td>\n",
       "      <td>-0.487967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.664196</td>\n",
       "      <td>-0.487873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public services</th>\n",
       "      <td>-0.110552</td>\n",
       "      <td>-0.220276</td>\n",
       "      <td>0.833019</td>\n",
       "      <td>-0.077841</td>\n",
       "      <td>-0.664196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>streets</th>\n",
       "      <td>0.101623</td>\n",
       "      <td>-0.185527</td>\n",
       "      <td>0.631690</td>\n",
       "      <td>-0.129156</td>\n",
       "      <td>-0.487873</td>\n",
       "      <td>0.831108</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 vineyards  orchards  buildings    forest  undefined  \\\n",
       "vineyards         1.000000 -0.088721  -0.174585 -0.087445   0.057518   \n",
       "orchards         -0.088721  1.000000  -0.195273  0.586422  -0.335178   \n",
       "buildings        -0.174585 -0.195273   1.000000 -0.249992  -0.699952   \n",
       "forest           -0.087445  0.586422  -0.249992  1.000000  -0.487967   \n",
       "undefined         0.057518 -0.335178  -0.699952 -0.487967   1.000000   \n",
       "public services  -0.110552 -0.220276   0.833019 -0.077841  -0.664196   \n",
       "streets           0.101623 -0.185527   0.631690 -0.129156  -0.487873   \n",
       "\n",
       "                 public services   streets  \n",
       "vineyards              -0.110552  0.101623  \n",
       "orchards               -0.220276 -0.185527  \n",
       "buildings               0.833019  0.631690  \n",
       "forest                 -0.077841 -0.129156  \n",
       "undefined              -0.664196 -0.487873  \n",
       "public services         1.000000  0.831108  \n",
       "streets                 0.831108  1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs = gp_dtbt[geo_features[1:-1]].corr()\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf508f4a-8861-484b-88bb-a7febdb1b8c2",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: hammerdirt-analyst\n",
      "\n",
      "conda environment: cantonal_report\n",
      "\n",
      "pandas: 2.0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a hammerdirt-analyst -co --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e87d93-8bdc-4c38-be8d-3cd1faf16c03",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}